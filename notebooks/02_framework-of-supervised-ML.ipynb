{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\title{Lecture 2: Framework of supervised machine learning}\n",
    "\\author{Arvind Suresh}\n",
    "\\date{Jan 27, 2025}\n",
    "\n",
    "\\maketitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last time\n",
    "\n",
    "## Loading the two datasets\n",
    "\n",
    "Let's start by again loading the `iris` and `real_estate` datasets. Note that each one actually contains a \"train\" set and \"test\" set. We explain what these are and where the names come from later below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the train data\n",
    "iris_train = pd.read_csv('../data/classification/iris/train.csv')\n",
    "real_estate_train = pd.read_csv('../data/regression/real_estate_valuation/train.csv')\n",
    "\n",
    "# Load the test data\n",
    "iris_test = pd.read_csv('../data/classification/iris/iris_test_private.csv')\n",
    "real_estate_test = pd.read_csv('../data/regression/real_estate_valuation/real_estate_valuation_test_private.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems of prediction\n",
    "\n",
    "We saw last time that ML problems are problems of prediction, and they fall into one of two categories, depending on the nature of the target variable to be predicted:\n",
    "\n",
    "- *Classification*. \n",
    "    - This is when  $Y$ is a categorical variable with finitely many possible values $c_1,\\dotsc,c_r$.\n",
    "    - The values of $Y$ partition the instances into $r$ classes. \n",
    "    - Predicting $Y$ amounts to classifying the instances, i.e. determining which class the instance lies in.\n",
    "    - For example, a natural target for `iris` is `class`; given a particular iris flower, one wants to classify it as belonging to one of the three classes (`Iris-setosa`, `Iris-virginica`, or `Iris-versicolor`).\n",
    "- *Regression*.\n",
    "    - This is when $Y$ is a continuous variable with real values.\n",
    "    - One wants to predict the value of $Y$ as closely as possible.\n",
    "    - For example, a natural target for `real_estate` is `Y house price of unit area`; given a particular house, one wants to predict the price per unit area. \n",
    "\n",
    "## Labelled and unlabelled datasets\n",
    "\n",
    "All the datasets loaded above are *labelled*, which means that they contain the target column for all instances. A dataset is *unlabelled* if it does not contain the target column. For example, running the following code will load unlabelled versions of the test set for `iris` and `real_estate`:\n",
    "\n",
    "```python\n",
    "iris_test_unlabelled = pd.read_csv('../data/classification/iris/test.csv')\n",
    "real_estate_test_unlabelled = pd.read_csv('../data/regression/real_estate_valuation/test.csv')\n",
    "```\n",
    "\n",
    "Machine Learning falls, broadly speaking, into one of two types:\n",
    "\n",
    "- Supervised Machine Learning seeks to train models on labelled datasets like `real_estate`, so that they can make predictions on unlabelled datasets like `real_estate_test`. \n",
    "- Unsupervised Machine Learning... is postponed until later. \n",
    "\n",
    "# Framework of supervised machine learning\n",
    "\n",
    "## Stating the problem\n",
    "\n",
    "Suppose we have a labelled dataset `train` with features $X_1,\\dotsc,X_n$ and target $Y$, and unlabelled dataset `test` with only the features $X_1,\\dotsc,X_n$. Machine Learning begins with:\n",
    "\n",
    "**Assumption 1.** *There exists some \"ground truth function\" $\\mathbf{F} : \\mathbb{R}^n \\to \\mathbb{R}$ such that*\n",
    "\\begin{equation}\n",
    "    Y = \\mathbf{F}(X_1,\\dotsc,X_n) + \\epsilon,\n",
    "\\end{equation}\n",
    "*where $\\epsilon$ is a small \"noise\" term to account for randomness inherent in the problem*. In other words, for every row $P = (x_1,\\dotsc,x_n)$ of features in our dataset (thought of as a point in $\\mathbb{R}^n$), the entry is the $y$-column is $$\\mathbf{F}(P) + \\epsilon = \\mathbf{F}(x_1,\\dotsc,x_n) + \\epsilon.$$ Thus, each row of the dataset looks like an ordered pair $(P,\\mathbf{F}(P) + \\epsilon)$, where $P \\in \\mathbb{R}^n$ and the $\\mathbf{F}(P) + \\epsilon \\in \\mathbb{R}$. \n",
    "\n",
    "The domain of $\\mathbf{F}$ is called the **feature space**, and the co-domain is the **target space**. Thus, the rows of our dataset can be visualized as a cloud of points; blue points correpond to rows of features $P \\in \\mathbb{R}^n$, red points correspond to pairs $(P,\\mathbf{F}(P) + \\epsilon) \\in \\mathbb{R}^{n+1}$.\n",
    "\n",
    "<img src=\"assets/ML-function-diagram.png\" width=\"60%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"learn\" in machine learning comes from the following formulation of our problem of prediction:\n",
    "\n",
    "**Goal 1.** *Compute (a good approximation to) the function $\\mathbf{F}$. That is, use the labelled dataset to <u>learn</u> the function $\\mathbf{F}$*.\n",
    "\n",
    "**Remark.** In practice, as is the case with `iris_test`, the test set will be labelled. The reason is quite natural- we need data to train our model, but we also need data to test our model's performance on instances which it has not seen during the training (that is, we need to know how well our model generalizes to new instances). Thus, we take our initial labelled data set and split off a portion for testing, and use the other portion for training. Note that, if we want to be able to glean $\\mathbf{F}$ by looking at the train set, we require it to be robust enough to create an approximation to $\\mathbf{F}$ which *generalizes* well to instances outside the dataset. More on this later. \n",
    "\n",
    "## Evaluation metrics\n",
    "\n",
    "Suppose we have managed to determine a function $F$ that (we believe) approximates $\\mathbf{F}$ well, and we write a program to implement this function. Our program accepts a dataset (the test set) with $m$ rows (instances) and columns $X_1,\\dotsc,X_n \\in \\mathbb{R}^m$ (features), and outputs a column vector of predictions $y_{\\textup{pred}} \\in \\mathbb{R}^m$. \n",
    "\n",
    "Our claim that $F$ is a good approximation to $\\mathbf{F}$ is judged by how closely our prediction vector $y_{\\textup{pred}} \\in \\mathbb{R}^m$  aligns with the vector $y_{\\textup{true}} \\in \\mathbb{R}^m$ of true values in the test set. This measure of closeness is made quantitative and rigorous in the form of a **scoring function**, which associates to the pair $(y_{\\textup{pred}},y_{\\textup{true}})$ some kind of numerical score $\\textup{Score}(y_{\\textup{pred}},y_{\\textup{true}})$:\n",
    "$$\\textup{Score}(y_{\\textup{pred}},y_{\\textup{true}}) : \\textup{ a number which encodes how closely $y_{\\textup{pred}}$ aligns with $y_{\\textup{true}}$.}$$\n",
    "\n",
    "- For classification tasks, a simple (but often not very informative) scoring function is simply  *accuracy score*: it is the fraction of instances that were correctly classified: $$ \\textup{Accuracy}(y_{\\textup{pred}},y_{\\textup{true}}) = \\dfrac{\\textup{Number of entries where } y_{\\textup{pred}} = y_{\\textup{true}}}{m}. $$\n",
    "The greater the accuracy score, the better our model is at making predictions.\n",
    "- For regression tasks, a simple (and perhaps the most widely used) scoring function is *Mean-squared error*: it is the square of the distance between the vectors $y_{\\textup{true}}$ and $y_{\\textup{pred}}$ in $\\mathbb{R}^m$, and divided by $m$ to (in some sense) account for the fact that there are $m$ entries: $$ \\textup{MSE}(y_{\\textup{pred}},y_{\\textup{true}}) = \\dfrac{||{y_{\\textup{pred}} - y_{\\textup{true}}}||^2}{m}. $$\n",
    "The smaller the MSE, the better our model is at making predictions. \n",
    "\n",
    "**Example.** As an example, let's make some random predictions of `class` for the labelled iris test set below and compute the accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>role</th>\n",
       "      <th>type</th>\n",
       "      <th>demographic</th>\n",
       "      <th>description</th>\n",
       "      <th>units</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>new_col_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal length</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cm</td>\n",
       "      <td>no</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal width</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cm</td>\n",
       "      <td>no</td>\n",
       "      <td>X2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal length</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cm</td>\n",
       "      <td>no</td>\n",
       "      <td>X3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal width</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cm</td>\n",
       "      <td>no</td>\n",
       "      <td>X4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class</td>\n",
       "      <td>Target</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>class of iris plant: Iris Setosa, Iris Versico...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name     role         type  demographic  \\\n",
       "0  sepal length  Feature   Continuous          NaN   \n",
       "1   sepal width  Feature   Continuous          NaN   \n",
       "2  petal length  Feature   Continuous          NaN   \n",
       "3   petal width  Feature   Continuous          NaN   \n",
       "4         class   Target  Categorical          NaN   \n",
       "\n",
       "                                         description units missing_values  \\\n",
       "0                                                NaN    cm             no   \n",
       "1                                                NaN    cm             no   \n",
       "2                                                NaN    cm             no   \n",
       "3                                                NaN    cm             no   \n",
       "4  class of iris plant: Iris Setosa, Iris Versico...   NaN             no   \n",
       "\n",
       "  new_col_name  \n",
       "0           X1  \n",
       "1           X2  \n",
       "2           X3  \n",
       "3           X4  \n",
       "4            Y  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = pd.read_csv('../data/classification/iris/data_description.csv')\n",
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa', 'Iris-virginica', 'Iris-versicolor']\n",
      "Accuracy: 0.33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               true             pred  correct\n",
       "0       Iris-setosa   Iris-virginica    False\n",
       "1    Iris-virginica      Iris-setosa    False\n",
       "2   Iris-versicolor   Iris-virginica    False\n",
       "3   Iris-versicolor   Iris-virginica    False\n",
       "4       Iris-setosa  Iris-versicolor    False\n",
       "5   Iris-versicolor   Iris-virginica    False\n",
       "6       Iris-setosa      Iris-setosa     True\n",
       "7       Iris-setosa      Iris-setosa     True\n",
       "8    Iris-virginica   Iris-virginica     True\n",
       "9   Iris-versicolor      Iris-setosa    False\n",
       "10   Iris-virginica   Iris-virginica     True\n",
       "11   Iris-virginica  Iris-versicolor    False\n",
       "12   Iris-virginica  Iris-versicolor    False\n",
       "13  Iris-versicolor  Iris-versicolor     True\n",
       "14      Iris-setosa  Iris-versicolor    False\n",
       "15      Iris-setosa      Iris-setosa     True\n",
       "16      Iris-setosa   Iris-virginica    False\n",
       "17  Iris-versicolor  Iris-versicolor     True\n",
       "18  Iris-versicolor  Iris-versicolor     True\n",
       "19   Iris-virginica  Iris-versicolor    False\n",
       "20      Iris-setosa  Iris-versicolor    False\n",
       "21   Iris-virginica      Iris-setosa    False\n",
       "22  Iris-versicolor      Iris-setosa    False\n",
       "23   Iris-virginica      Iris-setosa    False\n",
       "24   Iris-virginica   Iris-virginica     True\n",
       "25  Iris-versicolor   Iris-virginica    False\n",
       "26  Iris-versicolor   Iris-virginica    False\n",
       "27      Iris-setosa  Iris-versicolor    False\n",
       "28   Iris-virginica   Iris-virginica     True\n",
       "29      Iris-setosa   Iris-virginica    False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the labelled iris test set\n",
    "iris_test_full = pd.read_csv('../data/classification/iris/iris_test_private.csv')\n",
    "\n",
    "# Get the classes and display them\n",
    "classes = iris_test_full['Y'].unique().tolist()\n",
    "print(classes)\n",
    "\n",
    "# create a vector of true labels\n",
    "y_true = iris_test_full['Y'].values\n",
    "\n",
    "# Create a column of predictions, sampling uniformly from the classes\n",
    "y_pred = np.random.choice(classes, size=iris_test.shape[0])\n",
    "\n",
    "# Create a vector with 1 for correct predictions and 0 for incorrect predictions\n",
    "correct = y_true == y_pred\n",
    "\n",
    "#compute and display the accuracy\n",
    "accuracy = correct.mean()\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# display predictions, true values, correctness\n",
    "pd.DataFrame({'true': y_true, 'pred': y_pred, 'correct': correct})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above code many times changes the predictions and accuracy because the function `np.random.choice` is generating the predictions randomly. In general, you should be seeing that the accuracy is typically below $0.5$, meaning that less than $50\\%$ of the random predictions were correct!\n",
    "\n",
    "## What is a ML model?\n",
    "\n",
    "OK. We want to learn this hypothetical function $\\mathbf{F}$? How? In fact, what does it even mean to \"know\" the function $\\mathbf{F}$? \n",
    "\n",
    "The answer is tautological: knowing the function means that, given an input, we can compute the output. That is, knowing $\\mathbf{F}$ means that we know the *formula* which defines $\\mathbf{F}$, if such a formula at all exists, or more generally, we know an algorithm for computing outputs of $\\mathbf{F}$.\n",
    "\n",
    "Since there is a vast, vast jungle of possible functions, our starting point is always to first study the labelled dataset to explore any visible patterns in the data; this is known as *exploratory data analysis*, or EDA. A thorough and fruitful exploration of the data will allow us to narrow our search by making:\n",
    "\n",
    "**Assumption 2.** *There is a certain <u>class</u> of functions $\\mathcal{C}$ (called a **model**) such that some member $F \\in \\mathcal{C}$ is a good approximation to $\\mathbf{F}$.*\n",
    "\n",
    "The word model above is used in the mathematical sense; it refers to a family of functions that are all similar in some respect, for example, linear, logistic, exponential, polynomial, trigonometric, and so on. We also call them **machine learning models**. \n",
    "\n",
    "Now, given assumption 2, we have a model $\\mathcal{C}$ consisting of candidates for our approximation of $\\mathbf{F}$. Then, our problem is re-phrased as:\n",
    "\n",
    "**Goal 2.** *Produce the particular function $\\hat{F}$ in the chosen model $\\mathcal{C}$ which best approximates $\\mathbf{F}$ among all functions in $\\mathcal{C}$.* \n",
    "\n",
    "## Model parameters\n",
    "\n",
    "The examples of models given above are all **parametric models**: each model consists of functions having the same type of formula. These formulas involve constants, which are called **parameters**, and varying the parameters results in varying the function within the model. \n",
    "\n",
    "Suppose for example that we have just one feature $X$ and one target $Y$, both continuous. The simplest possible model is the *linear model*: $$\\mathcal{C}_{\\textup{linear}} = \\{ \\textup{Functions of the form } F(X) = mX + b \\}.$$ The model parameters here are pairs of real numbers $m$ and $b$, which can be grouped together and viewed as a single point $\\mathbf{w} = (m,b) \\in \\mathbb{R}^2$. This point corresponds to the linear function $F_{\\mathbf{w}}(X) = mX + b$. For example, the point $\\mathbf{w} = (1,1)$ corresponds to $F_{\\mathbf{w}}(X) = X + 1$. In fact, we have a bijection\n",
    "\\begin{align*}\n",
    "    \\mathbb{R}^2 & \\leftrightarrow \\mathcal{C}_{\\textup{linear}},\\\\\n",
    "    \\mathbf{w} & \\mapsto F_{\\mathbf{w}}(X).\n",
    "\\end{align*}\n",
    "So, we want to think of the model $\\mathcal{C}_{\\textup{linear}}$ itself as $\\mathbb{R}^2$, which is typically referred to as the **parameter space** or **weight space**. Goal 2 of finding the best approximation to $\\mathbf{F}$ within $\\mathcal{C}_{\\textup{linear}}$ amounts to finding a special point $\\hat{\\mathbf{w}}$ in the parameter space. In general, we can reformulate our goal as:\n",
    "\n",
    "**Goal 3.** *Produce the particular value $\\hat{\\mathbf{w}}$ of the parameters such that the corresponding function $F_{\\hat{\\mathbf{w}}}$ is the best approximation to $\\mathbf{F}$ within the model $\\mathcal{C}$.* \n",
    "\n",
    "## Loss functions\n",
    "The heart of supervised ML is the problem of accomplishing goal 3 and finding the parameters $\\hat{\\mathbf{w}}$ resulting in the *best* approximation $F_{\\hat{\\mathbf{w}}}$ to $\\mathbf{F}$. To make sense of the phrase \"best\", we first need a way to measure the goodness of a particular approximation $F_{\\mathbf{w}}$. This is accomplished by means of a **loss function**:\n",
    "\n",
    "A loss function is a real-valued function of the parameters, denoted $J(\\mathbf{w})$, which measures how well the corresponding function $F_{\\mathbf{w}}$ approximates $\\mathbf{F}$ *on the train set*. Any choice of parameters $\\mathbf{w}$ allows us to produce a vector of predictions $$y_{\\textup{pred},\\mathbf{w}} = F_{\\mathbf{w}}(X_1,\\dotsc,X_n) \\in \\mathbb{R}^r,$$ where $r$ denotes the number of instances of the train set. (Above, I've added the subscript $\\mathbf{w}$ to emphasize that the predictions change with $\\mathbf{w}$.) Similar to the evaluation metric, the loss function $J$ is a measure of how closely the predictions $y_{\\textup{pred},\\mathbf{w}} \\in \\mathbb{R}^r$ align with the true values $y_{\\textup{true}} \\in \\mathbb{R}^r$. \n",
    "\n",
    "A key difference, however, is that we view the loss as a function of the parameters, not of the data! This is quite natural: for the same fixed dataset, varying $\\mathbf{w}$ will vary the prediction vector $y_{\\textup{pred},\\mathbf{w}}$, which causes the loss $J$ between $y_{\\textup{true}}$ and $y_{\\textup{pred},\\mathbf{w}}$ to also vary. Choosing a useful loss function is one of the most important steps in building a good model. Often, one simply wants to take the loss to be the same as the evaluation metric (as we'll see, this won't always work). The next diagram visualizes what a loss function may look like. Note that the special value $\\hat{\\mathbf{w}}$ which minimizes the loss may not be unique!\n",
    "\n",
    "<img src=\"assets/loss-function-diagram.png\" width=\"60%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.** Returning back to the simple linear regression example with one feature $X$ and target $Y$, we could choose our loss function to be MSE. For a particular choice of parameters $\\mathbf{w} = (m,b) \\in \\mathbb{R}^2$, our function looks like $$F_{\\mathbf{w}}(X) = mX + b.$$ \n",
    "    Thus, if $X = [x_1 \\, \\dotsc \\, x_r]^t \\in \\mathbb{R}^r$ (the $t$ stands for transpose), then \n",
    "our vector of predictions is simply $$y_{\\textup{pred},\\mathbf{w}} = \\begin{bmatrix} mx_1 + b \\\\ \\vdots \\\\ mx_r + b \\end{bmatrix} \\in \\mathbb{R}^r.$$ Using MSE as our loss function, we have\n",
    "\\begin{align*}\n",
    "J(\\mathbf{w}) & = \\textup{MSE} (y_{\\textup{pred},\\mathbf{w}},y_{\\textup{true}})\\\\\n",
    "        & = \\dfrac{|| y_{\\textup{pred},\\mathbf{w}} - y_{\\textup{true}}||^2}{r}\\\\\n",
    "        & = \\dfrac{1}{r} \\sum_{i=1}^r (mx_i + b - y_i)^2,\n",
    "\\end{align*}\n",
    "which is indeed a function of $\\mathbf{w} = (m,b)$! So, for this toy example, Goal 3 would be restated as: *Find the value of $\\mathbf{w} = (m,b) \\in \\mathbb{R}^2$ which results in the smallest possible loss $J(\\mathbf{w})$*.\n",
    "\n",
    "## Model fitting/training\n",
    "In general, given a parametric model and a training dataset, **model training** or **model fitting** refers to the act of solving the following optimization problem: *Determine the the **optimum** value of the parameters $\\mathbf{w}$, i.e. the value $\\mathbf{w} = \\hat{\\mathbf{w}}$ which results in the smallest possible loss $J(\\mathbf{w})$.* \n",
    "\n",
    "Once $\\hat{\\mathbf{w}}$ has been found, we say that the model has been trained on the dataset, or that it has been fit to the dataset. Note that the choice of $\\hat{\\mathbf{w}}$ depends on the actual dataset being used for the training, so if more data is added (or removed) then we would expect the fit of the model (i.e. the choice of $\\hat{\\mathbf{w}}$) to change!\n",
    "\n",
    "**Example.** The example below implements a simple linear regression model to predict the target variable `Y house price of unit area` from the `real_estate` dataset (this will be our train set). For simplicity, we use only the feature `X2 house age` to predict the target. The loss function is MSE, and the model is trained to find the best parameters $\\hat{\\mathbf{w}} = (\\hat{m},\\hat{b})$ which minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model F is given by: Y = -0.22854316632099875X + 42.11997584096778\n",
      "Mean squared error: 170.15\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHFCAYAAAAHcXhbAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZEhJREFUeJzt3Xl0U9Xax/FvWlrGMMsoICoqoMx4hQtWZHB8FUXFAQUccLgIytUyqUURGVRArrNcQAVRcUZFQW5BpIoyiuLAUBBLW6ZCCy0t0P3+cdrQdEzSpidpfp+19lqck9OTJzsh58ne++ztAAwiIiIiQSrM7gBERERESkPJjIiIiAQ1JTMiIiIS1JTMiIiISFBTMiMiIiJBTcmMiIiIBDUlMyIiIhLUlMyIiIhIUFMyIyIiIkFNyYxIPsYYj0pUVJTdoZapuXPnEh8fb3cYtoiKinJ7b0+cOEFSUhLvv/8+5513XrnEEBsbS2xsrGu7RYsWGGMYPHiwV+dp3bo1MTExtGjRosBjofweS8VWye4ARALNRRdd5Lb9+OOP06tXLy699FK3/Vu2bCnPsKQcjB07ltjYWCIjI+nSpQtPPPEEvXv35oILLmDPnj3lGktiYiIXXXQR27dv9+rv2rRpw4QJE1ixYgW7du1ye2zixIm88MILZRmmSEBQMiOSz5o1a9y29+3bR3Z2doH9+VWtWpWMjAx/hiZ+tnXrVtf7vGrVKg4dOsScOXMYMmQIzzzzTKF/46/3PSsrq8TPnLd27NhRpucTCRTqZhLxQWxsLJs3b6Znz56sXr2ao0ePMmfOHMDqpoqJiSnwN/Hx8cydO9dtX8OGDXn11VfZvXs3mZmZ7NixgyeeeILw8PBin//jjz9m586dOByOAo/98MMPrFu3zrX9wAMPsHLlSpKTkzly5Ag///wzjz76KJUqFf9bprhujsJe49lnn82CBQtITk7m2LFjbNmyhQceeMDtGIfDwfjx4/n9999JT08nJSWFTZs2MWLEiCLjqF+/PpmZmTz11FMFHjv33HMxxvDggw8CVmLx7LPPsmPHDjIyMjhw4AA//fQTN998c7GvtSg//PADgKvLJiYmBmMMHTt2ZNGiRRw8eNCt5eT+++9nw4YNpKenc/DgQRYtWkTLli0LnPfRRx9l586dZGRksG7dOi6//PICxxRV/+eeey7vvPMOSUlJHDt2jF27dvHmm28SGRnJ4MGD+eCDDwBYsWKFq9ss9xyFdTNVrlyZZ555hh07dpCZmcnff//Niy++SK1atdyOi4+PZ/HixVx22WWsW7eO9PR0fvvtN4YOHep2XFm/ByKeUMuMiI8aN27M/PnzmTZtGuPGjSM7O9urv2/YsCE//vgj2dnZPPXUU2zfvp1u3brx2GOPccYZZ3DnnXcW+bdz5szhs88+49JLL2X58uWu/eeeey7/+Mc/XBd3gLPOOot33nmH+Ph4srKyaN++PePHj+e8887jrrvu8v6FF6J169bExcXx119/8e9//5ukpCQuu+wyZs2aRf369V2JSHR0NBMmTODpp5/m22+/JSIigvPOO4/atWsXee79+/fz+eefM3jwYFcykWvo0KFkZmayYMECAKZPn87tt9/OY489xoYNG6hevTrnn38+9erV8+l1nX322YDVOpfXRx99xLvvvsurr75K9erVAXjttdcYMmQIs2bNYvTo0dStW5cnnniCuLg42rdvz969ewErIZowYQKzZ8/mgw8+oFmzZrzxxhuEh4fzxx9/FBtPu3bt+O6779i/fz9PPPEEW7dupXHjxlxzzTVERkbyxRdfMHbsWCZPnswDDzzA+vXrAYrtqvrkk0/o3bs3kydPZtWqVbRr144nn3ySbt260a1bN7KyslzHtm/fnueff54pU6aQnJzM3XffzZw5c9i2bRurVq0Cyv49EPGUUVFRKbrMnTvXpKWlue2LjY01xhjTq1evAscbY0xMTEyB/fHx8Wbu3Lmu7VdeecWkpqaaZs2auR03atQoY4wxrVu3LjKm8PBwk5iYaObPn++2f8qUKebYsWOmbt26hf6dw+Ew4eHhZtCgQeb48eOmdu3abq8zPj7etd2iRQtjjDGDBw8u8TUuWbLE/PXXX8bpdLodN2vWLJOenu56ns8++8ysX7/e6/fg6quvNsYY06dPH9e+sLAw8/fff5tFixa59v3888/mo48+8vr8UVFRxhhjbrzxRhMeHm6qVKlievToYf78809z/Phxc8EFFxjAxMTEGGOMmTBhgtvf/+Mf/zDGGPPwww+77W/atKk5evSomTJligFMrVq1THp6uvnwww/djuvWrZsxxpjY2Nhi6/+bb74xBw8eNPXr1y/ytQwYMMAYY0xUVFShn+W873G/fv2MMcY88sgjbsfdeOONxhhj7r77brfPb3p6utvntXLlymb//v3mlVdeKfV7oKJSmqJuJhEfHTx40O3uE29dffXVxMbGsmfPHsLDw11lyZIlAMXeLXXy5Enmz5/P9ddfT82aNQEICwvj9ttv59NPP+XgwYOuYzt06MCnn37K/v37yc7O5sSJE7z99ttUqlSJc845x+f4c1WuXJnevXvz8ccfk56e7vZavvzyS6pWreoaVP3jjz/Svn17XnrpJfr164fT6fToOZYsWUJiYqJbl8Zll11G06ZNXd17uee/4oormDx5MlFRUVSpUsWr1/L+++9z4sQJMjIyWLVqFeHh4dxwww1s3rzZ7bgPP/zQbfvqq68mOzub+fPnu73+pKQkNm3axCWXXAJAt27dqFq1qqslKdf333/Pzp07i42tatWqREVF8f7777N//36vXldRcge1z5s3z23/okWLOHLkCL1793bbv3HjRnbv3u3azszM5M8//3S7c6q074GIL5TMiPgoMTGxVH/fsGFDrrnmGk6cOOFWcu+Sql+/frF/P2fOHKpWreoai3DZZZfRpEkTt3E5zZo1Y9WqVTRt2pSRI0fSo0cPunTp4hrLUrVq1VK9BoB69eoRERHBiBEjCryW3MQs97VMnjyZRx55hIsuuoglS5Zw4MABvvnmGzp37lzsc5w8eZK3336b6667zjWWY8iQIezZs4evv/7addyIESOYOnUq/fv3Z8WKFRw8eJCPP/7Y1V1UkujoaLp06ULHjh1p1qwZZ511Fp9++mmB4/K/9w0bNiQsLIy9e/cWqINu3bq5Xn9uV0tSUlKBcxa2L686depQqVIl/v77b49eiyfq1avH8ePHC02OkpKSCnQNHThwoMBxmZmZbp+j0r4HIr7QmBkRH+Udu5HXsWPHqFy5coH9+S8M+/fv5+eff2b8+PGFnqekW4F/++031qxZw9ChQ3n99dcZOnQoCQkJLF261HVM//79qVGjBtdffz1//fWXa3+HDh2KPXfu6wAKvJa6deu6baekpLhae1566aVCz5U76PTkyZPMmDGDGTNmUKtWLfr06cMzzzzD119/TbNmzYq9K2ju3LlER0dz8803895773HNNdcwc+ZMt7FK6enpTJgwgQkTJtCgQQOuuOIKpkyZwuLFi2ndunWJr3nHjh1ug6eLkv+9z2316tmzJ5mZmQWOz92Xmww0atSowDGNGjUqtnXm4MGDnDhxgtNPP73E+Dx14MABIiIiqF+/foGEplGjRvz0009en7O074GIL5TMiJSxnTt30q5dO7d9vXr1KtCl8vnnn3PllVeyfft2Dh065NNzzZ07l1dffZV//vOf/N///R/Tp093u7jnXnTzX2DvueeeEs+dnJxMRkZGgddy7bXXum1nZGQQGxtLx44d+fnnnzl+/LhHsR8+fJgPP/yQpk2b8sILL3DGGWfw22+/FXn877//zg8//MDQoUMJDw+nSpUqBe4Oy2vv3r28+eabtG/fnocfftivt85//vnnjB07lqZNm7Jo0aIij/vhhx/IyMjgtttu46OPPnLt79atG2eccUaxycyxY8dYuXIlN954I+PHjy+0lQROvdeetLotX76c0aNHM2jQIGbOnOnaP2DAAGrUqOE2uNwX5fkeSGhTMiNSxt5++20mTpzIk08+ycqVK2nTpg3Dhw8vkLA88cQT9O3bl7i4OGbNmsUff/xBlSpVOOOMM7jyyiu57777SEhIKPa5Fi5cyPTp01m4cCFVqlQpMPZh2bJlZGZmsnDhQqZNm0aVKlW4//77qVOnjkevZf78+dx5551s376dTZs2ceGFF3LrrbcWOG7kyJF89913rFq1ildeeYWdO3fidDo5++yz+b//+z/X2IvPPvuMX375hbVr17Jv3z5atGjBQw89xM6dO9m6dWuJ8cyZM4fXX3+dJk2asHr1av7880+3x3/44Qc+//xzfv75Z1JSUmjdujW33347cXFxfr2IxsXF8dprrzF37ly6dOnCt99+y9GjR2ncuDE9evRg8+bNvPrqqxw6dIjnnnuOxx9/nDfeeINFixbRrFkzJkyY4FG35ahRo/juu+9Ys2YNU6ZMYdu2ba7uynvvvZcjR47wyy+/ADBs2DDS0tI4duwY8fHxbuOoci1btoyvvvqKqVOnUrNmTVavXu26m2n9+vW8/fbbXteFXe+BiO2jkFVUArkUdTfT5s2bCz0+IiLCTJkyxezatcscPXrUxMbGmnbt2hW4mwkw9erVMzNnzjTbt283mZmZZv/+/eann34yEydONNWqVfMovvnz5xtjjFm1alWhj1911VVmw4YNJj093ezevdtMnTrVXHbZZQXueMl/pwtgnE6nef31101iYqJJS0szn376qWnevHmhd2y1aNHCzJ492+zevdtkZmaa5ORk891335lx48a5jnn44YfNd999Z/bu3WuOHTtmdu7cad544w3TvHlzj16r0+k0R48eNcYYc9dddxV4/JlnnjE//vijOXDggMnIyDDbtm0zzz//fJF3d+WW3LuZBgwYUOxxuXcz1atXr9DHhwwZYr7//nuTlpZmjh49arZu3WrmzZtnOnXq5Hbc6NGjza5du8yxY8fMxo0bzVVXXWViY2NLvJsJMOedd5557733zL59+1x1OGfOHBMZGek6ZsSIEWb79u3m+PHjbuco7D2uXLmymTx5somPjzeZmZkmISHBvPTSS6ZWrVpux8XHx5vFixcXeM354/b1PVBRKU1x5PxDREREJCjpbiYREREJakpmREREJKgpmREREZGgpmRGREREgpqSGREREQlqSmZEREQkqIXEpHlNmjQhLS3N7jBERETEC06ns8SlXSAEkpkmTZqUOIuqiIiIBKamTZuWmNBU+GQmt0WmadOmap0REREJEk6nk4SEBI+u3RU+mcmVlpamZEZERKQC0gBgERERCWq2JjPh4eFMnDiRHTt2kJ6ezvbt23n88cdxOBxux8XExJCQkEB6ejqxsbG0adPGpohFREQkENm2yuW4cePMvn37zJVXXmlatGhhBgwYYFJTU82IESNcx0RHR5vDhw+b6667zrRt29YsXLjQJCQkmBo1anj0HE6n0xhjjNPptH1VTxUVFRUVFRXPipfXb/sCXbx4sZk9e7bbvg8++MC89dZbru09e/aY6Oho13ZkZKRJSUkxw4YN80dlqKioqKioqARA8eb6bWs303fffUfv3r1p1aoVAO3ataNHjx58+eWXALRs2ZLGjRuzdOlS199kZWWxcuVKunfvXug5IyMjcTqdbkVEREQqLlvvZpo6dSq1atXi999/5+TJk4SHhzN+/HjeffddABo1agRAcnKy298lJyfTokWLQs85duxYJkyY4Ne4RUREJHDY2jIzcOBABg0axK233kqnTp0YPHgwjzzyCHfccYfbccYYt22Hw1FgX67JkydTs2ZNV2natKnf4hcRERH72doy8+yzzzJlyhTee+89AH755RdatGjB2LFjeeutt0hKSgKsFprcfwM0aNCgQGtNrqysLLKysvwfvIiIiAQEW1tmqlWrRnZ2ttu+kydPEhZmhRUfH09iYiJ9+/Z1PR4REUFUVBRxcXHlGquIiIgEJltbZhYvXsz48eP566+/+PXXX+nYsSOjRo1izpw5rmNmzpzJuHHj2Lp1K1u3bmXcuHGkp6fzzjvv2Bi5iIiIBBLbbruqUaOGmTFjhtm5c6dJT08327ZtMxMnTjQRERFux8XExJg9e/aYjIwMs2LFCtO2bVu/3NqloqKioqKiEhjFm+u3I+cfFZbT6SQ1NZWaNWtqbSYREZEg4c31W2sziYiIiM+uAhwlHuVfSmZERETEazWABcDnwKM2x2LrAGAREREJPh2A94FWwAngpK3RKJkRERERL9wPTAeqAH8BNwPf2xqRkhkRERHxQE1gNnBjzvZnwFDgoG0RnaIxMyIiIlKszsAGrETmODAKuJbASGRALTMiIiJSjBHAs0AksBMYCPxoZ0CFUDIjIiIiBdQG5gDX5Wx/BNwFHLIpnuKom0lERETc/AOrW+k6IBN4EBhAYCYyoGRGREREcjiAfwOrgDOA7UB34EUbY/KEuplERESEusCbwNU52+8Bw4BU2yLynFpmREREQtw/gY1Yicwx4D6s+WOCIZEBJTMiIiIhywGMAVYAzYA/sMbLvGZjTL5QN5OIiEgIOg14C7g8Z3s+1uy+R2yLyHdKZkRERELMxcBCoAmQjnW30hxbIyoddTOJiIiEiDDgceB/WInMFuBCgjuRAbXMiIiIhISGwAKgd872XGA4VstMsFMyIyIiUsH1xhoT0wg4ijU25m1bIypb6mYSERGpoMKBp4ClWInMZqALFSuRAbXMiIiIVEhNgHeAqJzt14GRWPPIVDRKZkRERCqYy7BaX04D0rBm8n3X1oj8S91MIiIiFUQl4BngK6xEZgPQmYqdyIBaZkRERCqE07GSln/mbL+EtWhkpm0RlR8lMyIiIkHuKqxFIusBh4G7gQ9sjah8qZtJREQkSEUAzwGfYyUya4FOhFYiA2qZERERCUotsLqVLsrZngmMBrLsCshGSmZERESCTH+sJQjqACnAUOBTOwOymbqZREREgkQk8ALwMVYi8wPQkdBOZEDJjIiISFA4E1gNjMjZfg5r9etdtkUUONTNJCIiEuBuAGYDtYADwGDgC1sjCixqmREREQlQlbHmi1mElch8B3RAiUx+SmZEREQCUCusMTEP5Gw/A1wC/G1XQAFM3UwiIiIB5hbgNcAJ7AVux1r5WgqnlhkREZEAURVrdet3sBKZFVjdSkpkiqdkRkREJACcB6wB7gGygSeBPkCinUEFCXUziYiI2OwO4GWgOpAE3Ab8z9aIgotaZkRERGxSDZiHtUhkdeAbrG4lJTLeUTIjIiJig/OxFoYcDJwEHgcuA5LtDCpIqZtJRESknN0F/AdrwG8CcCvwra0RBTdbW2bi4+MxxhQoL774ouuYmJgYEhISSE9PJzY2ljZt2tgYsYiIiO9qAPOxZvOtCizB6lZSIlM6tiYzXbt2pVGjRq7Sp08fABYtWgRAdHQ0o0aNYvjw4XTt2pWkpCSWLVtGjRo17AxbRETEa+2BdViDe08Ao4GrgP12BlWBmEApM2bMMFu3bnVt79mzx0RHR7u2IyMjTUpKihk2bJjH53Q6ncYYY5xOp+2vT0VFRUUlNMt9YDLAGDB/gekeADEFevHm+h0wA4AjIiIYNGgQc+bMAaBly5Y0btyYpUtPTRWUlZXFypUr6d69u11hioiIeKwm8B7wClAFWIzVrRRnY0wVUcAMAO7fvz+1a9dm3rx5ADRq1AiA5GT3cd3Jycm0aNGiyPNERkZSuXJl17bT6Sz7YEVERErQGSuROQs4jtWtNMPWiCqugGmZueuuu1iyZAmJie5zHRpj3LYdDkeBfXmNHTuW1NRUV0lISPBLvCIiIkV5EKv15SxgJ9ADJTL+FBDJTPPmzenTpw+zZ8927UtKSgJOtdDkatCgQYHWmrwmT55MzZo1XaVp06b+CVpERCSf2sCHwCwgEvgY6Aj8aGNMoSAgkpmhQ4eyd+9evvjiC9e++Ph4EhMT6du3r2tfREQEUVFRxMUV3duYlZVFWlqaWxEREfG3C4ENwPVAFjAi59+HbIwplNg6WtnhcJidO3eayZMnF3gsOjrapKSkmP79+5u2bduaBQsWmISEBFOjRg2/jIZWUVFRUVHxpYwCk4V1t9I2MJ0DIKZgL15ev+0Ntm/fvsYYY1q1alXo4zExMWbPnj0mIyPDrFixwrRt29aflaGioqKiouJxqQvmM6wkxoB5D0zNAIirIhRvrt+OnH9UWE6nk9TUVGrWrKkuJxERKTPdgXeBZsAx4CHgNTsDqmC8uX4HxJgZERGRYOHAus16JVYi8ydwEUpk7BQw88yIiIgEuvrAW8AVOdsLgPuAI7ZFJKBkRkRExCMXA+8ATYEMYDgwx9aIJJe6mURERIoRBjwG/A8rkfkN6IoSmUCilhkREZEiNATmA31ytucB/wLS7QpICqVkRkREpBCXYo2JaQQcBR7AGi8jgUfdTCIiInmEAROAZViJzGasbiUlMoFLLTMiIiI5GmMN8r0kZ/sNYCTWgF8JXEpmREREgH5Y42NOA9KAe4GFtkYknlI3k4iIhLRw4Bnga6xEZiPQGSUywUQtMyIiErJOx0paeuRsvwyMAjJti0h8oWRGRERC0pVYg3rrAYeBe4BFtkYkvlI3k4iIhJRKwLPAF1iJzFqgE0pkgplaZkREJGS0wFrp+qKc7ReAaCDLtoikLCiZERGRkHAtMBeoA6QAdwKf2BmQlBl1M4mISIUWCczASlzqAGuAjiiRqUiUzIiISIXVElgNPJSz/RzQE9hlV0DiF+pmEhGRCmkA8F+gFnAAGIw16FcqHrXMiIhIhVIZeAn4ACuR+Q7ogBKZikzJjIiIVBhnA99jrXANMBnoBfxtW0RSHtTNJCIiFcLNwOuAE9gH3I61RIFUfGqZERGRoFYFK4lZiJXIrMTqVlIiEzqUzIiISNA6D/gRaymCbOApoDewx86gpNypm0lERILS7cArQHUgCRgELLc1IrGLWmZERCSoVAPmYC0SWR0rgemAEplQpmRGRESCRlvgJ2AocBJ4HOgHJNsZlNhO3UwiIhIU7gT+g9Uyswe4BfjW1ogkUKhlRkREAloN4G2s2XyrAV9hdSspkZFcSmZERCRgtQPWYg3uPQGMAa7EmkdGJJe6mUREJCDdC8zEmkdmN1a30mo7A5KApWRGREQCSk2sSfAG5mx/jrVI5EHbIpJAp24mEREJGJ2AdViJzHHg38A1KJGR4qllRkREAsJw4DmsVa93Yq21tMbOgCRoKJkRERFb1ca6U+n6nO2PsW7DPmRTPBJ81M0kIiK26Qqsx0pksoAROf8+ZGNMEnyUzIiIiC0exro7qSWwHeiONSmeiLfUzSQiIuWqDjAPa2AvwCLgbiDVroAk6KllRkREyk03YCNWInMMuB+4CSUyUjpKZkRExO8cQDTWEgTNgT+Bi4BX7QxKKgx1M4mIiF/VB94CrsjZfgdrdt8jtkUkFY3tLTNNmjTh7bffZv/+/Rw9epQNGzbQqVMnt2NiYmJISEggPT2d2NhY2rRpY1O0IiLijZ5Y3UpXABlYY2NuQ4mMlC1bk5natWuzevVqjh8/zhVXXEGbNm3497//zaFDh1zHREdHM2rUKIYPH07Xrl1JSkpi2bJl1KhRw77ARUSkWGHAeCAWaAr8BlyINZ+MiD8Yu8rkyZPNt99+W+wxe/bsMdHR0a7tyMhIk5KSYoYNG+bRczidTmOMMU6n07bXqaKiohJKpQGYpWBMTpkHpnoAxKUSXMWb67etLTPXXHMNa9eu5f333yc5OZn169dz9913ux5v2bIljRs3ZunSpa59WVlZrFy5ku7duxd6zsjISJxOp1sREZHy0QvYBPQFjmItEDkk598i/mJrMnPmmWdy//33s3XrVi677DJeffVVZs2axe233w5Ao0aNAEhOTnb7u+TkZNdj+Y0dO5bU1FRXSUhI8O+LEBERwoAJwDdAI+AXrNl937IxJgkttjUhZWZmmtWrV7vte+GFF0xcXJwBTLdu3YwxxjRq1MjtmNdff90sWbKk0HNGRkYap9PpKk2aNFE3k4qKioofS2Mw/+NUt9LrYKoGQFwqwV2CppspMTGRLVu2uO377bffaN68OQBJSUkABVphGjRoUKC1JldWVhZpaWluRURE/KMv1t1KvYA04FZgGNadSyLlxdZkZvXq1Zx77rlu+8455xx27doFQHx8PImJifTt29f1eEREBFFRUcTFxZVrrCIicko4MAlYCjTASmg6AwttjElCm21NSF26dDFZWVlm7Nix5qyzzjK33HKLOXLkiLn11ltdx0RHR5uUlBTTv39/07ZtW7NgwQKTkJBgatSoUebNVCoqKioqJZemYL7lVLfSy2AqB0BcKhWreHn9tjfYq666yvz8888mIyPDbNmyxdx9990FjomJiTF79uwxGRkZZsWKFaZt27b+qgwVFRUVlWLKlWD2YSUxh8HcGAAxqVTM4s3125HzjwrL6XSSmppKzZo1NX5GRMRHlYBngEdzttdhLRC5w7aIpKLz5vqttZlERKRYzYF3sVa8BpiFldRk2RaRiDslMyIiUqRrgHlAHSAFuBP4xMZ4RApj+0KTIiISeCKAGcCnWInMGqAjSmQkMCmZERERNy2B1cBDOdvPYa1+vcuugERKoG4mERFxGYC1snUt4ADWukqf2xmQiAfUMiMiIlQGXgQ+wEpkVmN1KymRkWCgZEZEJMSdDcQB/8rZngJcAuy2KyARL6mbSUQkhA0E3gCcwD7gduBrWyMS8Z5aZkREQlAV4FWs+WOcwEqgA0pkJDgpmRERCTHnYt1qfS+QDUwEegN77AxKpBTUzSQiEkJuB14BqgNJwCBgua0RiZSeWmZEREJANWAO8BZWIrMcq1tJiYxUBEpmREQquDbAj8BQ4CTwBNAPSLYzKJEypG4mEZEKbCjW/DHVsMbE3Io12FekIlEyIyJSAVXHultpUM7211jjZfbZFpGI/6ibSUSkgmkHrMNKZE4AY4ErUCIjFZdaZkREKpBhwAtY88j8DdyMtTSBSEWmZEZEpAJwAq9jJS9grak0BGuxSJGKTt1MIiJBriOwHiuROQ48AlyDEhkJHWqZEREJYv8Cnsda9XoX1lpLa2yNSKT8KZkREQlCtYD/AgNytj8B7gRS7ApIxEbqZhIRCTJdgQ1YiUwWMBK4DiUyErqUzIiIBJGHgO+AlsAO4J/ALDsDEgkA6mYSEQkCdYB5WAN7ARYBdwOpdgUkEkDUMiMiEuC6ARuxEplM4AHgJpTIiORSMiMiEqAcwKPAt0BzYCtwEfCKnUGJBCB1M4mIBKD6wJvAlTnb7wD3Akdsi0gkcCmZEREJMD2Ad4GmQAYwAphta0QigU3dTCIiAcIBjANWYCUyvwP/QImMSEnUMiMiEgAaAG8D/XK238Ia6HvUtohEgoeSGRERm/UCFgCNsZKXf2GNlxERz6ibSUTEJmFADPANViLzC9bsvkpkRLyjlhkRERs0wrpDqVfO9mysgb4ZtkUkEryUzIiIlLO+wHyscTJHsG65fsfWiESCm0/dTB07duT88893bV9zzTV8/PHHTJo0iYiIiDILTkSkIgkHnga+wkpkNgGdUSIjUlo+JTOvvfYa55xzDgAtW7bk3XffJT09nRtvvJFp06aVaYAiIhVBU+B/wHisL95XsGbz/dPOoEQqEONtOXTokDnzzDMNYKKjo81XX31lANO9e3fz119/eX0+fxan02mMMcbpdNoei4qKSmiWK8DsA2PAHAZzUwDEpKIS6MWb67dPLTMOh4OwMOtP+/Tpw5dffgnA7t27qV+/vi+nFBGpcCoBU4EvsZYnWAd0At63MyiRCsinZGbt2rU89thjDBo0iKioKL744gvA6nJKTk4u0wBFRIJRM2AlEJ2zPQvoDmy3LSKRisunZOahhx6iU6dOvPjii0yaNInt263/njfccANxcXEenycmJgZjjFtJTEwscExCQgLp6enExsbSpk0bX0IWESk3/wdsxEpeDgHXAyOBLPtCEqnwyqx/q3LlyqZSpUoeHx8TE2M2b95sGjZs6Cr169d3PR4dHW0OHz5srrvuOtO2bVuzcOFCk5CQYGrUqOGXPjcVFRWV0pQIMNOxxsYYMGvAnBEAcamoBGPx5vpdqnlmIiIiaNCggWv8TK7du3d7fI4TJ04U2TX10EMPMWnSJD7++GMABg8eTHJyMrfeeiuvv/6674GLiJSxM4D3gAtztp8HxgLH7QpIJIT41M3UqlUrvv32WzIyMti1axfx8fHEx8ezc+dO4uPjvT5XQkICO3bsYOHChbRs2RKwxt80btyYpUuXuo7Nyspi5cqVdO/evcjzRUZG4nQ63YqIiD9dD2zASmQOYnUzPYISGZHy4lPLzNy5czlx4gRXX301iYmJGGN8evI1a9Zwxx138Oeff9KwYUMee+wx4uLiaNu2LY0aNQIo0GqTnJxMixYtijzn2LFjmTBhgk/xiIh4ozLwHDA8ZzsOuBnwvG1aRMqK1/1YR44cMeeee26Z949Vq1bNJCYmmocffth069bNGGNMo0aN3I55/fXXzZIlS4o8R2RkpHE6na7SpEkTjZlRUVEp83IWmHWcGh8zBUylAIhLRaWiFL/PM7Nlyxa/zCeTnp7O5s2badWqFUlJSQCuFppcDRo0KPb276ysLNLS0tyKiEhZGgisx5ozZh9wBTAGOGFnUCIhzKdkZvTo0UybNo2oqCjq1q1bZmNUIiMjad26NYmJicTHx5OYmEjfvn1dj0dERBAVFeXV7d8iImWlCvAq8C5QE/gW6IC11pKI2Mvrpp+TJ0+akydPmhMnTriV3H2enufZZ581F198sTnjjDPMhRdeaD777DNz+PBh07x5cwPWrdkpKSmmf//+pm3btmbBggW6NVtFRcWWcg6YjVhdSifBPAUmPADiUlGpqMXvt2b36tXLlz8r4PTTT2fhwoXUr1+fffv28cMPP3DRRRfx119/ATBt2jSqVq3Kyy+/TJ06dVizZg39+vXjyJEjZfL8IiKeuA2rRaYGkAwMAr6xNSIRycuBldVUWE6nk9TUVGrWrKnxMyLilarAi8CdOdv/w0pskmyLSCR0eHP99nnSvFq1anHXXXfRunVrjDFs2bKFOXPmkJqa6uspRUQCRhusBSHbAieBJ4FJQLadQYlIoXwaANy5c2e2b9/Oww8/TN26dalfvz6jRo1i+/btdOzYsaxjFBEpV0OAn7ASmUSgNzARJTIigczrQTnffvutmTNnjgkPD3ftCw8PN3PnzjUrV660fdBQ3qIBwCoqKp6W6mDe4tTcMV+BOS0A4lJRCcXi5fXb+ydIT08vdNK81q1bm6NHj9peAaWoDBUVlRAtF4D5DSuJOQFmLBhHAMSlohKqxe+T5qWmptK8efMC+5s1a6ZBtiISdO4BfgTOA/4GLgEmY31Likjg8ymZee+99/jvf//LTTfdxOmnn07Tpk0ZOHAgs2fPZuHChWUdo4iIXziBd4DXsSbE+wJrErzvbIxJRHzjddNPRESEmTlzpjl27JhrwryMjAwzffp0ExkZaXvTVN6ibiYVFZXCSgcwf2J1K2WBeQR1K6moBFLx5vpdqnlmqlatyllnnYXD4WDbtm1kZGT4eiq/0TwzIpLfA8B0rFWvd2GtdP2DrRGJSH7lMs8MQEZGBr/88ktpTiEiUm5qAbOBG3K2PwWGAim2RSQiZcHjZObDDz9kyJAhpKWl8eGHHxZ77IABA0odmIhIWeoCvAecCWQBjwKzbI1IRMqKx8nM4cOHMcbqkUpNTXX9W0Qk0I0EpgGRwA5gILDW1ohEpCxpbSYRqbDqAHOBa3O2PwDuBg7bFpGIeMqb67dPt2YvX76cWrVqFfrEy5cv9+WUIiJl6iJgA1Yikwn8C7gRJTIiFZFPycwll1xCZGRkgf1VqlShZ8+epQ5KRMRXDuAR4FugBbAVK7F52c6gRMSvvLqb6YILLnD9u02bNhw8eNC1HR4ezuWXX05CQkLZRSci4oV6wJvAVTnbC4F7AXUwi1RsXiUzGzduxBiDMYb//e9/BR7PyMjgwQcfLLPgREQ81QMreTkdyMAa9PuGrRGJSHnxKplp2bIlDoeDHTt2cOGFF7Jv3z7XY1lZWezdu5fs7OwyD1JEpCgOYAzwFNYX2u/ATcBmO4MSkXLlVTLz119/AVaXkoiI3U4D5gP9crbfwprd96htEYmIHXwaADxmzBiGDh1aYP/QoUOJjo4udVAiIiW5BNiElcikY83kOxglMiKhyKdk5t577+X3338vsP/XX3/lvvvuK3VQIiJFCQOeAL4BGgO/Ys3uO8/GmETEXj6tzdSoUSMSExML7N+3bx+NGzcudVAiIoVphNWt1Dtn+7/Ag1gDfkUkdPnUMrN7927++c9/Ftj/z3/+kz179pQ6KBGR/PoAG7ESmSPAIKzZfJXIiIhPLTOzZ89m5syZREREuG7R7t27N9OmTeP5558v0wBFJLSFAxOAcVi/vjZhra30h40xiUjgMb6UKVOmmPT0dHPixAlz4sQJc+TIEfP444/7dC5/FqfTaYwxxul02h6LioqKd6UpmJVgTE55BUyVAIhLRUXF/8Wb63epFpqsXr06rVu3JiMjg61bt5KVleXrqfxGC02KBKfLgbeB+kAqMAx4z9aIRKQ8eXP99qmbKdfRo0dZu3ZtaU4hIuKmEvA0MDpnex1Wt9J22yISkUDncTLz4YcfMmTIENLS0vjwww+LPXbAgAGlDkxEQk8z4F2ge872f7AWjQy8Nl8RCSQeJzOHDx/GGOP6t4hIWfo/rLli6gKHgLuAj2yMR0SCR6nGzAQDjZkRCWwRwBRgVM72j1jdSjtL+DtHWBhndmpPzdPqk7pvPzvWb8JobTjVS4Dx9/tRkd/vchszIyJSGmdgdSv9I2d7OtaikcdL+LsLekfRf8zD1G7U0LXvyMGDfDjxWX7+ZoUfIg0OhdXLoaRkPpkyg83LV9oYWWjy9/uh9/sUj1tm1q9f7+pmKknnzp1LE1OZUstMaKrIv1YCja91fR0wB6gNHASGAIs9eL4LekcxePpkwOAIc5/30xhD7Nz5fDHjZS9fhfcKe92AbZ+7ourFen4Hb44aG3IXODv5+/0IhffbLy0zn3zyievfVapU4YEHHmDLli18//33AFx00UW0bduWl1/2/5eISHH0a6X8+FLXkcBzWMsQAMQBtwB/efB8jrAw+o95mMISmVy9hg5i96+/8/PS/3n+QrxU2Os+mnIIgOp1arv2ldfnrrh6cYSFYbKzuXb0Q/wSu0pJfTnw9/uh97sgn8bMvPHGGyQmJvLEE0+47Z8wYQLNmjXjrrvuKqv4Sk0tM6ElFH6tBApP6vqX2FVuLRWOdRt51xhy226nAo8BJzx8zrO6dOSBuSX/YMo+eZK3Hn2czctivXtRHijydee0XDscjlP7yulz52m9fDJlBkcOppSq1UitniXz9P14eegDbF+7IeDOHyj8PmbmxhtvpEuXLgX2z58/n7Vr1wZUMiOho6x+rXj6ZV3UcaHwZe9JXd8QM9qt9eKcr76hz5bfqZKewX7gDmCJl89b87T6Hh0XFh7O4Ocn8ebDZZtEFPu68yQxeY/P/7nzx+fD03qxYrf40mrka6tnKPyfyMvT98PT48r7/MHIp2QmIyODHj16sG3bNrf9PXr04NixY2USmIi3zuzU3u1LNj9HWBh1GjfizE7ti/y14umXdVHHrf9yKZ2u7FduXVx2XSQ8qesadepgjKHSsWNETXuB9os+AeDvTu0ZWrUq36z+wevnTd2336vjy7qpvaTXXZi8n7tqtWoWMnA5hXWff8Wvsat8fv+8rReAWg1OY/D0yR63GuVtkfLmPKHY7evp++HL+1Ye5w9GPiUzM2fO5JVXXqFz58788IP1hXTRRRdx55138tRTT5VpgCKeKu2vFU+/rIs8rmEDeg0dBMa7L3tf2XmR8LSu6+78i6sfeYzT/tyGcThYc/dg4u4bykUHDrL88gFeX7ir1alN9smThIWHl3isw+EoMXn1Vml+6bbt1ZOLB91M/s9Njbp1iLrjFqLuuKXQ98+ThHXH+k0cSkqmVoPTCh1LZIwp0HLkbWulL62eviZAwa7E9yM7m0PJe12DxgPt/MGo8BF0JZg6dSp33HEHHTt2ZNasWcyaNYuOHTsyZMgQpk6dWtYxinikNL9WSvqyBsO1ox8irFKlErsZCv17Bwx4PJqwSmUzG0LuRaJWg9Pc9udeJC7oHVUmz1MUT+q69eKvuG3gUE77cxtH69bhw1dnEjfiXoiMdCUZ3rigdxSDn5tU5MDfopRlU3tpful2vvoyihu4DAXfvwt6R/HY1x/xwNyXGTTtKR6Y+zKPff1RgffXZGfzyZQZgKPwLtFCusDAvdWoqMfP6tKRfvffRe1GDYuMvbDzePp/ytv3MxgU937kjqP6dOpMn1sM/X3+YOTzp2jRokX06NGDevXqUa9ePXr06MGiRYvKMjYJEblfmB2v6MtZXTr6/OWW+2ulqP/AJjublMSkQn+t5HYflPRl/c+B1xd/XFEXDYcDZ726xCz/tNSJRiBcJIqr60oZx+j3xCSuGPckkRkZ/HVhZ+Z/8BZ/db/Q7Thvkgy311xEHRelqATEl89dSZ+xwpjsbNIOHKRG3bolPkfe9++Cvr28Slg3L1/Jm6PGcnjvPo9jy9W2V88C+/ImUv3uu9Oj8+R9Tz39P+VtUhssino/DiXvLZMWKX+fP9j4/DOxVq1a3HDDDZx55pk899xzpKSk0LFjR5KTk9mzZ09ZxigVUG7TedtePel89eXUqFvH9ZivXSW5v1YGT5/sGmiZ97Hifq14emGt3/x0r2LKr3rt2qVuXi+LsUGlVVRd190ez9WPPEb9bTswDgff338Xa4YNwRTSLeRNK4cvY1WKa2r3tYuu2M9YMXczrf/ia6LuuMWjuHPfvxseexRvu3U2L1/pdgdZjbp13Ab9FqXTVZex+PkXXecqqnuoJHnfUw1SLfh+lPW4Nn+fP5j49NPtggsu4M8//2T06NE8+uij1K5dG4DrrruOyZMnl2V8UgHl/cUXdcctbokMlK6rxNdfK55eWPf/9bfXMeVVFi0ngXKRyK3r9MOpALT55Atuu3ko9bft4Ej9eix6YxY/3H9XgUSmuBayonj7WopLXkvbRVfUZ+zooUOkH3Jfty73c/dr7Cqv4gdrLI0vrRomO5vtazewYckyvlv4AUcOHizxuZz16rrO5clcPoU9Z/73VINULXnfj+1rN5R5ouHv8wcLn1pmpk+fzrx58xg9ejSpqamu/UuWLOGdd97xKZAxY8YwefJkZs6cycMPn/olERMTw7Bhw6hTpw5r1qzhX//6F1u2bPHpOcR+nvziK+2kT778WvF0QN3q9z7ikiG3ejXQsrDXl7/lxJu7kgLpIvFL7CpuGnkflz07i7aLrRutd3a7kK+eiSG9ft0C9eFrf763r+VQ8l4+nTqzQPJaVrfvF/UZg8JnAHaEhRX7+fJVSUmeyc5m3eeetQrlnsvbVrCi3lMNUpXy5NP/qq5du/Laa68V2J+QkECjRo28Pl+XLl0YNmwYmza5f6ijo6MZNWoUw4cPp2vXriQlJbFs2TJq1KjhS9hSxrwdc+DNL77S9qd7+2vF0wF12SdOFH1cTjeDp8t+5F48PB3kmas0Y4PK2uXnncP9I8fQdvESssPC+G7EvXz06gzS69cFCo4h8rU/35uxKkcOHuSzaS8U+hxlOY6jsM9YUZ+7kgbo+sqTJM/TVqHcc3nbClbUe6pBqlKefEpmjh07Rs2aNQvsP/fcc9m3z7vBZ9WrV2fBggXcc889pKSkuD320EMPMWnSJD7++GN+/fVXBg8eTLVq1bj11lt9CVvKkLcXYCj5QlKY3C/WshokXJySuqh+iV3FWV06Uikykq9ffqPgcUnJxM6d75rWviSp+/b71OURKBeJu4GPfv+TevG7SGtwGovmvMSP9wyBQt6b795ZxMtDH2DS5QN8GitU7GvOlzxWr12bO55/ptC6s7OLrjQDdPPzJmH1Nvn1tBVs2atzSnxPNUhVyotPyxm89tprnHbaadx0000cPHiQdu3acfLkST755BO+/fZbt26iksybN4+DBw8yatQoYmNj2bhxIw8//DAtW7Zkx44ddOzYkY0bN7qO/+STTzh06BBDhgwp9HyRkZFUrlzZte10OklISNByBmXI1yUDOl7Rl0HTvJuH6OWhDxQ60Vh5T0R3fq+ehcbwwwefsv+vv926FMIqVSJm+adUr1272Ob1Z668kfFLPiixGX5SEfOxFDaINSUxqdDuldLIXx/71m3kVWPI7biI79GNJc88wbE8axLlV1bTqhf2mgtTVN0FwjTwufV5ydBBtLm4e4nHF9VV500y4M3/WUdYGI99/ZHPn8vChNoMwFI2/L6cwSOPPMKXX37J3r17qVq1KitXrqRRo0Z8//33jB8/3uPzDBw4kE6dOtG1a9cCj+V2VyUnJ7vtT05OpkWLFkWec+zYsUyYMMHjGMS7L5rSjDnwZtxD7hdmtTq1GfzcJMpz0q3croJcxU38ddkD9/DmqLFux2efOMEHT00r8a6qlh0uKNVdSeVxJ0P+5OG03/7gyofGUm9PItnh4awacS/rhtxWaGsMlG5cRGGfy9zX3OOWG4q9S6eouguEcRx5P1+eJDNHUw653+1XxHig4uS2kBRIyAs5V2nuCixK/v9TImXNp2QmLS2Nnj170qtXLzp16kRYWBjr169n+fLlHp/j9NNP54UXXqBfv35kZmYWeVz+JmSHw1HsmITJkyczffp013Zuy4wUzttbVM/q0tHnC3BJF5JcuV+Yn017gf6jH8LOlWF9Td48uXh0vKKvRzEU1+Xhz4uEWxJnDO3f+4ioaS9Q6fhxUhs35POpT5HUsV2xsfna5VXS5/LIwZRi/vqU/HXnjwt1Lm9bHzxNrJ658kZadrig1AmrN8mvN8mPSCDwOpkJDw/n2LFjdOjQgdjYWGJjfVuVtnPnzjRs2JB169adCqZSJS6++GKGDx/OueeeC1gtNElJSa5jGjRoUKC1Jq+srCyysrJ8iinUeDvV+AW9o7hxwliPzl3YBbi4C0leuV+Y6YdTbZ9PpTRzupR08bDrriRPLrp5k7jKR9PpF/MM5+SsQL3tkp4sfXo8x2rVKvZ5jqQc4sOJ07yemt+Tz2Vp6s4fF2pf5q3xNLHKPnGizD7f3iS/msNEgonXyczJkyfZtWsX4R6sjVKc5cuXc/7557vtmzt3Lr///jtTp05lx44dJCYm0rdvX9eYmYiICKKiohg9enSpnrssBHsfsLctDu36XMIdzz+Dp0OsirrYFHUhSTtwkPVffO222F5ZtFyUVmkHjBZ38SiLLg9vP4eeXnRzk7iGv2zhqkcep3bCHk5WqsS3o/7FhkEDwYNZePPfUeTJc3v6uXzmyhtLVXdleaEuKfn6+uU3CoyryhtHILeAqHtIgoVP3UxPP/00kydPZtCgQQXuQPLUkSNH+PXXX932HT16lAMHDrj2z5w5k3HjxrF161a2bt3KuHHjSE9P93kum7ISjKvA5r/oOcLDPW5xqFanNrc/OxFHmANrzHjRiruI5MZQKTKSheOegpwp/vN/yefeudTwzDM8em3+nE/Fn60npe3y8PZzWPRFt0GBlria9evRcf57XPz8i4SfOMHhpo35/LmnST6/jcevL+8dLJ62AnraEtaywwWl7i4qiwt1icmXMVw+fJhrX2Hvj1pARErPp2RmxIgRnH322ezZs4ddu3Zx9OhRt8c7d+5cJsFNmzaNqlWr8vLLL7smzevXrx9Hjhwpk/P7IhhXgS3sopft4Rdl2149ufj2mz1aD8dkG4qbdbWoC2/+wbb5jytqIrq8iZO3g5g9nezM3wNGff1l7u3nsPiLrjUO7YaYMfwSu4ra2dlM/eEnen31DQBb+1zC0ifHkVnT6dFryl8n3rQC5r9FvSi1GpzG+i+X2t6qUWLyle9zW9T7oxYQkdLx6dbsJ554otiZTp96yrvbb/3Jm1u7SuKPWxb9rchbMj2YqRbgyMEUqtep7dGxR1MOsejJKQUuIp7eFlpcrFD4mjdvjrLG8HjaQlFYspQ7L0z1PLcW5/17X29F90beBCvtwEEwBmf9eoUmZr58Dj29JXnn40/z70++oAVwIqISKx8ZwaZbbijQreQahG9KrhNvboducm4rj9YS+vHjxbz3xDNA2Xb5ensuX6YbCMTvCZFA5Ldbs6tWrcqzzz5L//79iYiIYPny5Tz44IMcOHCgVAEHi0BY4M8bxf4iLiE5MdnZHEk5hLNeXY+f761/j2fbT+s9jyHPr/JfV64uNtb8d7Dl/voGPG6hKKo1o1rtggNZ8/+9v1sAcn+ZX9A7ilsmPV5sYubL57DEsT/Z2XR+ayEjF39FOLANGN+hHRfefIOVsBSSSMbOm0+nK/uVWCfejDs64uGEg20u6en6/JRVq4Yv3ce+dC8G2veESEXgVTLz5JNPMmTIEBYsWEBGRga33norr7zyCjfddJO/4gsogbLAn6d8WWkYTnUXebrSb+4vze3rNnodQ+4X+00TxnrUXL/stTkcPZRK9dq1aNr6HLrd2B9Pui8ArxK7/H9fXnO6eJKY+fI5LO6iWyXlEJc/NpEzv40D4PM6tbk15RBpP63ntxKSuC9feLXEOvHHuKMadWqXaTLga/exp9MNFCZQvidEKgKvkpnrr7+eu+66i/feew+ABQsWsHr1asLCwjwegxHMAmmBP0/4+mWZfvgwi56cQvrhVI+SmeIGW3oaQ9drr/TouJ6DBlKlenWPjs2/zo63iV3+X9D+HNfgzbgSXz6HO9Zv4uihw1TP1wrVZP0mrop+AmfyXk5ERhI75mGe+HEdaTnjZUpK4jypkx3rN3E05RDVatcqfOyTMRw9dMg1xqawOAtTVslAaSaC9HS6gcIEyveESEXg1U+JZs2asWrVqUXLfvrpJ06cOEGTJk3KPLBAFEgL/HnC1y/Lt/49ns3LV3q0uF/2yZO89e9xZdoMX5zK1ap5/Tc1T6tfqgtfefyC9mYBRF8+hyY7m1Xz3zt1UHY2XWe/yU13/gtn8l4OntGcd975L5tv7E/q/gMFzufNop3ecjgcVKtVi/N7RxWMsxhl9dkq7eKTRa0/VNTknoH2PSFSEXiVzISHhxeYkO7EiRNUquTTTVFBJ/dXmN0L/HnKm5WG4dSXbG53UbGv1xiMMbz16OP8/M2KMouhyNhyns+Tgcj5pe7bX6oLX3n8gvam68jXz+E3b7zJ0ZRDVNl/gOvvH0XPF14l7ORJtlx9OQvem8u+Vmf65SJ7Zqf2JQ4iDwsLY/Dzk7igd5QrzvJKBsqi+3jz8pU8fdn1vDz0AeZHP8FXL75uTZwcBN8TIhWBV8mMw+Fg3rx5fPjhh65SpUoVXn31Vbd9FVkwrQJbUjKS/9jCvmSLfL1Jybz58Fg2Lyt+BujiYvDmdTgcDq8TmbwXPV+SqvL8Be1t15Evn0OTnU38Q2O446YhnBG3huNVKvP1U+P56pknyKpSBX9dZL1p2bp29EMALHpySrklA2XVfZy3BWvZa3OD5ntCpCLw6tbsOXPmeHTcnXfe6Ws8Za4sb83OK5hmAC50npmTJwnLM4tzSastl/b1erracWGOpByiRjErMhemsFuEfb31uzwuPL7e9u/p+xIGjAdigHBgb4tmLJk5hQNnnwn4Z7XtXJ7emp0rd8Xq8lwV3F9TLgTT94RIoPHm+u3TPDPBxF/JTHkqiy/E/OeI37i5TBav8yWGVv/oQt/7Sk54l706h61r1uIIC+P+/77o1XMVddEr7AJ5JCUFBw63eWb8eXEvir/ms2kILAB652zPAUY4HDTq3KFc3v+SkoX85kc/wYYly1x/Wx7JQHnMJSQi3lEyk0ewJzMX9O3FDY89So26dVz7An3phJJ4+0vYdXzDBkV2NRljOHIwhc+mvcDhvfvKbAbg8lbWrRG9sRKZhsAR4H5ggQ2tBbnJgrUkRvFyW2bKW3m1BImIZ5TM5BHMycxVDz9Ar6GDClzAjTFgCOpfi97+EnYd7yg4L0xuN9GbDwdvfeRVFq0R4VhdSuOxuph+Bm4CIv24rpgjLIyzOnfg7As7Y4DtP613u/upXZ9LuP25p926N/MKhJlx1S0kEjiUzOQRrMlMuz6XcMf0nOnai5ib41BSclBPie7tL+ELekdxY8wYt+4gsMbUfFDIMgqhqgnwDhCVs/0a8BDQyo9dKUW9N/mXuLigby8GPz8JsHeMkogEPiUzeQRjMuMIC2NC7GJq1C15KQG7muTLire/hEv69R/qLgPeBk4D0oB7gPfw7yBXb1vN1J0jIp7w29pMUj7O7NTeo0QGAn9K9JKSFW9n1TXZ2Wz7aX2BNaBCXSVgIjAmZ3s9MBBrjSXw37pirtlzC0lk4NS6WteOftg1g255LA0hIqFFyUwA8iZBCeQp0X1ZuE+8dzrwLvDPnO0XgUeAzDzH+GtdMU/W/3I4HNRp3NAtUfLn0hAiEnq8WxlNyoWnCUp6airxGzf7ORrf5HY91Gpwmtv+3IX7LugdVcRfijeuBjZiJTKHgAHAg7gnMuC/dcW8SX4CvRVRRIKXkpkA5OlstdVq1mT8kg8CLjEoaeE+MFw7+iGvVxmWUyKA54DFQD3gR6AT8FERx3u6zlb1unU4q0tHOl7Rl7O6dCzxPfIm+Uk7cNCrc/uTIywsYGIRkdLTAOAAVdSty/kF4l0gns74GuyDl+1yBla30j9ytmcAo4HjJfxdSZ+pwmZCLqlb0NM5gNIPHeZ4ZmZAdDmq+1MkOHhz/dbPkQBV1No7+QViS4e/xmf4Q6D+Qi8qrv7ABqxEJgW4FhhFyYkMWJ+pt/49rsgFHAtLRjzpFvzhg0+BwleJzt1XrVatgOhyVPenSMWkAcABLPeujx633JDTbVM4X+9E8Rd/jc8oa4H6C72wuNL++puz732I2/5OAOB74GbgLy/PffTQ4SInrYOCCY0jLAyTnc21ox9y3Y1UXJyFPZ8DqFarZqFdjkWd2x9K6v4sz1hEpGwFxs9QKZLJzubIwRSPjg2Elg4oeXxGea5GXZRA/YVeWFy1dv/NvY8+5kpkXm/YgCiHw+tEBnz7jORNlouLE6z31mQbNn29nFfuGs7b/x5P9Tq1i2zxKuzc/pJ751UgxCIiZUvJTBAIlpaOXCY7m0+mzAAcBRKa3DE+n06daeuU9eUxQNnbLqzC4jrnq28YdONgGm35g4zatfj4pec48s2njFn6sU8JV2k+I7mJkCf117xdW7av3YCzfj2vzu1PwdT9KRIMAqmbXt1MQSC3paOk2VvtbOnIL3fMT4FunOS9ts/06q8J5PLypQsrb1zhmZlcMu0F2r//MQB/d2rPl1Of4kijBsCpFqQ3HxlPesohjyefK+mzVJzcRMib+gukRDyQYhEJdoHWTa9kJgjktnQMnj7ZtYp03sfsbukoSqDO9OrvX+h57xrKy5WAFHHnWe7z1d75F1c/8hgN/tiKcTj48e47iHvgbkylU/9dHWFhGGO449mJbmNgSvoyKfazZEzh64DlS5a9qb+NXy8PmEQ8GH8UiAQiX7/j/EndTEGiqLubDiXvDajbsvPLnel1w5JlAbOGkj9/oZemCyt1337O+/xrBt00hAZ/bCW9bh0+enUGq0fc55bIuM7ncBQYzOvJmJ/i7pQrrlsQrNvuG5x5RpHnzv96AqnLMZBiEQlWgTqPmOaZCTLeLswoBflz0UVf59ipCvwHuCtne3fXTnw59UmO+tA65Gn8+T9L1WvX4trRDxW6ACRQoEm5pJacvM8fSItLBlIsIsGmPOcR00KTFZjWtCk9f3bb+dKF1Rp4HzgfyAZ+uO9Ofhg2BCIivH5+8HzMT2Gfpc3/+7ZAsnx+r56FNilDwYSmqPoLpC7HQIpFJNgE6kB6JTMSkvw1QNnbLqzBwEtAdSARuA3Yv3U7/Q8cLHEBx5L48mWSP8Eptkk5Z0XsvIqrv0BKxAMpFpFgEqgD6ZXMSMjyxy90TweZJq/byDysZAZgGTAI2AuQJ662vXpy8e03gyl+WYvClMWXSYl3LuW0yix7dQ5b16xVC4dIBReoA+k1AFhCWlkPUPZkkOmWx5/mR2MYDJwExgOXkZPI5Ivrs2dn8ebDBQfrZp88WS6TEnraupO8Y2fADPAWEf8J1IH0apkRKWNFdmElJRM+cgzzf/+TqkACcAuwyoPz5W9Bql67Fnc8/4zfb9UP1CZlEbFPIM4jpruZRPwk791CJ5OSGb3hZ27NeexLrC6m0qQA5XFXjj/v/BKR4Obvu2u9uX4rmRHxs/ZYdyudA5wAxgHPUTb/8crjVv28E2QV1goUyPMciUjwUjKTh5IZsdN9wAygCtYK1zdjrXgdbDQ3i4iUNyUzeSiZETvUBN4AbsrZ/gwYAni2/nlg0oSNIlKeNGmeiI06A+8BZwFZwGhgpp0BlRHNzSIigUrJjEgZGgE8C0QC8cBA4CdbIxIRqfiUzIiUgdrAHOC6nO0PsdZZOmxXQCIiIUST5omU0oXABqxEJhMYDtyAEhkRkfKiZEbERw5gFPAdcAawDeiOtdaSiIiUH1uTmfvuu49NmzZx+PBhDh8+TFxcHJdffrnbMTExMSQkJJCenk5sbCxt2rSxKVqRU+pi3aH0PBABvAt0AtbbGZSISIiyNZn5+++/GTNmDF26dKFLly7873//49NPP3UlLNHR0YwaNYrhw4fTtWtXkpKSWLZsGTVq1LAzbAlx3YGNwNXAMeBerGUJdOO/iIh9TCCVAwcOmDvvvNMAZs+ePSY6Otr1WGRkpElJSTHDhg3z+HxOp9MYY4zT6bT9takEd3GAGQ3mOBgD5ncw7QIgLhUVFZWKWLy5fgfMmJmwsDAGDhxI9erV+f7772nZsiWNGzdm6dKlrmOysrJYuXIl3bt3L/I8kZGROJ1OtyJSWqdhrac0BesWwLex5pP52c6gREQECIABwOeffz5paWlkZmby6quvct111/Hbb7/RqFEjAJKTk92OT05Odj1WmLFjx5KamuoqCQkJfo1fKr6LsbqVLgfSgTuBO4CjNsYkIiKn2J7M/PHHH3To0IGLLrqIV155hTfffJPWrVu7HjfGuB3vcDgK7Mtr8uTJ1KxZ01WaNm3qt9ilYgsDHgP+BzQBtgBdgbl2BiUiIgXYPmne8ePH2b59OwDr1q2ja9eujBw5kqlTpwLQqFEjkpKSXMc3aNCgQGtNXllZWWRlZfk3aKnwGgLzgT4523OAB7FaZkREJLDY3jKTn8PhoHLlysTHx5OYmEjfvn1dj0VERBAVFUVcXJyNEUpFdylWt1IfrK6k27Fm81UiIyISmGxtmZk0aRJLlixh9+7dOJ1Obr75Zi655BLXXDMzZ85k3LhxbN26la1btzJu3DjS09N555137AxbKqhw4AmsrqUwrMG9NwF/2BmUiIiUyNZkpmHDhrz99ts0btyYw4cP8/PPP3P55ZfzzTffADBt2jSqVq3Kyy+/TJ06dVizZg39+vXjyJEjdoYtFVBjYCEQlbP9GvAQ1jwyIiIS2BxY92hXWE6nk9TUVGrWrElamqY1k4Iuw7rV+jSsie/uAd6zNSIREfHm+h1wY2ZEyks48AzwFVYiswFrSQIlMiIiwcX2u5lE7HA6VrdSj5ztF4FHsFa9FhGR4KJkRkLOVcCbQD3gMNadSh/aGpGIiJSGupkkZEQAzwKfYyUyPwEdUSIjIhLs1DIjIaEF8C5wUc72DGAMoOkVRUSCn5IZqfCuxVqCoA6QAgwBPrMzIBERKVPqZpIKKxKYCXyClch8D3RAiYyISEWjZEYqpDOB1cDInO1pWKtf/2VbRCIi4i/qZpIK5wZgNlAL2A8MBr60NSIREfEntcxIhVEZeAlYhJXIrMLqVlIiIyJSsSmZkQqhFfAD8EDO9jNALyDBtohERKS8qJtJgt4tWAtDOoG9wO3AUlsjEhGR8qSWGQlaVYHXgXewEplYrG4lJTIiIqFFyYwEpfOANVgrXGcDTwJ9gEQ7gxIREVuom0mCzh3Ay0B1IAm4FatVRkREQpNaZiRoVMOayfdNrERmGdAeJTIiIqFOyYwEhbZYC0MOAU4C44HLsQb8iohIaFM3kwS8u4D/YA34TcC6e2mVrRGJiEggUTIjAasG8CpwW872EqzxMvtti0hERAKRupkkILUH1mIlMieA0cBVKJEREZGC1DIjAec+YAZQBWthyJuxVrwWEREpjJIZCRg1sSbBG5iz/RkwFDhoW0QiIhIM1M0kAaETsB4rkTkOjAKuRYmMiIiUTC0zYrvhwHNYq17vxEpofrQzIBERCSpKZsQ2tYH/AtfnbH+EdRv2IZviERGR4KRuJrHFhVjdStcDmVitMwNQIiMiIt5TMiPlbhTwHdAS2AZ0B16yNSIREQlm6maSclMXmAf8X872e8AwINWugEREpEJQy4yUi+7ABqxE5hjWXDI3o0RGRERKT8mM+JUDa/belUBz4A/gH8BrdgYlIiIVirqZxG/qA28BV+RszwfuB47YFpGIiFRESmbEL3oCC4GmQDrwIDDH1ohERKSiUjeTlKkwYDwQi5XIbMG6DVuJjIiI+ItaZqTMNAAWAH1ytudizR+TbltEIiISCpTMSJm4FCuRaQQcxRob87atEYmISKhQN5OUShgwAViGlchsBjqjREZERMqPWmbEZ42xWmN65Wy/DozEmkdGRESkvCiZEZ/0w2p9aQCkYc3k+66tEYmISKhSN5N4JRx4BvgaK5HZgNWtpERGRETsYmsyM2bMGH788UdSU1NJTk7m448/5pxzzilwXExMDAkJCaSnpxMbG0ubNm1siFZOB1YAY3O2XwK6AVvtCkhERASbk5moqCheeuklLrroIvr27UulSpVYunQp1apVcx0THR3NqFGjGD58OF27diUpKYlly5ZRo0YNGyMPPVcCG4EewGHgRqzbrjNtjElERCSXCZRSv359Y4wxPXv2dO3bs2ePiY6Odm1HRkaalJQUM2zYMI/O6XQ6jTHGOJ1O219fMJZKYKaBMTnlJzBnBkBcKioqKioVu3hz/Q6oMTO1atUC4ODBgwC0bNmSxo0bs3TpUtcxWVlZrFy5ku7du9sSYyhpDqwCHs3Zngn8E9hhV0AiIiKFCKi7maZPn86qVav49ddfAWjUqBEAycnJbsclJyfTokWLQs8RGRlJ5cqVXdtOp9NP0VZs12LN4FsHSAGGAp/aGpGIiEjhAqZl5sUXX6Rdu3bccsstBR4zxrhtOxyOAvtyjR07ltTUVFdJSEjwS7wVVQQwA/gEK5H5AeiIEhkREQlcAZHMzJo1i2uuuYZevXq5JR9JSUnAqRaaXA0aNCjQWpNr8uTJ1KxZ01WaNm3qv8ArmJbAauChnO1nsVa/3mVXQCIiIh6wPZn5z3/+w/XXX8+ll17Kzp073R6Lj48nMTGRvn37uvZFREQQFRVFXFxcoefLysoiLS3NrUjJBmDNGdMVOABcBUQDJ+wMSkRExEO2jVR+6aWXTEpKirn44otNw4YNXaVKlSquY6Kjo01KSorp37+/adu2rVmwYIFJSEgwNWrUKPPR0KFYKoN5kVN3K60Cc3oAxKWioqKiEtrFy+u3fYEWZfDgwW7HxcTEmD179piMjAyzYsUK07ZtW39VRkiVs8Gs51QiMwlMeADEpaKioqKi4s3125HzjwrL6XSSmppKzZo11eWUx81YC0M6gb3A7cDSYv9CRESk/Hhz/bZ9zIyUryrAa8BCrERmBdABJTIiIhK8lMyEkHOBH7FWuM4GngT6AIl2BiUiIlJKATVpnvjP7cArQHUgCbgN+J+tEYmIiJQNtcxUcNWAOcBbWInMN1jdSkpkRESkolAyU4G1wepWGgqcBB4DLgMKn25QREQkOKmbqYK6E/gPVstMAnAr8K2tEYmIiPiHkpkKpgbW2JhBOdtLgDuA/bZFJCIi4l/qZqpA2gFrsRKZE8BorGUJlMiIiEhFppaZCmIY8ALWPDK7sSbFK3z1KhERkYpFyUyQcwJvAANzthcDQ4CDdgUkIiJSztTNFMQ6AeuxEpnjwCjgGpTIiIhIaFHLTJAaDjwHVAZ2YiU0P9oZkIiIiE2UzASZWsB/gQE52x9j3YZ9yK6AREREbKZupiDSFdiAlchkAg8C16NERkREQpuSmSDxMLAaaAlsB7oDL9oakYiISGBQN1OAqwPMwxrYC/A+cA+QaldAIiIiAUYtMwGsG7ARK5E5BtyHNdBXiYyIiMgpSmYCkAN4FGstpebAn8BFwGt2BiUiIhKg1M0UYOoDbwJX5mwvwGqROWJbRCIiIoFNyUwA6QksBJoCGVhzycyxNSIREZHAp26mABAGjAdisRKZ37Buw1YiIyIiUjK1zNisATAf6JuzPQ/4F5BuV0AiIiJBRsmMjXphjYlpDBwFHgDesjUiERGR4KNuJhuEAROAb7ASmc1AF5TIiIiI+EItM+WsMVZrTK+c7TeAkVgDfkVERMR7SmbKUV+s8TENgDTgXqy7l0RERMR36mYqB+HA08BXWInMRqAzSmRERETKglpm/KwpVtLSM2f7ZWAU1qrXIiIiUnpKZvzoCqxBvfWBw1gLRC6yNSIREZGKR91MflAJmAp8iZXIrAU6oURGRETEH9QyU8aaA+9irXgN8AIQDWTZFpGIiEjFpmSmDF0DzAXqAinAUOBTWyMSERGp+NTNVAYigBlYiUtd4AegI0pkREREyoOSmVJqCawGHsrZfg64GNhlV0AiIiIhRt1MpXA91srWtYADwGDgC1sjEhERCT1qmfHRROBDrETmO6ADSmRERETsoGTGR2uAbGAy1jpLf9sbjoiISMhSN5OPPgdaA3/aHYiIiEiIU8tMKSiRERERsZ+SGREREQlqtiYzPXv25LPPPiMhIQFjDNdee22BY2JiYkhISCA9PZ3Y2FjatGljQ6QiIiISqGxNZqpXr86mTZsYPnx4oY9HR0czatQohg8fTteuXUlKSmLZsmXUqFGjnCMVERGRQGYCoRhjzLXXXuu2b8+ePSY6Otq1HRkZaVJSUsywYcM8Pq/T6TTGGON0Om1/jSoqKioqKiqeFW+u3wE7ZqZly5Y0btyYpUuXuvZlZWWxcuVKunfvXuTfRUZG4nQ63YqIiIhUXAGbzDRq1AiA5ORkt/3JycmuxwozduxYUlNTXSUhIcGvcYqIiIi9AjaZyWWMcdt2OBwF9uU1efJkatas6SpNmzb1d4giIiJio4CdNC8pKQmwWmhy/w3QoEGDAq01eWVlZZGVleX3+ERERCQwBGzLTHx8PImJifTt29e1LyIigqioKOLi4myMTERERAKJrS0z1atX5+yzz3Ztt2zZkvbt23Pw4EF2797NzJkzGTduHFu3bmXr1q2MGzeO9PR03nnnHRujFhERkUBj221XUVFRpjBz5851HRMTE2P27NljMjIyzIoVK0zbtm39dmuXioqKioqKSmAUb67fjpx/VFhOp5PU1FRq1qxJWlqa3eGIiIiIB7y5fgfsmBkRERERTwTs3UxlTZPniYiIBA9vrtsVPpnJrQxNniciIhJ8nE5nid1MFX7MDECTJk08Hi/jdDpJSEigadOmIT/GRnXhTvXhTvVxiurCnerjFNWFO2/rw+l0smfPnhKPq/AtM4BHFZFfWlqaPng5VBfuVB/uVB+nqC7cqT5OUV2487Q+PK0zDQAWERGRoKZkRkRERIKakpl8MjMzmTBhApmZmXaHYjvVhTvVhzvVxymqC3eqj1NUF+78VR8hMQBYREREKi61zIiIiEhQUzIjIiIiQU3JjIiIiAQ1JTMiIiIS1EIymenZsyefffYZCQkJGGO49tprCxwTExNDQkIC6enpxMbG0qZNGxsi9b8xY8bw448/kpqaSnJyMh9//DHnnHNOgeNCpT7uu+8+Nm3axOHDhzl8+DBxcXFcfvnlbseESl3kN2bMGIwxzJgxw21/qNRHTEwMxhi3kpiYWOCYUKiLXE2aNOHtt99m//79HD16lA0bNtCpUye3Y0KlTuLj4wt8PowxvPjii65jQqUuwsPDmThxIjt27CA9PZ3t27fz+OOP43A43I4r6/owoVYuv/xyM3HiRHPdddcZY4y59tpr3R6Pjo42hw8fNtddd51p27atWbhwoUlISDA1atSwPfayLkuWLDGDBw82bdq0Me3atTOLFy82O3fuNNWqVQvJ+rj66qvNFVdcYVq1amVatWplnn76aZOZmWnatGkTcnWRt3Tp0sXs2LHDbNy40cyYMSMkPxsxMTFm8+bNpmHDhq5Sv379kKwLwNSuXdvEx8ebOXPmmK5du5oWLVqYSy+91Jx55pkhWSf169d3+2z07t3bGGNMVFRUyNXFuHHjzL59+8yVV15pWrRoYQYMGGBSU1PNiBEj/PnZsP+F21kKS2b27NljoqOjXduRkZEmJSXFDBs2zPZ4/V3q169vjDGmZ8+eqo+ccuDAAXPnnXeGbF1Ur17d/PHHH6Z3794mNjbWLZkJpfqIiYkxGzZsKPLxUKoLwEyePNl8++23xR4TanWSt8yYMcNs3bo1JOti8eLFZvbs2W77PvjgA/PWW2/5rT5CspupOC1btqRx48YsXbrUtS8rK4uVK1fSvXt3GyMrH7Vq1QLg4MGDQGjXR1hYGAMHDqR69ep8//33IVsXL730El988QXLly932x+K9dGqVSsSEhLYsWMHCxcupGXLlkBo1sU111zD2rVref/990lOTmb9+vXcfffdrsdDsU5yRUREMGjQIObMmQOEXl1899139O7dm1atWgHQrl07evTowZdffgn4pz5CYqFJbzRq1AiA5ORkt/3Jycm0aNHCjpDK1fTp01m1ahW//vorEJr1cf755/P9999TpUoVjhw5wnXXXcdvv/1Gt27dgNCqi4EDB9KpUye6du1a4LFQ+2ysWbOGO+64gz///JOGDRvy2GOPERcXR9u2bUOuLgDOPPNM7r//fqZPn84zzzzDhRdeyKxZs8jMzOTtt98OyTrJ1b9/f2rXrs28efOA0Pu/MnXqVGrVqsXvv//OyZMnCQ8PZ/z48bz77ruAf+pDyUwRjDFu2w6Ho8C+iubFF190ZdD5hVJ9/PHHH3To0IHatWszYMAA3nzzTaKiolyPh0pdnH766bzwwgv069ev2KnHQ6U+vvrqK9e/f/nlF77//nu2b9/O4MGD+eGHH4DQqQuwWi7Xrl3L+PHjAdi4cSNt27bl/vvv5+2333YdF0p1kuuuu+5iyZIlBQaIh0pdDBw4kEGDBnHrrbfy66+/0qFDB2bOnMmePXt46623XMeVZX2omymfpKQk4FTmmKtBgwYFssiKZNasWVxzzTX06tWLhIQE1/5QrI/jx4+zfft21q1bx7hx49i0aRMjR44Mubro3LkzDRs2ZN26dRw/fpzjx49zySWXMGLECI4fP+56zaFSH/mlp6ezefNmWrVqFXKfDYDExES2bNnitu+3336jefPmQGh+dwA0b96cPn36MHv2bNe+UKuLZ599lilTpvDee+/xyy+/MH/+fGbMmMHYsWMB/9SHkpl84uPjSUxMpG/fvq59ERERREVFERcXZ2Nk/vOf//yH66+/nksvvZSdO3e6PRaK9ZGfw+GgcuXKIVcXy5cv5/zzz6dDhw6u8tNPP7FgwQI6dOjAjh07Qqo+8ouMjKR169YkJiaG3GcDYPXq1Zx77rlu+8455xx27doFhO53x9ChQ9m7dy9ffPGFa1+o1UW1atXIzs5223fy5EnCwqyUw1/1YfvI5/Iu1atXN+3btzft27c3xhjz0EMPmfbt25tmzZoZsG4ZS0lJMf379zdt27Y1CxYsqLC30L300ksmJSXFXHzxxW63FVapUsV1TCjVx6RJk0yPHj1MixYtzPnnn2+efvppc+LECdOnT5+Qq4vCSv67mUKpPp599llz8cUXmzPOOMNceOGF5rPPPjOHDx82zZs3D7m6AOt2/aysLDN27Fhz1llnmVtuucUcOXLE3HrrrSH5+QCMw+EwO3fuNJMnTy7wWCjVxdy5c83u3btdt2b379/f7N2710yZMsWf9WH/Cy/vEhUVZQozd+5c1zExMTFmz549JiMjw6xYscK0bdvW9rj9UYoyePBgt+NCpT5mz55t4uPjzbFjx0xycrJZtmyZK5EJtboorORPZkKpPnLnwcjMzDR///23+eCDD0zr1q1Dsi5yy1VXXWV+/vlnk5GRYbZs2WLuvvvuAseEUp307dvXGGNMq1atCn08VOqiRo0aZsaMGWbnzp0mPT3dbNu2zUycONFERET4rT4cOf8QERERCUoaMyMiIiJBTcmMiIiIBDUlMyIiIhLUlMyIiIhIUFMyIyIiIkFNyYyIiIgENSUzIiIiEtSUzIhISImPj2fkyJF2hyEiZUjJjIgUyxhTbJk7d67dIYpIiKtkdwAiEtjyrmw7cOBAnnrqKbcFBjMyMtyOr1SpEidOnCi3+ERE1DIjIsVKTk52lcOHD2OMcW1XqVKFw4cPc+ONNxIbG0tGRgaDBg0iJiaGDRs2uJ1n5MiRxMfHu+0bMmQIW7ZsISMjg99++43777+/yDiGDRvG33//jcPhcNv/6aefMm/ePADOPPNMPvnkE5KSkkhLS+PHH3+kd+/eRZ6zRYsWGGNo3769a1+tWrUwxhAVFeXa17p1a7744gvS0tJISkrirbfeol69eq7HBwwYwM8//0x6ejr79+9n2bJlVKtWrehKFZEypWRGREpt6tSpzJo1i9atW/P111979Dd33303kyZNYvz48bRu3Zpx48YxceJE7rjjjkKPX7RoEfXr16dXr16ufbVr1+ayyy5jwYIFANSoUYMvv/ySPn360LFjR77++msWL15Ms2bNfH5tjRo1YuXKlWzcuJEuXbpw+eWX07BhQ95//33X4wsXLmTOnDm0bt2aSy65hI8++qhA0iUi/mX7CpsqKirBUQYPHmxSUlJc2y1atDDGGDNixAi342JiYsyGDRvc9o0cOdLEx8e7tnft2mVuvvlmt2PGjx9vVq9eXeTzf/LJJ2b27Nmu7Xvuucfs2bPHhIWFFfk3v/zyi/nXv/7l2o6PjzcjR450i799+/aux2vVqmWMMSYqKsoA5sknnzRfffWV2zmbNm3qWh25Y8eOxhhjmjdvbvv7o6ISqkUtMyJSamvXrvXq+Pr169O8eXP++9//kpaW5iqPPfYYZ511VpF/t2DBAgYMGEBkZCQAt912G++++y7Z2dkAVKtWjalTp/Lrr7+SkpJCWloa5513Hs2bN/f5tXXu3JlevXq5xfn7778DcNZZZ7Fp0ya++eYbNm/ezPvvv8/dd99N7dq1fX4+EfGeBgCLSKkdPXrUbTs7O7tAN0tERITr32Fh1u+oe+65hzVr1rgdd/LkySKfZ/HixYSFhXHVVVfx008/0bNnT0aNGuV6/Nlnn+Wyyy7jkUceYdu2bWRkZPDBBx+4kp/8cpOgvLHmjTM31sWLFzN69OgCf5+YmEh2djZ9+/ale/fu9OvXjwcffJBJkybxj3/8g507dxb5WkSk7CiZEZEyt2/fPre7oAA6dOjg+vfevXv5+++/OfPMM3nnnXc8Pu+xY8f46KOPuO222zj77LP5888/Wb9+vevxnj17Mm/ePD755BMAqlevzhlnnFFsnACNGzdm48aNBeIEWL9+PQMGDGDnzp3FJlpxcXHExcXx1FNPsWvXLq677jpmzJjh8WsTEd8pmRGRMrdixQpOO+00oqOj+eCDD7j88su54oorSE1NdR0zYcIEZs2aRWpqKkuWLKFy5cp06dKFOnXqFJsELFiwgMWLF9O2bVvmz5/v9ti2bdu4/vrrWbx4McYYJk6c6GoFKsyxY8f4/vvvGTNmDDt37qR+/fo8/fTTbse89NJL3HPPPSxcuJBnn32W/fv3c/bZZ3PzzTdzzz330KVLF3r37s3SpUvZu3cv//jHPzjttNP47bfffKw9EfGF7QN3VFRUgqMUNQA47wDa3HLvvfeaXbt2mbS0NDNv3jwzduxYtwHAgLnlllvM+vXrzbFjx8yBAwfMihUrTP/+/YuNISwszCQkJBhjjGnZsqXbYy1atDDLly83R48eNbt27TIPPPCAiY2NNTNmzHAdk3cAMGDOO+88ExcXZ44ePWrWr19v+vTp4zYAGDBnn322+fDDD83BgwfN0aNHzZYtW8z06dNdf79kyRKTnJxsMjIyzO+//+424FhFRcX/xZHzDxEREZGgpLuZREREJKgpmREREZGgpmRGREREgpqSGREREQlqSmZEREQkqCmZERERkaCmZEZERESCmpIZERERCWpKZkRERCSoKZkRERGRoKZkRkRERIKakhkREREJav8PH4f9HCHhvDsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Implement a simple linear regression model using the real estate dataset\n",
    "\n",
    "# import the model from sklearn and mse score from sklearn.metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#get the labelled test set\n",
    "real_estate_test_full = pd.read_csv('../data/regression/real_estate_valuation/real_estate_valuation_test_private.csv')\n",
    "\n",
    "# Create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Choose only the feature X2 house age\n",
    "X_train = real_estate_train[['X2']]   \n",
    "y_train = real_estate_train['Y'] #vector of true values in train set\n",
    "X_test = real_estate_test[['X2']] \n",
    "y_test = real_estate_test['Y'] #vector of true values in test set\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the coefficients of the fitted model\n",
    "m = model.coef_[0] #slope of our fitted model\n",
    "b = model.intercept_ #intercept of our fitted model\n",
    "\n",
    "# Display the formula for the fitted model\n",
    "print(f'Our model F is given by: Y = {m}X + {b}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "#Display the mse\n",
    "print(f'Mean squared error: {mse:.2f}')\n",
    "\n",
    "#visualize the column of true values and the column of predictions\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('True values vs Predictions')\n",
    "#plot the line y=x\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model is fared quite poorly (it might be fair to classify it as garbage): the true values are spread out from $10$ to $80$, but our model basically only predicted values between $30$ and $40$! The issue is that we did not both to explore the data and check whether a linear model was a good fit for the data in the first place! That is, we left out the all-important step of exploratory data analysis (EDA), which is crucial for choosing the right model for the problem.\n",
    "\n",
    "## Summary of a simple machine learning pipeline\n",
    "\n",
    "A machine learning pipeline refers to a sequence of tasks that are carried out by the programming, beginning with procuring the data, and ending with making predictions and (if relevant) evaluating the model. A typical pipeline may look like so:\n",
    "\n",
    "1. **Data cleaning.** Process the data into a neat, well-labelled table with feature columns and a target column.\n",
    "2. **EDA.** Explore relationships in the data with visualizations, statistical tests and so on.\n",
    "3. **Model selection.** Based on your understanding of the data from the EDA, choose a model which you believe will be a good approximation to $\\mathbf{F}$.\n",
    "4. **Feature engineering.** Modify the features (or create new ones) that you believe will help the model make better predictions.\n",
    "5. **Loss function selection.** Choose a loss function which will measure how well your model approximates $\\mathbf{F}$. Also, choose your evaluation metric (i.e. scoring function).\n",
    "6. **Train-test-split.** Split off a portion of the data (usually $20\\%$) to be used as the test set; the rest of the data will form the train set. <u>Forget about the test set until you're completely and utterly finished with training your model</u>.\n",
    "7. **Model training.** Fit your model to the train set, i.e. find the parameters $\\hat{\\mathbf{w}}$ which minimize the loss function.\n",
    "8. **Final performance evaluation.** After you are satisfied with the performance of your model on the train set, finally, evaluate the performance by making and scoring predictions on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
