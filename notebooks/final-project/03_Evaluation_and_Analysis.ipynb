{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab308044",
   "metadata": {},
   "source": [
    "# Notebook 3: Model Evaluation and Comparative Analysis\n",
    "\n",
    "**Goal:**\n",
    "1.  Evaluate trained models on the test set.\n",
    "2.  Calculate performance metrics.\n",
    "3.  Load and compare results from multiple experimental setups.\n",
    "4.  Perform qualitative analysis by visualizing predictions.\n",
    "5.  Synthesize findings and discuss project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe6ccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Evaluating Setup ID: resnet_mid_aug\n",
      "Model: resnet, Unfreeze: mid\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm # For progress bars\n",
    "\n",
    "# Import utility functions\n",
    "import utils\n",
    "\n",
    "# --- Define Setup for SINGLE Model Evaluation (initially) ---\n",
    "# This should match a *completed* training run from Notebook 2\n",
    "\n",
    "# Unique identifier for the experimental setup to evaluate\n",
    "SETUP_ID_TO_EVAL = 'resnet_mid_aug' # <<< CHANGE THIS TO THE DESIRED SETUP ID >>>\n",
    "\n",
    "MODEL_NAME = 'resnet'        # 'resnet' or 'mobilenet'  (must match SETUP_ID_TO_EVAL)\n",
    "UNFREEZE_STRATEGY = 'mid'    # 'head', 'mid', or 'deep' (must match SETUP_ID_TO_EVAL)\n",
    "# AUGMENT_TRAIN is not directly used for evaluation, but kept for consistency if model loading needs it\n",
    "\n",
    "# --- Device Setup ---\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Unfreeze Strategy Mapping ---\n",
    "resnet_unfreeze_map = {\n",
    "    'head': ['fc.'],\n",
    "    'mid':  ['fc.', 'layer4.'],\n",
    "    'deep': ['fc.', 'layer4.', 'layer3.']\n",
    "}\n",
    "mobilenet_unfreeze_map = {\n",
    "    'head': ['classifier.3.'],\n",
    "    'mid':  ['classifier.3.', 'features.10.', 'features.11.', 'features.12.'],\n",
    "    'deep': ['classifier.3.', 'features.8.', 'features.9.', 'features.10.', 'features.11.', 'features.12.']\n",
    "}\n",
    "if MODEL_NAME == 'resnet':\n",
    "    layers_to_unfreeze = resnet_unfreeze_map[UNFREEZE_STRATEGY]\n",
    "elif MODEL_NAME == 'mobilenet':\n",
    "    layers_to_unfreeze = mobilenet_unfreeze_map[UNFREEZE_STRATEGY]\n",
    "\n",
    "# --- Filenames ---\n",
    "# Input file from Notebook 2\n",
    "best_model_filename = f\"best_model_{SETUP_ID_TO_EVAL}.pth\"\n",
    "# Output files for this notebook\n",
    "predictions_filename = f\"predictions_{SETUP_ID_TO_EVAL}.json\" # Store as list of dicts\n",
    "eval_metrics_filename = f\"eval_metrics_{SETUP_ID_TO_EVAL}.json\"\n",
    "\n",
    "print(f\"Evaluating Setup ID: {SETUP_ID_TO_EVAL}\")\n",
    "print(f\"Model: {MODEL_NAME}, Unfreeze: {UNFREEZE_STRATEGY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f688671",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mget_model(MODEL_NAME)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39madapt_model_head(model, MODEL_NAME)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mapply_unfreeze_logic(model, layers_to_unfreeze) \u001b[38;5;66;03m# Apply same unfreeze logic\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m architecture instantiated for evaluation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MATH-392-Intro-to-neural-networks/notebooks/final-project/utils.py:158\u001b[0m, in \u001b[0;36mapply_unfreeze_logic\u001b[0;34m(model, layers_to_unfreeze)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_unfreeze_logic\u001b[39m(model, layers_to_unfreeze: \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Freezes all model layers, then unfreezes specified layers by name substring.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m    159\u001b[0m         param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Unfreeze parameters whose names contain any specified substring\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate Model Architecture\n",
    "model = utils.get_model(MODEL_NAME)\n",
    "model = utils.adapt_model_head(model, MODEL_NAME)\n",
    "model = utils.apply_unfreeze_logic(model, layers_to_unfreeze) # Apply same unfreeze logic\n",
    "print(f\"Model '{MODEL_NAME}' architecture instantiated for evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7957750b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ResNet(\n",
       "   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer4): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       " ),\n",
       " ResNet18_Weights.IMAGENET1K_V1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc084d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Load Saved Best Model Weights\n",
    "print(f\"Loading best model weights from: {best_model_filename}\")\n",
    "# Add check if file exists? No error handling per request.\n",
    "model.load_state_dict(torch.load(best_model_filename, map_location=device))\n",
    "model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "print(\"Best model weights loaded and model set to evaluation mode.\")\n",
    "\n",
    "# 3. Load Test Dataset and DataLoader\n",
    "# Test data is *never* augmented\n",
    "_ , _, test_dataset = utils.get_datasets(augment_train=False) # Pass dummy augment_train\n",
    "# The first two datasets (train, val) are not needed here\n",
    "# weights_obj is not needed for simplified get_datasets\n",
    "\n",
    "_, _, test_loader = utils.get_dataloaders(\n",
    "    None, # train_dataset not needed\n",
    "    None, # val_dataset not needed\n",
    "    test_dataset,\n",
    "    batch_size=64 # Can use a reasonable batch size for inference\n",
    ")\n",
    "print(f\"Test DataLoader created. Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Get class names for OxfordIIITPet (for confusion matrix and reports)\n",
    "# This is a bit of a hack to get class names if not stored elsewhere.\n",
    "# Assumes the test_dataset is an instance of OxfordIIITPet or a Subset of it.\n",
    "if isinstance(test_dataset, torch.utils.data.Subset):\n",
    "    # Access the underlying dataset if it's a Subset\n",
    "    if hasattr(test_dataset.dataset, 'classes'):\n",
    "         class_names = test_dataset.dataset.classes\n",
    "    elif hasattr(test_dataset.dataset, '_breeds'): # OxfordIIITPet specific\n",
    "         class_names = test_dataset.dataset._breeds\n",
    "    else: # Fallback if classes are not directly accessible\n",
    "         class_names = [str(i) for i in range(utils.NUM_CLASSES)]\n",
    "\n",
    "elif hasattr(test_dataset, 'classes'):\n",
    "    class_names = test_dataset.classes\n",
    "elif hasattr(test_dataset, '_breeds'): # OxfordIIITPet specific\n",
    "    class_names = test_dataset._breeds\n",
    "else:\n",
    "    class_names = [str(i) for i in range(utils.NUM_CLASSES)]\n",
    "\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "# print(class_names) # Uncomment to see class names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
