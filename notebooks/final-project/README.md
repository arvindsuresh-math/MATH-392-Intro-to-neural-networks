# Fine-tuning CNNs for Pet Breed Classification

## 1. Project Overview

This project explores the fine-tuning of pre-trained Convolutional Neural Networks (CNNs) for the task of pet breed classification using the **Oxford-IIIT Pet Dataset**. The dataset contains images of 37 different breeds of cats and dogs, with approximately 200 images per class. The images have a large variation in scale, pose, and lighting. Our goal is to classify an input image into one of these 37 pet breeds.

We will compare the performance of two common CNN architectures: **ResNet18** and **MobileNetV3-Small**. The comparison will involve systematically varying several factors during the fine-tuning process, leading to 12 distinct experimental "setups."

### Experimental Setups

Each setup is uniquely identified by a `setup_id` string in the format: `modelname_unfreezekey_augmentstr`. The goal is to run all 12 setups and compare their performance. The factors defining these setups are:

1.  **Base Model (`modelname`):**
    *   `resnet`: ResNet18
    *   `mobilenet`: MobileNetV3-Small

2.  **Unfreezing Strategy (`unfreezekey`):** This determines how many layers of the pre-trained model are unfrozen and trained alongside the new classification head.
    *   `head`: Only the final classification layer (the "head") is trained. All pre-trained backbone layers remain frozen (feature extraction).
    *   `mid`: The head and a medium number of layers from the end of the backbone are unfrozen and trained.
        *   For `resnet`: `fc.` (head) and `layer4.`
        *   For `mobilenet`: `classifier.3.` (head) and features `10, 11, 12`.
    *   `deep`: The head and a larger number of layers from the end of the backbone are unfrozen and trained.
        *   For `resnet`: `fc.`, `layer4.`, and `layer3.`
        *   For `mobilenet`: `classifier.3.` (head) and features `8, 9, 10, 11, 12`.

3.  **Data Augmentation (`augmentstr`):**
    *   `aug`: On-the-fly data augmentation (random resized crops, horizontal flips, color jitter, random rotations) is applied to the training dataset.
    *   `noaug`: No data augmentation is applied to the training dataset, only standard resizing and normalization.

**The 12 Setup IDs are:**

1.  `resnet_head_noaug`
2.  `resnet_mid_noaug`
3.  `resnet_deep_noaug`
4.  `resnet_head_aug`
5.  `resnet_mid_aug`
6.  `resnet_deep_aug`
7.  `mobilenet_head_noaug`
8.  `mobilenet_mid_noaug`
9.  `mobilenet_deep_noaug`
10. `mobilenet_head_aug`
11. `mobilenet_mid_aug`
12. `mobilenet_deep_aug`

## 2. Workflow Instructions

The project involves a three-stage workflow for each setup:
1.  Hyperparameter Optimization (HPO)
2.  Final Model Training
3.  Evaluation

These stages are executed using separate Python scripts. All output files are saved into a structured `results/` directory, with subdirectories for `hpo/`, `final_training/`, and `evaluation/`.

**Key Files:**
*   `utils.py`: Contains shared utility functions for data loading, model preparation, etc.
*   `config.py`: Contains global configurations, HPO grid definition, unfreeze maps, and output directory paths.
*   `run_hpo.py`: Script for running the HPO stage.
*   `run_final_training.py`: Script for running the final model training stage.
*   `run_evaluation.py`: Script for running the evaluation stage.
*   Jupyter Notebooks (`01_...ipynb` to `04_...ipynb`): Can be used for exploring individual steps or for visualizing and analyzing the results generated by the scripts.

---

### Stage 1: Hyperparameter Optimization (`run_hpo.py`)

**Purpose:** To find a good set of hyperparameters (learning rates for head and backbone, weight decay) for a given `setup_id` by running short training trials on a validation set.

**What it does:**
*   For each specified `setup_id`:
    *   Parses the `setup_id` to determine the model, unfreeze strategy, and augmentation setting.
    *   Loads the Oxford-IIIT Pet `trainval` dataset and splits it into a training subset and a validation subset (80/20 split by default).
    *   Iterates through a predefined grid of hyperparameter combinations (defined in `config.py`).
    *   For each combination (a "trial"):
        *   Initializes the specified model, adapts its head, and applies the unfreezing strategy.
        *   Trains the model using a specified batch size (default is `64`, configurable via `--batch_size`)  for a fixed number of epochs (default is `15`, configurable via `--hpo_epochs`) on the training subset.
        *   Evaluates the model on the validation subset after each epoch.
        *   **Saves to file:**
            *   `results/hpo/hpo_history_{setup_id}.json`: A detailed log of all HPO trials, including the epoch-by-epoch training and validation loss/accuracy for each trial.
            *   `results/hpo/best_params_{setup_id}.json`: The hyperparameter combination that yielded the best validation accuracy at the end of its HPO trial epochs.

**Example:**
Running this in the command line will run HPO for the `resnet_mid_aug` and `resnet_deep_aug` setups, using 12 epochs and a batch size of 32: 
```bash
python run_hpo.py --setup_ids resnet_mid_aug resnet_deep_aug --hpo_epochs 12 --batch_size 32
```

### Stage 2: Final Model Training (`run_final_training.py`)

**Purpose:** To train a model for a given `setup_id` for a potentially larger number of epochs, using the best hyperparameters found in Stage 1, and employing early stopping based on training loss.

**What it does:**
*   For each specified `setup_id`:
    *   Parses the `setup_id`.
    *   **Loads from file:**
        *   `results/hpo/best_params_{setup_id}.json`: The best hyperparameters determined by `run_hpo.py`.
    *   Loads the full Oxford-IIIT Pet `trainval` dataset (referred to as the 'train' task in `utils.py`, which uses the entire `trainval` portion for training). Applies augmentation if specified by the `setup_id`.
    *   Initializes the model, adapts its head, applies the unfreezing strategy, and sets up the optimizer with the loaded best hyperparameters.
    *   Trains the model for a maximum number of epochs (default is `50`, configurable via `--final_train_epochs`), using a specified batch size (default is `32`, configurable via `--batch_size`).
    *   Implements early stopping: training stops if the training loss does not improve for a specified number of `patience` epochs (default is `10`, configurable via `--patience`).
    *   **Saves to file:**
        *   `results/final_training/best_model_{setup_id}.pth`: The `state_dict` of the model that achieved the lowest training loss during this final training phase.
        *   `results/final_training/final_training_history_{setup_id}.json`: The epoch-by-epoch training loss and accuracy.

**Example:**
The following command in the command line will run final training for the `resnet_mid_aug` and `resnet_deep_aug` setups, using 50 epochs, a batch size of 32, and a patience of 10 epochs for early stopping:
```bash
python run_final_training.py --setup_ids resnet_mid_aug resnet_deep_aug --final_train_epochs 50 --batch_size 32 --patience 10
```

### Stage 3: Evaluation (`run_evaluation.py`)

**Purpose:** To evaluate the performance of a trained model (from Stage 2) on the held-out test set.

**What it does:**
*   For each specified `setup_id`:
    *   Parses the `setup_id`.
    *   **Loads from file:**
        *   `results/final_training/best_model_{setup_id}.pth`: The saved model weights.
    *   Loads the Oxford-IIIT Pet `test` dataset (no augmentation).
    *   Initializes the model architecture (matching the `setup_id`) and loads the saved weights.
    *   Iterates through the test dataset, making predictions for each image.
    *   Calculates performance metrics (overall accuracy, precision, recall, F1-score per class, confusion matrix).
    *   **Saves to file:**
        *   `results/evaluation/predictions_{setup_id}.csv`: A CSV file containing the true label and predicted label for each image in the test set.
        *   `results/evaluation/eval_metrics_{setup_id}.csv`: A CSV file containing the detailed classification report.

**Example:**
The following command in the command line will run evaluation for the `resnet_mid_aug` and `resnet_deep_aug` setups:
```bash
python run_evaluation.py --setup_ids resnet_mid_aug resnet_deep_aug
```