{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e67ec2",
   "metadata": {},
   "source": [
    "# Notebook 00: End-to-End Pipeline for a Single Setup\n",
    "\n",
    "**Purpose:** This notebook demonstrates how to run the entire experimental pipeline (Hyperparameter Optimization, Final Training, and Evaluation) for a *single, specific setup* by calling the core functions defined in `run_hpo.py`, `run_final_training.py`, and `run_evaluation.py`.\n",
    "\n",
    "This allows for:\n",
    "1.  Testing the full workflow programmatically.\n",
    "2.  Running a specific setup if modifications are needed without using the command line for all scripts.\n",
    "3.  Understanding how the different stages connect and pass information (e.g., best HPO params to final training).\n",
    "\n",
    "**Setup to Run in this Notebook:** `resnet_mid_noaug`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9597ee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Will run pipeline for Setup ID: resnet_mid_noaug ###\n",
      "Using device: mps\n",
      "Output directories ensured.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import time # For potential timing if desired, though scripts handle internal timing\n",
    "\n",
    "# Import shared utilities and configurations\n",
    "import utils\n",
    "import config # Contains HPO_CONFIG_LIST, UNFREEZE_MAPS, output dirs, defaults\n",
    "\n",
    "# Import the core processing functions from our scripts\n",
    "from run_hpo import perform_hpo_for_setup\n",
    "from run_final_training import perform_final_training_for_setup\n",
    "from run_evaluation import perform_evaluation_for_setup\n",
    "\n",
    "# --- Define the Single Setup to Run ---\n",
    "SETUP_ID_TO_RUN = 'resnet_mid_noaug'\n",
    "print(f\"### Will run pipeline for Setup ID: {SETUP_ID_TO_RUN} ###\")\n",
    "\n",
    "# --- Global Parameters for this Run (can override config defaults if needed) ---\n",
    "# These would typically come from argparse in the scripts, here we set them directly\n",
    "# Or, we can rely on defaults set within config.py and the script functions\n",
    "HPO_EPOCHS = config.DEFAULT_HPO_EPOCHS\n",
    "FINAL_TRAIN_EPOCHS = config.DEFAULT_FINAL_TRAIN_EPOCHS\n",
    "PATIENCE = config.DEFAULT_PATIENCE\n",
    "BATCH_SIZE = config.DEFAULT_BATCH_SIZE # Using one batch size for simplicity here, scripts might allow separate\n",
    "\n",
    "# --- Device Setup ---\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Ensure Output Directories Exist ---\n",
    "config.create_output_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75336872",
   "metadata": {},
   "source": [
    "## Stage 1: Hyperparameter Optimization\n",
    "\n",
    "Running HPO for the selected setup (`SETUP_ID_TO_RUN`).\n",
    "This will iterate through the hyperparameter grid defined in `config.HPO_CONFIG_LIST`, run short training trials, and save the best parameters found and the full HPO history to the `results/hpo/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8932051",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*5} STAGE 1: Hyperparameter Optimization {'='*5}\")\n",
    "hpo_start_time = time.time()\n",
    "\n",
    "# Call the HPO function from run_hpo.py\n",
    "# It will handle parsing the setup_id internally if designed to do so,\n",
    "# or we can pass the components if the function expects them directly.\n",
    "# Assuming perform_hpo_for_setup takes setup_id and uses config for maps.\n",
    "\n",
    "best_hpo_params_found = perform_hpo_for_setup(\n",
    "    setup_id=SETUP_ID_TO_RUN,\n",
    "    hpo_grid=config.HPO_CONFIG_LIST,\n",
    "    num_epochs_hpo=HPO_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device\n",
    "    # The function saves its outputs to files within config.HPO_DIR\n",
    ")\n",
    "\n",
    "hpo_end_time = time.time()\n",
    "print(f\"\\n{'*'*10} HPO Stage for {SETUP_ID_TO_RUN} finished in {(hpo_end_time - hpo_start_time)/60:.2f} minutes {'*'*10}\")\n",
    "\n",
    "if best_hpo_params_found:\n",
    "    print(f\"Best HPO parameters found: {best_hpo_params_found}\")\n",
    "    # These are also saved to results/hpo/best_params_{SETUP_ID_TO_RUN}.json\n",
    "else:\n",
    "    print(f\"HPO did not complete successfully or find best parameters for {SETUP_ID_TO_RUN}. Cannot proceed.\")\n",
    "    # Consider raising an error or stopping the notebook here if HPO is critical for next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedbae2",
   "metadata": {},
   "source": [
    "## Stage 2: Final Model Training\n",
    "\n",
    "Running final training for `SETUP_ID_TO_RUN` using the best hyperparameters found in Stage 1.\n",
    "This loads `results/hpo/best_params_{SETUP_ID_TO_RUN}.json`, trains for more epochs with early stopping on training loss, and saves the best model and training history to `results/final_training/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_hpo_params_found: # Proceed only if HPO was successful\n",
    "    print(f\"\\n{'='*20} STAGE 2: Final Model Training {'='*20}\")\n",
    "    final_train_start_time = time.time()\n",
    "\n",
    "    # Call the final training function from run_final_training.py\n",
    "    # It will load the best_params file itself based on setup_id.\n",
    "    saved_model_filepath = perform_final_training_for_setup(\n",
    "        setup_id=SETUP_ID_TO_RUN,\n",
    "        max_epochs=FINAL_TRAIN_EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        device=device\n",
    "        # The function saves its outputs to files within config.FINAL_TRAINING_DIR\n",
    "    )\n",
    "\n",
    "    final_train_end_time = time.time()\n",
    "    print(f\"\\n{'*'*10} Final Training Stage for {SETUP_ID_TO_RUN} finished in {(final_train_end_time - final_train_start_time)/60:.2f} minutes {'*'*10}\")\n",
    "\n",
    "    if saved_model_filepath:\n",
    "        print(f\"Best model saved to: {saved_model_filepath}\")\n",
    "        # This path is also saved internally by the function to results/final_training/best_model_{SETUP_ID_TO_RUN}.pth\n",
    "    else:\n",
    "        print(f\"Final training did not complete successfully or model was not saved for {SETUP_ID_TO_RUN}. Cannot proceed to evaluation.\")\n",
    "else:\n",
    "    print(\"\\nSkipping Stage 2: Final Model Training due to HPO failure or no best parameters found.\")\n",
    "    saved_model_filepath = None # Ensure it's None if HPO failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd65a8",
   "metadata": {},
   "source": [
    "## Stage 3: Evaluation\n",
    "\n",
    "Evaluating the best model from Stage 2 for `SETUP_ID_TO_RUN` on the test set.\n",
    "This loads `results/final_training/best_model_{SETUP_ID_TO_RUN}.pth`, generates predictions, calculates metrics, and saves predictions and metrics to `results/evaluation/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4cc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if saved_model_filepath and os.path.exists(saved_model_filepath): # Proceed only if final training produced a model\n",
    "    print(f\"\\n{'='*20} STAGE 3: Evaluation {'='*20}\")\n",
    "    eval_start_time = time.time()\n",
    "\n",
    "    # Call the evaluation function from run_evaluation.py\n",
    "    # It will load the model file itself based on setup_id and config.FINAL_TRAINING_DIR\n",
    "    perform_evaluation_for_setup(\n",
    "        setup_id=SETUP_ID_TO_RUN,\n",
    "        device=device\n",
    "        # The function saves its outputs to files within config.EVALUATION_DIR\n",
    "    )\n",
    "\n",
    "    eval_end_time = time.time()\n",
    "    print(f\"\\n{'*'*10} Evaluation Stage for {SETUP_ID_TO_RUN} finished in {(eval_end_time - eval_start_time)/60:.2f} minutes {'*'*10}\")\n",
    "    print(f\"\\nEvaluation results (predictions and metrics CSVs) are saved in: {config.EVALUATION_DIR}\")\n",
    "else:\n",
    "    print(\"\\nSkipping Stage 3: Evaluation due to final training failure or model not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6a0e0",
   "metadata": {},
   "source": [
    "## Pipeline Complete for `resnet_mid_noaug`\n",
    "\n",
    "The HPO, Final Training, and Evaluation stages have been executed for the setup `resnet_mid_noaug`.\n",
    "\n",
    "**Outputs can be found in the `results/` directory:**\n",
    "*   `results/hpo/hpo_history_resnet_mid_noaug.json`\n",
    "*   `results/hpo/best_params_resnet_mid_noaug.json`\n",
    "*   `results/final_training/best_model_resnet_mid_noaug.pth`\n",
    "*   `results/final_training/final_training_history_resnet_mid_noaug.json`\n",
    "*   `results/evaluation/predictions_resnet_mid_noaug.csv`\n",
    "*   `results/evaluation/eval_metrics_resnet_mid_noaug.csv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
