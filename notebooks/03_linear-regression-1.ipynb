{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression 1\n",
    "\n",
    "In this notebook, we recall some basic facts about vectors and matrices. Our motivation is to understand the linear regression model, which is a simple yet powerful tool for predicting a continuous target variable. To illustrate the concepts, we will use the concrete compressive strength dataset `../data/regression/concrete_compressive_strength/train.csv`. \n",
    "\n",
    "As usual, we begin by importing the necessary libraries and loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 824 rows and 9 columns in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173.8</td>\n",
       "      <td>93.4</td>\n",
       "      <td>159.9</td>\n",
       "      <td>172.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>746.6</td>\n",
       "      <td>28</td>\n",
       "      <td>37.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>355.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>967.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>28</td>\n",
       "      <td>44.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.7</td>\n",
       "      <td>180.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>804.9</td>\n",
       "      <td>28</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>159.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1003.8</td>\n",
       "      <td>903.8</td>\n",
       "      <td>100</td>\n",
       "      <td>47.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>28</td>\n",
       "      <td>37.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1     X2     X3     X4    X5      X6     X7   X8      Y\n",
       "0  173.8   93.4  159.9  172.3   9.7  1007.2  746.6   28  37.81\n",
       "1  355.0   19.0   97.0  145.0  13.1   967.0  871.0   28  44.03\n",
       "2  134.7    0.0  165.7  180.2  10.0   961.0  804.9   28  13.29\n",
       "3  212.6    0.0  100.4  159.4  10.4  1003.8  903.8  100  47.74\n",
       "4  150.0  237.0    0.0  174.0  12.0  1069.0  675.0   28  37.43"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import the concrete compressive strength dataset\n",
    "df = pd.read_csv('../data/regression/concrete_compressive_strength/train.csv')\n",
    "\n",
    "# display some info\n",
    "print(f'There are {df.shape[0]} rows and {df.shape[1]} columns in the dataset.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "### The space $\\mathbb{R}^n$\n",
    "Let $S_1,\\dotsc,S_n$ be a finite collection of non-empty sets. The *direct* (or *Cartesian*) *product* of these sets is the set\n",
    "$$S_1 \\times \\dotsb \\times S_n = \\{ (x_1,\\dotsc,x_n) \\mid x_i \\in S_i \\textup{ for } i=1,\\dotsc,n \\}.$$\n",
    "The reason for the \"$\\times$\" notation is that if each $S_i$ is a finite set (of size $|S_i|$), then the size of the direct product is the product of the sizes: $$|S_1 \\times \\dotsb \\times S_n| = |S_1| \\times \\dotsb \\times |S_n|.$$\n",
    "\n",
    "The real line is denoted $\\mathbb{R}$, and sometimes, $\\mathbb{R}^1$. The notation $\\mathbb{R}^n$ represents the direct product of $\\mathbb{R}$ with itself $n$ times:\n",
    "\\begin{align*}\n",
    "    \\mathbb{R}^n & \\coloneqq \\underbrace{\\mathbb{R} \\times \\dotsb \\times \\mathbb{R}}_{n \\textup{ copies}} \\\\\n",
    "                & = \\{ (x_1,\\dotsc,x_n) \\mid x_1,\\dotsc,x_n \\in \\mathbb{R} \\}.\n",
    "\\end{align*}\n",
    "These are the most intuitive spaces to do geometry and visualize things, and as such, elements of $\\mathbb{R}^n$ are often referred to as *points*. For example, $\\mathbb{R}^1$ is simply the real line, $\\mathbb{R}^2$ is a plane, $\\mathbb{R}^3$ is an abstract representation of physical 3d-space, and so on.\n",
    "\n",
    "### Vectors\n",
    "When we want to do arithmetic with points in $\\mathbb{R}^n$, such as addition and multiplication, it becomes appropriate to consider them as **vectors**. Informally, a vector is an arrow that starts at the origin and ends at some point. For us, vectors will always mean (unless otherwise specified) ***column vectors**, denoted as follows:\n",
    "\\begin{equation*}\n",
    "    \\mathbf{x} = \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\in \\mathbb{R}^n.\n",
    "\\end{equation*}\n",
    "When we want to instead work with **row vectors**, we use the superscript \"$(\\cdot)^T$\" (for **transpose**) to denote our vector:\n",
    "\\begin{equation*}\n",
    "    \\mathbf{x}^T = [x_1 \\, \\dotsb \\, x_n] \\in \\mathbb{R}^n.\n",
    "\\end{equation*}\n",
    "Since the transpose of a row is a column, the notation $\\mathbf{x} = [x_1 \\, \\dotsb \\, x_n]^T$ means that $\\mathbf{x}$ is a column vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows and columns of datasets\n",
    "Suppose we have a ML provlem with features $X_1,\\dotsc,X_n$ and target $Y$. For simplicity, assume that all features and target are continuous variables. Suppose there are $m$ instances or observations for which we know the values of $X_1,\\dotsc,X_n,Y$. These values can be put together into a labelled dataset that looks like:\n",
    "\\begin{equation*}\n",
    "    \\begin{bmatrix}\n",
    "        x_{11}  & \\dotsb & x_{1n} & y_1\\\\\n",
    "        \\vdots  & \\ddots & \\vdots & \\vdots\\\\\n",
    "        x_{m1}  & \\dotsb & x_{mn} & y_m\n",
    "    \\end{bmatrix}.\n",
    "\\end{equation*}\n",
    "We write $\\mathbb{R}^{m \\times n}$ to denote the set of $m\\times n$ matrices. The **design matrix** is the $m \\times n$ matrix $$X = [x_{ij}] \\in \\mathbb{R}^{m \\times n}.$$ (This notation means that the entry in $i$-th row and $j$-th column is $x_{ij}$.) Denoting the first column of the dataset as $\\mathbf{1} \\in \\mathbb{R}^m$, we can write the dataset as\n",
    "\\begin{equation*}\n",
    "    \\textup{Dataset } = \\begin{bmatrix} \\; X & \\mathbf{y} \\; \\end{bmatrix} \\in \\mathbb{R}^{m \\times (n+1)}.\n",
    "\\end{equation*}\n",
    "Let's examine the rows and columns for a moment.\n",
    "- **Rows.** Observe that the $i$-th row of $X$ is\n",
    "\\begin{equation*}\n",
    "    \\mathbf{x}_i^T = \\begin{bmatrix} \\; x_{i1} & \\dotsb & x_{in} \\; \\end{bmatrix} \\in \\mathbb{R}^n.\n",
    "\\end{equation*}\n",
    "NOTE: we think of $\\mathbf{x}_i$ as a column vector, so that $\\mathbf{x}_i^T$ is a row vector (the actual row in the dataset).\n",
    "By the **feature space**, we mean the space $\\mathbb{R}^n$ of all possible row vectors. The $i$-th vector $\\mathbf{x}_i^T$ in the feature space corresponds to an instance, and the $j$-th coordinate of $\\mathbf{x}_i^T$ records the value of $X_j$ for that instance. \n",
    "- **Columns.**  The columns of $X$ are vectors in $\\mathbb{R}^m$; each column $\\mathbf{v}_j$ corresponds to the feature $X_j$. The last column $\\mathbf{y} \\in \\mathbb{R}^m$ corresponds to the target. We often summarize this info by writing\n",
    "\\begin{equation*}\n",
    "    \\textup{Dataset } = \\begin{bmatrix} \\; \\mathbf{v}_1 & \\dotsb & \\mathbf{v}_n & \\mathbf{y} \\; \\end{bmatrix} = \\begin{bmatrix} \\; X & \\mathbf{y} \\; \\end{bmatrix} \\in \\mathbb{R}^{m \\times n}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our framework for ML\n",
    "Recall that in our framework of supervised ML (in particular, regression), there exists a \"ground truth\" function $\\mathbf{F}$ from the feature space $\\mathbb{R}^n$ to the target space $\\mathbb{R}$ (space of possible $Y$-values) such that, for every row $(\\mathbf{x}^T,y) \\in \\mathbb{R}^n \\times \\mathbb{R}$, we have\n",
    "\\begin{equation*}\n",
    "    y = \\mathbf{F}(\\mathbf{x}) + \\epsilon,\n",
    "\\end{equation*}\n",
    "where $\\epsilon$ is some small error term. \n",
    "\n",
    "For example, in our current dataset `df`, there are $n=8$ features, so our feature space is $\\mathbb{R}^8$. \n",
    "\n",
    "We assume moreover that $\\mathbf{F}$ is of the form $F_{\\mathbf{w}}$, where $\\{F_{\\mathbf{w}}\\}$ is a class of functions parameterized by some vector $\\mathbf{w} \\in \\mathbb{R}^k$ of parameters (these are simply coefficients appearing in the function). Here, $k$ is some positive integer. Recall then that in order to make the best predictions, we need to \"fit the model to the data\", which means that we find the best parameters $\\hat{\\mathbf{w}}$ such that the predictions $F_{\\hat{\\mathbf{w}}}(\\mathbf{x})$ are as close as possible to the true target $y$. To make this precise, we define a **loss function** $J(\\mathbf{w})$ that measures the distance between the predictions and the true target. The \"best-fit\" parameters are then the ones that minimize the loss function:\n",
    "\\begin{equation*}\n",
    "    \\hat{\\mathbf{w}} = \\argmin_{\\mathbf{w} \\in \\mathbb{R}^k} J(\\mathbf{w}).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions for regression\n",
    "Let us denote\n",
    "\\begin{equation*}\n",
    "    \\hat{y}_i = F_{\\mathbf{w}}(\\mathbf{x}_i)\n",
    "\\end{equation*}\n",
    "for the predicted value of the target for the $i$-th instance. (Note that $\\hat{y}_i$ depends on the parameters $\\mathbf{w}$.)  The **residual** is the difference between the true target $y_i$, and the predicted target: $$\\epsilon_i = y_i - \\hat{y}_i, \\quad \\textup{ for } i=1,\\dotsc,m.$$ Our loss function will be a function of the residuals which (in some precise, sensible way) measures how small the residuals are. This is accomplished using a general schema:\n",
    "\n",
    "1. For each instance $i=1,\\dotsc,m$, compute the error for the $i$-th instance as some function of $\\epsilon_i$.\n",
    "2. Average the errors over all instances to get the *mean error per instance*.\n",
    "\n",
    "A naive first attempt would be to take $\\epsilon_i$ itself as our for each instance. However, this would be problematic, since positive and negative errors could cancel each other out. To avoid this, we want the errors to all be non-negative. Thus, there are two natural choices for the error function:\n",
    "\n",
    "1. **Mean Absolute Error (MAE):** The error for the $i$-th instance is $|\\epsilon_i| = |y_i - \\hat{y}_i|$. Geomtrically, this is simply the distance between the actual and predicted values on the target axis. Averaging over the instances $i=1,\\dotsc,m$, we get the MAE:\n",
    "\\begin{align*}\n",
    "    \\textup{MAE}(\\mathbf{w})    & = \\frac{1}{m} \\sum_{i=1}^m |\\epsilon_i|\\\\\n",
    "                                & = \\frac{1}{m} \\sum_{i=1}^m |y_i - \\hat{y}_i|.\n",
    "\\end{align*}\n",
    "2. **Mean Squared Error (MSE):** The error for the $i$-th instance is $(\\epsilon_i)^2 = (y_i - \\hat{y}_i)^2$. Geometrically, this is the square of the distance between the actual and predicted values on the target axis. Averaging over the instances $i=1,\\dotsc,m$, we get the MSE:\n",
    "\\begin{align*}\n",
    "    \\textup{MSE}(\\mathbf{w})    & = \\frac{1}{m} \\sum_{i=1}^m \\epsilon_i^2\\\\\n",
    "                                & = \\frac{1}{m} \\sum_{i=1}^m (y_i - \\hat{y}_i)^2.\n",
    "\\end{align*}\n",
    "\n",
    "**Example.** Below, we generate some random predictions of the target for the first 100 instances in our dataset `df`. We then compute the MAE and MSE for these predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAHqCAYAAADrpwd3AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdfhJREFUeJzt3XmcjfX///HnjFmYaRA+lmQrS5ZfwmjFWLJVn2yfD5GMraLILkOFTzEJ2T5KhSGlUhF97DRJkSLZtxhLg7Ez++b9+yNzvk5zjlmcmWtmzuN+u71vrvM+7+u6Xue6zuF1Xq7zvjwkGQEAAAAAAAAAgHQ8rQ4AAAAAAAAAAIC8iiI6AAAAAAAAAABOUEQHAAAAAAAAAMAJiugAAAAAAAAAADhBER0AAAAAAAAAACcoogMAAAAAAAAA4ARFdAAAAAAAAAAAnKCIDgAAAAAAAACAExTRAQAAAAAAAABwgiI6gGwLDg6WMcbW4uPjdebMGX333XcaNWqU/vGPf6RbZ+zYsTLGZGk/RYoU0dixYxUUFJSl9RztKyIiQt9++22WtpORrl27atCgQQ6fM8Zo7NixLt2fqzVv3ly//vqrYmJiZIxRu3btMlynTp06MsYoKSlJZcuWdTgmJ451RoKCgmSMyfJ7Rcr++ywzIiIi7D4rN7fw8HCX7w8AALgvcvS/uFOOfvfdd2v27Nk6dOiQ4uLidPHiRe3evVsffvih7r777lyM2hphYWGKiIjIcFx4eLjTnDwz6wNwb15WBwAg/+vZs6cOHjwob29vlS5dWo0aNdKrr76q4cOHq0uXLtq4caNt7Ny5c7VmzZosbd/Pz0/jxo3TuHHjtGnTpkyvl519ZUe3bt1Up04dzZgxI91zDz/8sP78888cj+F2LFmyRIcPH9bTTz+t2NhYHTp0KMN1+vbtK0ny9vZWjx499M477+R0mDkuu++zzPrxxx81fPjwdP3Xrl1z+b4AAADI0d0jRy9fvrx+++03XblyRVOnTtWhQ4dUrFgx1apVS507d9Y999yT519rbjp69KieffbZdP2JiYkWRAMgP6GIDuC27d27Vzt27LA9Xrp0qaZNm6Yff/xRS5cuVbVq1XTu3DlJUmRkpCIjI3M0niJFiig+Pj5X9pWRbdu2Wbr/jNx1110qWbKkli1bpu+++y5T6/j4+OjZZ5/V77//rlKlSql3794Fooie065cuZKt90Pa+9mRwoULKyEhIdsxeXl5yRij1NTUbG8DAADkTeTozhWkHP3555/XP/7xDz344IM6fvy4rX/58uUKDQ2Vh4dHDkebfbeby2ZHfHx8ts7/rWK9Vb6eGZ6envLy8lJSUlK2twEg5zGdC4AccerUKQ0bNkxFixbViy++aOt39PPNZs2aKTw8XBcuXFBcXJxOnDihr776SkWKFFGlSpV04cIFSdK4ceNsP7cLCwuz2169evX05Zdf6tKlSzp69KjTfaVp3769du3apfj4eB09elQDBw60ez7tZ7CVKlWy6//7dCHh4eF66qmnVLlyZbufA6Zx9FPR2rVr65tvvtGlS5cUHx+vnTt3qkePHg7388wzz+itt95SZGSkrl69qvXr16t69eq3Pvg3PPbYY9qwYYOuXbum2NhY/fTTT3riiSdsz48dO9b2Beadd97J9M8Y27dvr1KlSmnu3LlauHChatSooccee+yW4291rD08PDRmzBgdPHhQcXFxunz5snbt2qVXXnklS6/HmfDwcIdTptz8s8+M3meSVLVqVX366aeKiopSQkKC9u/fr5deeinD/WfFrd7PaT9z7tChg3777TfFx8fb3ltZeU91795dU6ZM0Z9//qnExERVrVpVRYoU0eTJk3Xs2DHFx8fr4sWL+vXXX/XMM8+49PUBAABrkaP/pSDl6CVLllRqaqrtP0T+7u/HOjg4WAcPHrTls88991y66VCcTZFYqVIlGWMUHBxs62vQoIE+++wzRUREKC4uThEREVq8eLEqVqyYbr/GGLVs2VLz5s3TuXPnFB8fL19fX0lS586dtWXLFsXExCg6Olpr1qzRAw88kO71OIrf1W4Va3h4uPbs2aPGjRvrp59+UmxsrObPny9JqlChghYtWmT3fWHo0KF2/5GRdgxHjBihMWPG6NixY0pMTFSzZs0y/b0IgDW4Eh1Ajlm1apVSUlLUpEkTp2MqVaqklStXavPmzerdu7euXLmi8uXLq02bNvLx8dGZM2fUunVrrV27VnPnztXcuXMlSefPn7fbztKlS/X5559rzpw58vf3v2VcDzzwgKZPn65x48bp7NmzevbZZzVz5kz5+Pho6tSpWXqNL730kj788EPde++96tChQ4bjq1evri1btujcuXN65ZVXdPHiRXXv3l0LFy5UmTJlNHnyZLvxEydO1E8//aS+ffuqaNGimjRpkr799lvVrFlT169fd7qfJk2aaP369dq9e7f69OmjxMREvfTSS/r222/VtWtXLVmyRHPnztWuXbu0bNkyzZw5U4sXL87Uzxj79OmjhIQEffrppypRooRCQkLUp08f/fTTT+nGZuZYjxw5UuPGjdNbb72lH374Qd7e3rrvvvtUvHjxLL2e25HR+6xmzZrasmWLTp48qWHDhuns2bNq3bq1Zs6cqVKlSuk///lPhvvw8PBQoUKF0vU7ugrc2fu5fv36qlmzpt566y1FREQoNjY2y++p0NBQbd26Vf369dP169d17tw5vfvuu3ruuef02muvaefOnfL391edOnVUsmTJLB1HAACQ95Gjp5efc/StW7dqwIABWrp0qd59911t3bpV0dHRDscGBwdrwYIF+uabbzRs2DAVK1ZM48aNk6+v7y3jvpXKlSvr0KFD+vzzz3Xp0iWVK1dO/fv316+//qpatWrp4sWLduPnz5+vlStX6rnnnpO/v7+Sk5MVEhKit956S2FhYXrrrbfk4+OjESNGaPPmzXrwwQd14MABl8bvKCe/fv16uv9wcBSrJJUrV06ffPKJ3nnnHY0ePVrXr19XqVKltGXLFvn4+Oj111/X8ePH9dRTT2nq1Km699579fLLL9tt+5VXXtHhw4c1fPhwXbt2TUeOHMnU9yIA1jI0Go2WnRYcHGyMMaZBgwZOx5w5c8bs27fP9njs2LHG/JWdGEmmY8eOxhhj7r//fqfbKFmypDHGmLFjx6Z7Lm1748aNc/rczX0REREmNTU13f7Wrl1rrly5YooUKWL32ipVqmQ3LigoyBhjTFBQkK3v22+/NREREQ5j/3vcixcvNvHx8ebuu++2G7dy5UoTExNjihYtaref//3vf3bj/vWvfxljjHnooYdueW62bNlizp49a/z9/W19np6eZvfu3ebkyZO2vkqVKhljjBk2bFimznnFihVNSkqKWbx4sa0vPDzcREdHmzvuuCNbx3rFihXmt99+c8nrcXR+wsPDTXh4eLpthoWF2Z23W73PVq9ebU6ePGkCAgLs+mfOnGni4uJM8eLFbxl/RESEcWbMmDGZej9HRESY5ORkU61aNbv+rL6nvv/++3Tb3r17t1m6dGmm3gM0Go1Go9HydiNH/6vPnXL0999/36SkpBhjjElNTTX79u0zU6dOtTtOHh4e5s8//zTbt2+3W7dixYomMTHR7lg5Op43xxUcHOw0Fk9PT+Pn52eio6PNwIED070vFyxYYDf+7rvvNklJSWbGjBl2/f7+/ub06dPm888/z3L8zlp4eLjTnPyjjz7KMNabt9GsWTO7/okTJxpjjGnYsKFd/+zZs01qaqoth087hkeOHDFeXl52YzPzvYhGo1nXmM4FQI7KaA6+33//XYmJifrwww/Vo0cPValSJVv7+frrrzM9dt++fdq9e7dd3+LFi1WsWDHVr18/W/vPrObNm2vjxo3pbu6zYMEC+fv765FHHrHrX7Fihd3jtLj//hPWm/n5+emhhx7SV199pdjYWFv/9evXtWjRIlWoUEE1atTIVvy9evVSoUKFbD9ZlP66QuOOO+5Qly5d0o3PzLH+5ZdfVLduXc2ePVutWrVSQEBArr2ezPD19VWLFi20bNkyxcXFqVChQra2atUqFSlSRA8//HCG29m8ebMCAwPTtXnz5qUb6+z9vHv3bh05csSuL6vvKUfb/uWXX9S2bVuFhoYqKChIhQsXzvD1AACA/Isc3V5+z9H79++ve+65R/3791dYWJi8vb01dOhQ7du3z/aLgxo1aqh8+fJavHix3bonT57Uli1bsrVfSfL399fbb7+tI0eOKDk5WampqYqNjdUdd9yhmjVrphv/9/dE69at5e3trY8//tguz05ISNCmTZvUtGlTl8b/xx9/OMzJ33zzzQxjTXPp0qV000U2b95c+/bt06+//mrXv2DBAnl6eqp58+Z2/StWrFBKSopdX0bfiwBYiyI6gBzj5+enkiVL6vTp007HHDt2TI8//rjOnTun2bNn69ixY/rjjz+yPO/bmTNnMj327NmzTvtyevqKkiVLOow17Rj9ff9///lj2k85ixQp4nQfd955pzw9PbO0n8zw8PBQz549FRkZqR07dqhYsWIqVqyYNmzYoJiYGPXp0yfdOpk51qGhoRo+fLgefvhhrV69WhcvXtSGDRvUoEGDHH09mVWyZEl5e3vrlVdeUUpKil1bvXq1JKlUqVIZbufq1avasWNHuuboGDl7Pzvqz+p7ytHYV155RZMmTVL79u31/fff69KlS1q2bJmqVq2a4esCAAD5Czl6evk5R09z8uRJzZkzR3379lX16tXVuXNnFS5c2DYVTdq2b3Wcs2Px4sUaMGCA5s6dq9atW6thw4YKDAzUuXPnHB6Pv7/+MmXKSJK2b9+eLtd+5plnbHm2q+JPSEhwmJOfPHkyw1hv1e+KnDyj70UArMWc6AByzJNPPikvLy99//33txz3448/6scff5Snp6cCAwM1cOBAzZgxQ1FRUfriiy8ytS/j5OZEjpQtW9ZpX1pCnHbn9bQb3aTJTLH0Vi5evKhy5cql67/rrrskyXaDpttx+fJlpaamunw/jz/+uCpXrizpr6sv/u6RRx5RzZo1bXMWSpk71qmpqZo2bZqmTZumYsWK6fHHH9fEiRO1du1aVahQ4bZfT0JCgooVK5auP7Pn8vLly0pJSdGiRYs0e/Zsh2Myc0PWrHD2fnbUn9X3lKNtxMXFady4cRo3bpxKly6ttm3b6u2337bN7QkAAAoOcvT08nOO7syXX36pkJAQ1alTR9L/HcNbHec0mT3ORYsW1VNPPaXx48dr0qRJtn4fHx+VKFHCYVx/f0+kveZOnTrpxIkTTl9PVuJ3ldzOyTP6XhQfH5+dlwHARbgSHUCOqFChgqZMmaIrV67ogw8+yNQ6169f1y+//GK76UrazzYzc2VHVtSuXVv333+/XV+3bt107do1/fbbb5Kk48ePS1K6cU8//XS67SUmJmY6to0bN6p58+bpEqwePXooNjZWP//8c2ZfhlNxcXHatm2bOnbsaDcth4eHh7p3765Tp07p8OHDWd5unz59lJqaqnbt2qlp06Z2rXv37pKk3r17262TmWN9s6tXr+rrr7/W7NmzVbJkSVWuXPm2X8/x48dVvXp1+fj42PpKlCihRx991G6cs/dZfHy8wsPDVa9ePe3evdvhlSuO/lMht7j6PXXu3DktXLhQn332me677z6Xfe4AAID1yNEdy885urMCsr+/vypUqGC7EvrQoUM6ffq0unbtajeuYsWK6fLizB5nY4w8PT3T3fi0b9++8vLK3DWba9euVXJysu69916HefaOHTuyHL8VNm7cqNq1a6tevXp2/T169ND169fTTf+SEUffiwBYiyvRAdy2OnXqyMvLS15eXipdurQaN26sXr16KTU1VR06dLjlFRUvvviimjdvrpUrV+rkyZMqXLiwrRC7YcMGSVJMTIyOHz+udu3aaePGjbp06ZIuXLhwyysVbuX06dNasWKFxo0bpzNnzqh79+5q1aqVRo4cafvf/V9//VUHDx7UlClT5OXlpcuXL6tDhw5q1KhRuu3t2bNHnTp1Ur9+/bRjxw5dv37dluz93fjx4/XUU08pPDxc//nPf3Tp0iU9++yzeuqppzRixAhdu3YtW6/p70JCQrR+/XqFh4drypQpSkpK0ksvvaQ6deqkSzwzo0SJEmrXrp3Wrl2bbg7INEOGDFGPHj0UEhJim98vM8d6xYoV2rt3r7Zv367z58+rUqVKGjx4sI4fP26b//t2Xs+iRYvUr18/ffLJJ/roo49UsmRJjRw5Mt2xvtX7bNCgQfrxxx+1efNmvf/++zp+/LgCAgJUtWpV/fOf/1SLFi0yPIbFixfXQw89lK4/MTFRv//+e4brO+OK99TPP/+s//3vf9q9e7cuX76smjVr6rnnntOWLVu44gUAgHyKHL3g5+iSNGbMGD322GP64osv9Pvvvys+Pl5VqlTRgAEDVKpUKY0YMULSXwXv119/XfPmzdOyZcv00UcfqXjx4ho3bly66VCioqK0fv16hYSE6PLlyzpx4oRatGihjh072o2Ljo7Wpk2bNGLECF24cEHHjx9XUFCQ+vTpo8uXL2cq/hMnTuiNN97QhAkTdM8992jNmjW6fPmyypQpowcffFCxsbEaN25cluK/lSJFijjMySVp27Ztmd7O302bNk09evTQypUr9cYbb+jEiRN68skn9dJLL+n9999Pd18jRzLzvQiAtSy/uymNRsufLe2u5WkSEhLM2bNnTXh4uBk1apQpVapUunXGjh1rzF+/XTOSzEMPPWS+/vprExERYeLj48358+dNeHi4eeqpp+zWa968udmxY4eJj483xhgTFhZmt72SJUtmuC9JJiIiwnz77bemY8eOZs+ePSYhIcEcO3bMDB48ON36VatWNWvWrDFXrlwxUVFRZsaMGaZt27bp7lRfvHhxs2TJEnPp0iWTmppqt09jjBk7dqzddmvXrm2WL19uLl++bBISEszOnTvT3eE+KCjIGGNMp06d7PrT7ub+9/GO2mOPPWY2bNhgoqOjTWxsrNmyZYt58sknHW5v2LBht9zWK6+8Yowx5umnn3Y65oUXXjDGGNOhQ4csHeshQ4aYH3/80Zw7d84kJCSY48ePm48++shUrFgxy68n7bjdfH4kmeeee87s27fPxMXFmb1795p///vfJiwszERERGTqfZZ2rObOnWtOnTplEhMTTVRUlPnxxx/N6NGjMzwXERERxplTp06le886ej+nHU9H27+d95QkM3HiRPPLL7+Yixcvmvj4ePPHH3+YqVOnmhIlSuTa3yc0Go1Go9Fc08jR/xrnDjm6JPPggw+aWbNmmZ07d5oLFy6Y5ORkExUVZVatWmXatGmTbnzv3r3NoUOHTEJCgjl48KDp2bOnw7y4TJkyZsmSJebChQvm8uXL5uOPPzb169dP9zrvuusu8+WXX5qLFy+aq1evmlWrVplatWqZiIgIu1w67X3ZoEEDh6/j6aefNhs3bjRXrlwx8fHxJiIiwixZssQ0b948W/E7auHh4U5zcmOMKVSoUIaxhoeHmz179jjcfoUKFcwnn3xizp8/bxITE82BAwfMsGHDjIeHR6bObWa/F9FoNGuax40FAAAAAAAAuJmwsDA1bdpUVapUsToUAMizmBMdAAAAAAAAAAAnKKIDAAAAAAAAAOAE07kAAAAAAAAAAOAEV6IDAAAAAAAAAOAERXQAAAAAAAAAAJygiA4AAAAAAAAAgBNeVgeQG+666y5FR0dbHQYAAAAgSQoICNDp06etDsMS5OYAAADISzKTmxf4Ivpdd92lyMhIq8MAAAAA7JQvX97tCunk5gAAAMiLMsrNC3wRPe0ql/Lly3PFC/A3fpLO3lguKynOwlgAAHAXAQEBioyMdMvclNw8byM3BAAA7iazuXmBL6KniY6OJlEH/ib1puVo8UUJAADkDnLzvIncEAAAwDFuLAoAAAAAAAAAgBMU0QEAAAAAAAAAcIIiOgAAAAAAAAAATrjNnOgAAAB5iZeXl8qVKydPT65pKGiMMbpw4YLi4phRGgAAIL/w8/NTqVKl5OHhYXUocBFX5uUU0QEAAHJZ6dKl9dZbb6lw4cJWh4Ic9P333yssLEzGGKtDAQAAgBMeHh7q1auXmjZtanUoyCGuyMspogNuLFnSuJuWAQA5z8PDQ3379lVMTIymTJmixMREq0OCi3l5eem+++5T586dJUnz58+3OCIgc8gNAQDuqFevXgoKCtIXX3yhgwcPKiUlxeqQ4CKuzMspogNuLFnSeKuDAAA3U7x4cd1333167733dPjwYavDQQ45evSoJKlLly76/PPPmdoF+QK5IQDA3fj7+6tp06b64osvtHLlSqvDQQ5wVV7OJJwAAAC5KCAgQJJ07tw5iyNBTjt48KAkqVSpUhZHAgAAAEdKliwp6f/yNhRMrsjLuRIdcGMekmreWD4giRlbASDnpd2oKDU11eJIkNPSfgrMzamQX5AbAgDcTVqexhQuBZsr8nKK6IAbKyJp341lf0n80BwAAMB9kRsCAAA4xnQuAAAAAAAAAAA4QREdAAAAGQoLC5MxRu+//36652bPni1jjMLCwuz6H3nkEaWkpGj16tXp1qlUqZKMMQ7bQw89lO04+/fvr2PHjik+Pl7bt29Xo0aNMvW6/t727t1rG9O3b1/98MMPunTpki5duqT169erYcOG2Y4RAAAAuF1Zyc//8Y9/aM6cOTpx4oQSEhJ05swZrVmzRg8//LBtnYiICId58auvvprtGJs0aaLt27crPj5eR48e1YsvvpjhOoGBgdqwYYMuX76sS5cuae3atapbt67t+erVq+u7777T2bNnbdt988035eWVsxOuUEQHAABAppw8eVLPPPOMChcubOvz9fVV165ddeLEiXTje/furVmzZqlRo0aqUKGCw222aNFCZcuWtWs7duzIVnydO3fW9OnTNWHCBNWrV0+bN2/W6tWrne5bkgYNGmS377vvvlsXL17Ul19+aRvTtGlTffbZZ2rWrJkeeeQRnTx5UuvWrdNdd92VrTgBAAAAV8hsfv7111+rbt26Cg4OVvXq1fX000/r+++/V4kSJey29/rrr6fLzWfNmpWt2CpXrqxVq1Zp8+bNqlevniZOnKiZM2eqY8eOTte54447tHbtWp08eVIPPfSQGjVqpGvXrmnt2rW2InlycrI+/vhjtWrVSjVq1NDgwYP1/PPPa/z48dmKM7OYEx0AAACZ8ttvv+mee+5Rx44dtXjxYklSx44dderUKR07dsxurJ+fnzp37qyGDRuqbNmy6tmzp958881027x48aKioqJcEt/QoUM1b948zZs3T5I0ZMgQtW7dWv3799fo0aMdrnPt2jVdu3bN9rhdu3a688477a6q7969u906zz//vP71r3+pRYsWWrRokUtiBwAAALIqM/l5sWLF1LhxYwUFBemHH36Q9Ffx/ddff023vejoaJfl5v369dPJkyc1ZMgQSdLBgwcVGBio4cOHa+nSpQ7XqVGjhkqUKKE33nhDf/75pyRp/Pjx2rNnjypWrKhjx44pIiJCERERtnVOnjypTz/9VI0bN3ZJ3M5wJToAAEAe4HeL5puFsYUzOTa7wsLC1KtXL9vj3r17a/78+enGdenSRYcOHdLhw4f1ySef2K2TWY0aNVJ0dPQtW0hIiCTJ29tbDRo00Lp16+y2sW7dOj366KOZ3mefPn20YcMGnTx50ukYPz8/eXt769KlS1l+TQAAAMj78ktuLmWcn8fExCg6Olrt27eXj4/Pbe0ro9x81apVtrGPPPJIutx87dq1CgwMdDr1yqFDh3T+/Hn16dNH3t7eKly4sPr06aO9e/c6/OWrJN17771q06aNNm3adFuvLSNciQ4AAJAHxN7iuZWSnrrp8TlJ/k7Gfi+p2U2Pj0v6h4NxHlmI7WaLFi1SaGiobU7zxx57TM8884yaNm1qN65Pnz765JNPJElr1qzRHXfcoRYtWmjjxo1247Zs2aLr16/b9RUrVkzXr1/X9u3b9cADD9wynrRCdqlSpeTl5ZXuypmoqCiVLVs2U6+tbNmyatu2rbp163bLcW+//bYiIyO1YcOGTG0XAAAA+Ut+yc2ljPPz1NRU9ezZUx999JH69eun3377TZs2bdLnn3+uPXv22G1r0qRJeuutt+z6nnrqKVuBOqPcPD4+3rZctmxZh7m5t7e3SpUqpbNnz6ZbPyYmRk2bNtXy5cv1+uuvS5IOHz6s1q1bKzU11W7sTz/9pPr166tw4cL64IMP9MYbb9wytttFER1wY8mSJt+0DABARi5evKiVK1cqODhYHh4eWrlypS5evGg3pnr16nrwwQdt8x2mpqbqiy++UO/evdMV0bt06aIDBw7Y9aUV1RMSEnT06NEsxWeMsXvs4eGRrs+Znj176sqVK/rmm2+cjhkxYoS6du2qpk2bKjExMUuxAXkduSEAAPlPZvLzpUuXauXKlWrcuLEeeeQRtWnTRiNHjlTfvn21cOFC27jJkydrwYIFdutGRkball2RmzvqT1O4cGHNnz9fP/30k7p27apChQpp+PDhWrVqlRo2bKiEhATb2C5duiggIEB169bV5MmTNXz4cE2ePNnhdl2BIjpyRO9ZOfemzcj8gSMs23d+kyxppNVBAAAkOb96RZJS//a49C3GXv/b48rZiubW5s+fr//+97+SpJdffjnd82k/v7w54fbw8FBycrKKFy+uK1eu2PpPnTrlNBlv1KiRVq9efctYJk6cqNDQUF24cEEpKSnprjovXbp0pud17N27txYtWqTkZMflw2HDhmn06NF6/PHH0121g7yP/DRj5IYAAPwlP+XmUsb5uSQlJiZqw4YN2rBhg95880199NFHGj9+vF0R/cKFC7cslEdHR98yjs2bN+uJJ56QJJ09e9Zhbp6cnJyuyJ+mW7duqly5sh555BFbob1bt266fPmy2rVrpy+++MI2Nm3O9AMHDqhQoUL68MMPNXXq1HS/cnUViugAAAB5QFweGJtZa9assc2nuHbtWrvnChUqpB49emjo0KHp5kD8+uuv9eyzz2r27NmZ2k9WpnNJTk7Wjh071LJlS7sryVu2bKnly5dnuK+goCBVq1bNdlPSvxs+fLhee+01tW7dWjt27MhU/AAAAMif8lNuLt06P3dm//79at++fZb2k5XpXLZu3ap//vOfds+3atVK27dvV0pKisP1/fz8dP36dbsr1dMee3o6v7Wnh4eHvL29bVe65wSK6IAb85BU8cbySUmZ+7E7AMDdXb9+XTVr1rQt3+ypp57SnXfeqXnz5unatWt2z3311Vfq06ePXRG9ZMmSKlOmjN24K1euKDExMcvTubz77rtatGiRtm/frq1bt+qFF15QxYoVNWfOHNuYiRMnqnz58goODrZbt0+fPvr555+1b9++dNsdMWKE3nzzTXXr1k3Hjx+3xRsTE6PY2FvNmAnkL+SGAADkT7fKz0uUKKEvv/xS8+fP1+7duxUdHa3AwECNHDky3cUmAQEB6XLzuLg42xXoWcnN58yZowEDBmjq1Kn66KOP9Mgjj6hPnz7q2rWrbUz79u0VGhpqi339+vWaPHmyZs+erVmzZsnT01OjRo1SSkqKwsPDJf11ZXpycrL27NmjxMRENWjQQKGhofriiy/SzZvuShTRATdWRH/d1EL666dKOfU/ogCAgsfZTzn79OmjDRs2pCugS39diT5mzBjVq1fPdgX53+dIl6RnnnnG7qeambVkyRKVLFlSb7zxhsqVK6e9e/fqiSee0MmTJ21jypUrp4oVK9qtV7RoUXXq1EmDBg1yuN2XXnpJvr6++vrrr+36x40bp/Hjx2c5TiCvIjcEACD/cpafx8TEaNu2bRoyZIjuvfdeeXt769SpU/roo480ceJEu7Fvvvmm3nzzTbu+OXPmqH///lmO5/jx43riiSc0bdo0vfzyyzp9+rReeeUVLV261DamWLFiuu+++2yPDx06pH/+858aO3astm7dquvXr2vnzp1q06aN7UakKSkpevXVV1W9enV5eHjoxIkTmj17tqZNm5blGLOCIjoAAAAy1KtXr1s+36FDhwy3sXPnTrufWObEzy3ff/99vf/++06fd/Q6rl27Jn9/5zNfVqlSxSWxAQAAAK6Slfx89OjRGj169C3H50TO+8MPP6hBgwZOn1+4cKHdnOySbPO2O7NkyRItWbLEZTFmlvPJZAAAAAAAAAAAcHMU0QEAAAAAAAAAcIIiOgAAAAAAAAAATlBEBwAAAAAAAADACYroAAAAAAAAAAA4QREdcGMpkmbfaCkWxwIA7sIYI0ny8vKyOBLkNF9fX0lSamqqxZFkbOzYsTLG2LUzZ86kGxMZGam4uDiFh4erVq1aFkWLnEJuCABwN9evX5f0f3kbCiZX5OV8ewPcWJKkAVYHAQBu5vz580pOTlaHDh20bNkypaRQqipoChUqpNKlS6tz585KSEjQ2bNnrQ4pU/bu3avHH3/c9vjmLxkjR47U0KFD1bNnTx0+fFivvfaa1q9frxo1aigmJsaKcJEDyA0BAO7mzJkzSkhIUL9+/bRkyRKdO3cuX1wAgcxxZV5OER0AACAXxcfHa9q0aRoyZIjuv/9+q8NBDjp48KBCQ0PzzX+UpKSkKCoqyuFzgwcP1oQJE7Rs2TJJUnBwsKKiotStWzd9+OGHuRkmAACAy6SkpGjMmDF6/vnn9dJLL1kdDnKIK/JyiuiAmyt1488LlkYBAO5l7969GjBggP7xj3/Iw8PD6nDgYsYYXbt2TVevXrVN35MfVKtWTZGRkUpMTNS2bds0evRoRUREqEqVKipXrpzWrVtnG5uUlKRNmzbp0UcfpYhewJAbAgDczfnz5xUaGqpixYqpaNGi5OcFiCvzcorogBvzk3T+xrK/pDgLYwEAdxMfH6+TJ09aHQYgSdq2bZt69Oihw4cPq0yZMnrttde0ZcsW1a5dW2XLlpWkdFepR0VFqVKlSrfcro+Pj90cowEBAa4PHi5DbggAcFfGGF25ckVXrlyxOhTkURTRAQAAADe3Zs0a2/LevXu1detWHT16VMHBwfr5558lKd3VOx4eHhle0RMSEqJx48a5PF4AAAAgN3laHQAAAACAvCUuLk579uxRtWrVbDdgSrsiPU3p0qWdzqGeJjQ0VEWLFrW18uXL51jMAAAAQE6hiA4AAADAjo+Pj2rWrKkzZ84oIiJCZ86cUcuWLW3Pe3t7KygoSFu2bLnldpKSkhQdHW3XAAAAgPzG0iJ648aNtWLFCkVGRsoYo3bt2qUbc99992n58uW6cuWKrl27pq1bt6pChQoWRAsAAAAUTJMnT1aTJk1UuXJlPfjgg/rqq69UtGhRLVy4UJI0ffp0jR49Wu3bt1ft2rW1YMECxcXFafHixRZHDgAAAOQ8S+dE9/f3165duxQWFqalS5eme/6ee+7Rjz/+qHnz5mns2LG6evWqatasqYSEBAuiBQAAAAqmu+++W5999plKlSql8+fP6+eff9bDDz9su/ntO++8oyJFiui9997TnXfeqW3btqlVq1aKiYmxOHIAAAAg51laRF+zZo3dTYz+bsKECVq1apVeffVVW19ERERuhAYAAAC4ja5du2Y4Zvz48Ro/fnwuRAMAAADkLXl2TnQPDw89+eSTOnz4sNasWaOoqCj9/PPPDqd8uZmPj48CAgLsGgDHUiQtuNFSLI0EAAAAViM3BAAAcCzPFtFLly6tgIAAjRo1SmvWrFGrVq20bNkyLV26VE2aNHG6XkhIiK5du2ZrkZGRuRg1kL8kSep1oyVZHAsAAACsRW4IAADgWJ4tont6/hXa8uXLNX36dO3atUuTJk3S//73P/Xr18/peqGhoSpatKitlS9fPrdCBgAAAAAAAAAUMJbOiX4rFy5cUHJysvbv32/Xf+DAATVq1MjpeklJSUpK4roJILP8bvwZZ2kUAAAAyAvIDQEAANLLs1eiJycn69dff1WNGjXs+qtXr64TJ05YFBVQsPhJir3R/DIYCwAAgIKN3BAAAMAxS69E9/f3V9WqVW2Pq1Sporp16+rSpUs6deqUJk+erC+++EI//PCDwsPD1aZNG/3zn/9U06ZNrQsaAAAAAAAAAOA2LC2iBwYG6vvvv7c9njZtmiRpwYIF6tWrl7755hv169dPISEhmjlzpg4dOqROnTrpp59+sihiAAAAAAAAAIA7sbSIvmnTJnl4eNxyTFhYmMLCwnIpIgAAAAAAAAAA/k+enRMdAAAAAAAAAACrUUQHAAAAAAAAAMAJiugAAAAAAAAAADhh6ZzoAKyVKunLm5YBAADgvsgNAQAAHKOIDrixREmdrQ4CAAAAeQK5IQAAgGNM5wIAAAAAAAAAgBMU0QEAAAAAAAAAcIIiOuDG/CSZG83P4lgAAABgLXJDAAAAxyiiAwAAAAAAAADgBEV0AAAAAAAAAACcoIgOAAAAAAAAAIATFNEBAAAAAAAAAHCCIjoAAAAAAAAAAE5QRAcAAAAAAAAAwAkvqwMAYJ1USStvWgYAAID7IjcEAABwjCI64MYSJT1ldRAAAADIE8gNAQAAHGM6FwAAAAAAAAAAnKCIDgAAAAAAAACAExTRATfmJynmRvOzOBYAAABYi9wQAADAMeZEB9ycv9UBAAAAIM8gNwQAAEiPK9EBAAAAAAAAAHCCIjoAAAAAAAAAAE5QRAcAAAAAAAAAwAmK6AAAAAAAAAAAOEERHQAAAAAAAAAAJ7ysDgCAda5L+v6mZQAAALgvckMAAADHKKIDbixBUjOrgwAAAECeQG4IAADgGNO5AAAAAAAAAADgBEV0AAAAAAAAAACcoIgOuDE/SeduND+LYwEAAIC1yA0BAAAcY050wM39w+oAAAAAkGeQGwIAAKTHlegAAAAAAAAAADhBER0AAAAAAAAAACcoogMAAAAAAAAA4ISlRfTGjRtrxYoVioyMlDFG7dq1czp2zpw5MsZo0KBBuRghAAAAAAAAAMCdWVpE9/f3165duzRgwIBbjmvXrp0eeughRUZG5lJkAAAAAAAAAABIXlbufM2aNVqzZs0tx9x1113673//q9atW2vlypW5FBngHq5L+vWmZQAAALgvckMAAADHLC2iZ8TDw0OLFi3S5MmTtX//fqvDAQqcBEkPWh0EAAAA8gRyQwAAAMfydBH91VdfVUpKimbOnJnpdXx8fOTr62t7HBAQkBOhAQAAAAAAAADcgKVzot9K/fr1NWjQIPXs2TNL64WEhOjatWu2xjzqAAAAAAAAAIDsyrNF9MaNG6t06dI6efKkkpOTlZycrMqVK2vq1KmKiIhwul5oaKiKFi1qa+XLl8/FqIH8pYikiButiMWxAAAAwFrkhgAAAI7l2elcFi1apA0bNtj1rV27VosWLVJYWJjT9ZKSkpSUlJTT4QEFgoekyjctAwAAwH2RGwIAADhmaRHd399fVatWtT2uUqWK6tatq0uXLunUqVO6dOmS3fjk5GSdPXtWhw8fzu1QAQAAAAAAAABuyNIiemBgoL7//nvb42nTpkmSFixYoF69elkUFQAAAAAAAAAAf7G0iL5p0yZ5eGT+h4JVqlTJwWgAAAAAAAAAALCXZ28sCgAAAAAAAACA1SiiAwAAAAAAAADghKXTuQCwlpG076ZlAAAAuC9yQwAAAMcoogNuLF5SHauDAAAAQJ5AbggAAOAY07kAAAAAAAAAAOAERXQAAAAAAAAAAJygiA64sSKS9t5oRSyOBQAAANYiNwQAAHCMOdEBN+YhqfZNywAAAHBf5IYAAACOcSU6AAAAAAAAAABOUEQHAAAAAAAAAMAJiugAAAAA7IwaNUrGGE2bNs2uf+zYsYqMjFRcXJzCw8NVq1YtiyIEAAAAcg9FdAAAAAA2gYGBeuGFF7Rr1y67/pEjR2ro0KEaMGCAGjZsqLNnz2r9+vW64447LIoUAAAAyB0U0QEAAABIkvz9/fXpp5/q+eef1+XLl+2eGzx4sCZMmKBly5Zp3759Cg4Olp+fn7p162ZRtAAAAEDuoIgOuDEj6fiNZiyNBAAA5AWzZ8/WypUrtXHjRrv+KlWqqFy5clq3bp2tLykpSZs2bdKjjz6a22Eih5AbAgAAOOZldQAArBMvqYrVQQAAgDyhS5cuql+/vho2bJjuubJly0qSoqKi7PqjoqJUqVIlp9v08fGRr6+v7XFAQICLokVOIDcEAABwjCvRAQAAADd39913a8aMGerevbsSExOdjjPG/vpkDw+PdH03CwkJ0bVr12wtMjLSZTEDAAAAuYUiOgAAAODmGjRooDJlymjHjh1KTk5WcnKymjZtqldeeUXJycm2K9DTrkhPU7p06XRXp98sNDRURYsWtbXy5cvn6OsAAAAAcgLTuQBurLCkH24sN5GUYGEsAADAOhs3blSdOnXs+sLCwnTw4EFNmjRJx44d05kzZ9SyZUv9/vvvkiRvb28FBQXp1VdfdbrdpKQkJSUl5WTocCFyQwAAAMcoogNuzFNSw5uWAQCAe4qJidG+ffvs+mJjY3Xx4kVb//Tp0zV69GgdOXJER44c0ejRoxUXF6fFixdbETJyALkhAACAYxTRAQAAAGTonXfeUZEiRfTee+/pzjvv1LZt29SqVSvFxMRYHRoAAACQoyiiAwAAAEinWbNm6frGjx+v8ePHWxANAAAAYB1+pQcAAAAAAAAAgBMU0QEAAAAAAAAAcIIiOgAAAAAAAAAATjAnOuDmzlsdAAAAAPIMckMAAID0KKIDbixOUmmrgwAAAECeQG4IAADgGNO5AAAAAAAAAADgBEV0AAAAAAAAAACcoIgOuLHCksJvtMIWxwIAAABrkRsCAAA4xpzogBvzlNT0pmUAAAC4L3JDAAAAx8iNAAAAAAAAAABwgiI6AAAAAAAAAABOUEQHAAAAAAAAAMAJiugAAAAAAAAAADhBER0AAAAAAAAAACcsLaI3btxYK1asUGRkpIwxateune05Ly8vvf3229q9e7diYmIUGRmphQsXqly5chZGDBQ8sTcaAAAAQG4IAACQnqVFdH9/f+3atUsDBgxI95yfn5/q16+vN998U/Xr11fHjh1VvXp1rVixwoJIgYIpTtIdN1qcxbEAAADAWuSGAAAAjnlZufM1a9ZozZo1Dp+7du2aWrVqZdc3cOBA/frrr6pQoYJOnTqVGyECAAAAAAAAANyYpUX0rCpWrJiuX7+uK1euOB3j4+MjX19f2+OAgIBciAwAAAAAAAAAUBDlmyK6r6+v3n77bS1evFjR0dFOx4WEhGjcuHG5F1ge1nvWZKtDQB7nK+nrG8udJCVaGAsAAACsRW4IAADgmKVzomeWl5eXPv/8c3l6euqll1665djQ0FAVLVrU1sqXL59LUQL5TyFJT95ohSyOBQAAANYiNwQAAHAsz1+J7uXlpSVLlqhKlSpq3rz5La9Cl6SkpCQlJSXlUnQAAAAAAAAAgIIsTxfR0wro1apVU7NmzXTp0iWrQwIAAAAAAAAAuBFLi+j+/v6qWrWq7XGVKlVUt25dXbp0SadPn9ZXX32l+vXr66mnnlKhQoVUpkwZSdKlS5eUnJxsVdgAAAAAAAAAADdhaRE9MDBQ33//ve3xtGnTJEkLFizQuHHj1K5dO0nSrl277NZr2rSpNm3alGtxAgAAAAAAAADck6VF9E2bNsnDw8Pp87d6DgAAAAAAAACAnOZpdQAAAAAAAAAAAORVefrGogByVpwkfu8BAAAAidwQAADAGa5EBwAAAAAAAADACYroAAAAAAAAAAA4QREdcGO+kpbcaL4WxwIAAABrkRsCAAA4RhEdcGOFJP37RitkcSwAAACwFrkhAACAYxTRAQAAAAAAAABwgiI6AAAAAAAAAABOUEQHAAAAAAAAAMAJiugAAAAAAAAAADhBER0AAAAAAAAAACcoogMAAAAAAAAA4ISX1QEAsE6cJP+blgEAAOC+yA0BAAAco4gOuDm+IAEAACANuSEAAEB6TOcCAAAAAAAAAIATFNEBN+YjKexG87E4FgAAAFiL3BAAAMAxiuiAG/OS1PNGY24nAAAA90ZuCAAA4BhFdAAAAAAAAAAAnKCIDgAAAAAAAACAExTRAQAAAAAAAABwgiI6AAAAAAAAAABOUEQHAAAAAAAAAMAJiugAAAAAAAAAADjhZXUAAKwTJ+kfNy0DAADAfZEbAgAAOEYRHXBzF6wOAAAAAHkGuSEAAEB6TOcCAAAAAAAAAIATFNEBN+Yj6b83mo/FsQAAAMBa5IYAAACOUUQH3JiXpJdvNOZ2AgAAcG/khgAAAI5RRAcAAAAAAAAAwAmK6AAAAAAAAAAAOJGtInrlypVdHAYAAACA7CA3BwAAAHJWtorof/zxh7777js9++yz8vX1dXVMAAAAADKJ3BwAAADIWdkqotetW1c7d+7U1KlTdfbsWc2ZM0cNGzZ0dWwAAAAAMkBuDgAAAOSsbBXR9+3bp2HDhql8+fLq1auXypYtqx9//FF79+7VkCFDVKpUKVfHCQAAAMABcnMAAAAgZ93WjUVTU1P1zTffqHPnznr11Vd17733asqUKfrzzz+1cOFClS1b9pbrN27cWCtWrFBkZKSMMWrXrl26MWPHjlVkZKTi4uIUHh6uWrVq3U7IAG4SL6nyjRZvaSQAAOB23W5uDpAbAgAAOHZbRfQGDRpo9uzZOnPmjIYOHaopU6bo3nvvVfPmzVW+fHktX778luv7+/tr165dGjBggMPnR44cqaFDh2rAgAFq2LChzp49q/Xr1+uOO+64nbAB3GAknbjRjMWxAACA23O7uTlAbggAAOCYV3ZWGjJkiHr16qUaNWpo1apV6tGjh1atWiVj/kq1jh8/rhdffFEHDx685XbWrFmjNWvWOH1+8ODBmjBhgpYtWyZJCg4OVlRUlLp166YPP/wwO6EDAAAABYqrcnMAAAAAjmWriN6/f3/Nnz9fYWFhioqKcjjm5MmT6tOnT7YDq1KlisqVK6d169bZ+pKSkrRp0yY9+uijFNEBF/CWNOHG8hhJyRbGAgAAsic3cnO4B3JDAAAAx7JVRK9evXqGY5KTk/Xxxx9nZ/OSZJuz8e9fBKKiolSpUiWn6/n4+MjX19f2OCAgINsxAAWdt6QRN5bHiS9KAADkR7mRm8M9kBsCAAA4lq0ies+ePRUTE6OvvvrKrv9f//qX/Pz8XJqgp/0MNY2Hh0e6vpuFhIRo3LhxLtv/7eo9a7LVIQAAAKAAc0Vu3q9fP/Xv31+VK1eWJO3bt0//+c9/7KZeHDt2rF544QXdeeed2rZtm15++WXt37/fpa8FAAAAyIuydWPRUaNG6cKFC+n6z507p9GjR992UJJ09uxZSf93RXqa0qVLO/2ZqiSFhoaqaNGitla+fHmXxAMAAADkRa7Izf/880+NGjVKgYGBCgwM1Hfffafly5erVq1akqSRI0dq6NChGjBggBo2bKizZ89q/fr1uuOOO1z6WgAAAIC8KFtF9EqVKikiIiJd/4kTJ1SxYsXbDkqSIiIidObMGbVs2dLW5+3traCgIG3ZssXpeklJSYqOjrZrAAAAQEHlitz8f//7n1avXq0jR47oyJEjeu211xQTE6OHH35YkjR48GBNmDBBy5Yt0759+xQcHCw/Pz9169bNpa8FAAAAyIuyVUQ/d+6c7r///nT9devW1cWLFzO9HX9/f9WtW1d169aV9NfNROvWrasKFSpIkqZPn67Ro0erffv2ql27thYsWKC4uDgtXrw4O2EDAAAABY6rcvM0np6e6tKli/z9/bV161ZVqVJF5cqV07p162xjkpKStGnTJj366KO33JaPj48CAgLsGgAAAJDfZGtO9M8//1wzZ85UdHS0fvjhB0lSUFCQZsyYoc8//zzT2wkMDNT3339vezxt2jRJ0oIFC9SrVy+98847KlKkiN577z3b3IutWrVSTExMdsIGAAAAChxX5eZ16tTR1q1bVbhwYcXExKhDhw46cOCAHnnkEUlKN6ViVFSUKlWqdMtt5rX7FQEAAADZka0i+muvvaZKlSpp48aNSklJkfTXFSsff/xxluZE37Rpkzw8PG45Zvz48Ro/fnx2wgQAAAAKPFfl5ocOHdIDDzyg4sWLq1OnTlq4cKGCgoJszxtj7MZ7eHik6/u70NBQvfvuu7bHAQEBioyMzHRMAAAAQF6QrSJ6cnKynnnmGb3++uuqW7eu4uPjtWfPHp08edLV8QHIQfGSat+0DAAA8h9X5ebJyck6evSoJGnHjh1q2LChBg0apEmTJkmSypYtq7Nnz9rGly5dOt3V6X+XlJSkpKSkLL4iWIXcEAAAwLFsFdHTpN14CED+ZCTttzoIAADgEq7OzT08POTr66uIiAidOXNGLVu21O+//y5J8vb2VlBQkF599VWX7Q/WIzcEAABwLFtFdE9PT/Xs2VMtWrRQ6dKl5elpf3/SFi1auCQ4AAAAALfmitx8woQJWr16tU6dOqWAgAA988wzatq0qdq0aSNJmj59ukaPHm0r1I8ePVpxcXFavHhxjrwmAAAAIC/JVhF9xowZ6tmzp1auXKm9e/dmOBcigLzJW1LaTKkTJSVbGAsAAMgeV+TmZcqU0aJFi1SuXDldvXpVu3fvVps2bbRhwwZJ0jvvvKMiRYrovffe05133qlt27apVatWiomJcfXLgYXIDQEAABzLVhH9mWeeUefOnbV69WpXxwMgF3lLGndjebL4ogQAQH7kity8b9++GY4ZP368xo8fn+19IO8jNwQAAHDMM+Mh6SUlJemPP/5wdSwAAAAAsojcHAAAAMhZ2SqiT506VYMGDXJ1LAAAAACyiNwcAAAAyFnZms6lUaNGatasmdq2bat9+/YpOdn+h36dOnVySXAAAAAAbo3cHAAAAMhZ2SqiX7lyRcuWLXN1LAAAAACyiNwcAAAAyFnZKqL37t3b1XEAAAAAyAZycwAAACBnZWtOdEkqVKiQWrRooRdeeEF33HGHJKlcuXLy9/d3WXAAAAAAMkZuDgAAAOScbF2JXrFiRa1Zs0YVK1aUr6+v1q9fr5iYGI0cOVKFCxdW//79XR0ngByQIKnhTcsAACD/ITeHq5AbAgAAOJatK9FnzJih7du3684771R8fLytf9myZWrRooXLggOQs65L2n6jXbc4FgAAkD3k5nAVckMAAADHsnUleqNGjfTYY48pOTnZrv/EiRMqX768SwIDAAAAkDFycwAAACBnZauI7unpqUKFCqXrv/vuuxUdHX3bQQHIHd6SBt1YniEp+RZjAQBA3kRuDlchNwQAAHAsW9O5rF+/XoMHD7Y9NsbI399f48eP16pVq1wVG4Ac5i1p8o3mbXEsAAAge8jN4SrkhgAAAI5l60r0IUOGKDw8XPv27VPhwoW1ePFiVatWTRcuXFDXrl1dHSMAAAAAJ8jNAQAAgJyVrSL6mTNn9MADD6hr166qX7++PD09NW/ePH366adKSOA+7rBW71mTrQ7BEvMHjrA6BAAAYAFycwAAACBnZauILkkJCQkKCwtTWFiYK+MBAAAAkEXk5gAAAEDOyVYR/bnnnrvl84sWLcpWMAAAAACyhtwcAAAAyFnZKqLPmDHD7rG3t7f8/PyUlJSkuLg4EnUAAAAgl5CbAwAAADnLMzsrlShRwq4FBASoRo0a+vHHH7l5EQAAAJCLyM0BAACAnJWtIrojf/zxh0aNGpXuShgAeVeCpKY3GrcdAwCg4CA3R3aQGwIAADiW7RuLOpKamqq77rrLlZsEkIOuS9pkdRAAACBHkJsjq8gNAQAAHMtWEf2f//yn3WMPDw+VK1dOAwYM0E8//eSSwAAAAABkjNwcAAAAyFnZKqJ/8803do+NMTp//ry+++47DRs2zBVxAcgFXpJeuLH8oaQUC2MBAADZQ24OVyE3BAAAcCxbRfRChQq5Og4AFvCRNPvG8gLxRQkAgPyI3ByuQm4IAADgmMtuLAoAAAAAAAAAQEGTrSvRp06dmumx/IQUAAAAyDnk5gAAAEDOylYRvV69eqpfv768vLx06NAhSVL16tWVmpqq3377zTbOGOOaKAEAAAA4RG4OAAAA5KxsFdG//fZbRUdHKzg4WFeuXJEkFS9eXGFhYdq8ebPeffddV8YIAAAAwAlycwAAACBnZWtO9GHDhikkJMSWpEvSlStX9Nprr/ETUQAAACAXkZsDAAAAOStbRfSiRYuqTJky6fpLly6tgICA2w4KAAAAQOaQmwMAAAA5K1tF9GXLliksLEydOnVS+fLlVb58eXXq1Enz5s3T0qVLXR0jgBySKOnJGy3R4lgAAED2kJvDVcgNAQAAHMvWnOj9+vXTlClT9Mknn8jb21uSlJKSonnz5mnEiBEuDRBAzkmVtMrqIAAAwG0hN4erkBsCAAA4lq0r0ePj4/Xyyy+rZMmSqlevnurXr68SJUro5ZdfVlxcnMuCK1SokN58800dO3ZMcXFxOnr0qF5//XV5eHi4bB8AAABAfpZbuTkAAADgrrJ1JXqacuXKqVy5cvrhhx+UkJDgqphsXn31VfXr10/BwcHat2+fAgMDFRYWpqtXr2rmzJku3x/gbrwkPXtj+VNJKRbGAgAAbk9O5+Yo+MgNAQAAHMtWEb1EiRJasmSJmjVrJmOMqlWrpoiICM2dO1dXrlzR8OHDXRLcI488ouXLl2vVqr9+VHjixAl17dpVgYGBLtk+4O58JC24sfyl+KIEAEB+lFu5OQo+ckMAAADHsjWdy7Rp05ScnKyKFSva/UT0iy++UJs2bVwW3I8//qgWLVqoWrVqkqT7779fjRo1shXVHfHx8VFAQIBdAwAAAAqq3MrNAQAAAHeVrSvRW7VqpdatWysyMtKu/8iRI6pUqZJLApOkSZMmqVixYjp48KBSU1NVqFAhjRkzRp9//rnTdUJCQjRu3DiXxQAAAADkZbmVmwMAAADuKltXovv7+zu8SVGpUqWUmJh420Gl6dKli7p3765u3bqpfv36Cg4O1vDhw9WjRw+n64SGhqpo0aK2Vr58eZfFAwAAAOQ1uZWbAwAAAO4qW0X0H374wa6QbYyRh4eHRowYofDwcJcFN3nyZL399tv64osvtHfvXn3yySeaNm2aQkJCnK6TlJSk6OhouwYAAAAUVLmVmwMAAADuKlvTuYwYMULff/+9AgMD5ePjo3feeUe1a9dWiRIl9Nhjj7ksOD8/P12/ft2uLzU1VZ6e2ar9AwAAAAVObuXmAAAAgLvKVjX6wIEDuv/++/XLL79o/fr18vf319KlS1WvXj0dO3bMZcF9++23GjNmjJ544glVqlRJ7du319ChQ7Vs2TKX7QMAAADIz3IrNwcAAADcVZavRPfy8tK6dev04osv5vgNPAcOHKg333xT7733nkqXLq3Tp0/rgw8+0H/+858c3S/gLhIl/fumZQAAkL/kZm6Ogo/cEAAAwLEsF9FTUlJUp04dGWNyIh47MTExGjJkiIYMGZLj+wLcUaqkr6wOAgAAZFtu5uYo+MgNAQAAHMvWdC4ff/yx+vTp4+pYAAAAAGQRuTkAAACQs7J1Y1EfHx/17dtXLVu21Pbt2xUbG2v3/LBhw1wSHICcVUhShxvLy/TX1UcAACB/ITeHq5AbAgAAOJalInqVKlV0/Phx1alTR7/99pskqXr16nZj+CkpkH/4SvryxrK/pDgLYwEAAFlDbg5XIzcEAABwLEtF9CNHjqhcuXJq3ry5JOnzzz/XK6+8onPnzuVIcAAAAAAcIzcHAAAAckeW5kT38PCwe9y2bVv5+/u7NCAAAAAAGSM3BwAAAHJHtm4smubviTsAAAAAa5CbAwAAADkjS0V0Y0y6eRWZZxEAAADIfeTmAAAAQO7I0pzoHh4eWrBggRITEyVJhQsX1pw5cxQbG2s3rlOnTq6LEAAAAEA65OYAAABA7shSEX3hwoV2jz/55BOXBgMAAAAgc8jNAQAAgNyRpSJ67969cyoOABZIktTzpmUAAJB/kJvD1cgNAQAAHMtSER1AwZIiaWGGowAAAOAOyA0BAAAcy9KNRQEAAAAAAAAAcCdciQ64sUKSWt9YXisp1cJYAAAAYC1yQwAAAMcoogNuzFfSyhvL/pLiLIwFAAAA1iI3BAAAcIzpXAAAAAAAAAAAcIIiOgAAAAAAAAAATjCdC4Db1nvWZEv2O3/gCEv2C2tY9T6TeK8BAAAAAODOuBIdAAAAAAAAAAAnKKIDAAAAAAAAAOAERXQAAAAAAAAAAJxgTnTAjSVJevmmZQAAALgvckMAAADHKKIDbixF0ntWBwEAAIA8gdwQAADAMaZzAQAAANzcqFGj9Msvv+jatWuKiorSsmXLVL169XTjxo4dq8jISMXFxSk8PFy1atWyIFoAAAAgd1FEB9yYp6SgG42/DAAAcF9BQUGaPXu2Hn74YbVs2VJeXl5at26d/Pz8bGNGjhypoUOHasCAAWrYsKHOnj2r9evX64477rAwcrgSuSEAAIBjTOcCuLHCkr6/sewvKc66UAAAgIXatm1r97hXr146f/68GjRooM2bN0uSBg8erAkTJmjZsmWSpODgYEVFRalbt2768MMPcz1muB65IQAAgGNcYAAAAADATrFixSRJly5dkiRVqVJF5cqV07p162xjkpKStGnTJj366KOWxAgAAADkFq5EBwAAAGDn3Xff1ebNm7Vv3z5JUtmyZSVJUVFRduOioqJUqVIlp9vx8fGRr6+v7XFAQEAORAsAAADkLK5EBwAAAGDz3//+V/fff7+6du2a7jljjN1jDw+PdH03CwkJ0bVr12wtMjLS5fECAAAAOY0iOgAAAABJ0syZM/X000+rWbNmdgXvs2fPSvq/K9LTlC5dOt3V6TcLDQ1V0aJFba18+fI5EzgAAACQgyiiAwAAANCsWbPUsWNHNW/eXMePH7d7LiIiQmfOnFHLli1tfd7e3goKCtKWLVucbjMpKUnR0dF2DQAAAMhvmBMdAAAAcHOzZ89Wt27d1K5dO0VHR6tMmTKSpKtXryohIUGSNH36dI0ePVpHjhzRkSNHNHr0aMXFxWnx4sVWhg4AAADkOIrogBtLljTipmUAAOCeXnrpJUnSpk2b7Pp79uyphQsXSpLeeecdFSlSRO+9957uvPNObdu2Ta1atVJMTEyux4ucQW4IAADgGEV0wI0lS5pidRAAAMByHh4emRo3fvx4jR8/PoejgVXIDQEAABxjTnQAAAAAAAAAAJzI80X0u+66S4sWLdKFCxcUGxurnTt3qn79+laHBRQInpICb7Q8/5cBAAAAchS5IQAAgGN5ejqX4sWL66efflJ4eLjatm2rc+fO6d5779WVK1esDg0oEApL+vXGsr+kOAtjAQAAgLXIDQEAABzL00X0V199VadOnVLv3r1tfSdOnLAwIgAAAAAAAACAO8nTv9J7+umntX37di1ZskRRUVH67bff1LdvX6vDAgAAAAAAAAC4iTxdRL/nnnvUv39/HTlyRK1bt9acOXM0c+ZMPffcc07X8fHxUUBAgF0DAAAAAAAAACA78vR0Lp6entq+fbvGjBkjSfr9999Vu3Zt9e/fX4sWLXK4TkhIiMaNG5eLUQKwSu9Zky3b9/yBIyzbNwAAAAAAAHJPnr4S/cyZM9q/f79d34EDB1SxYkWn64SGhqpo0aK2Vr58+ZwOEwAAAAAAAABQQOXpK9F/+ukn1ahRw66vevXqt7y5aFJSkpKSknI6NAAAAAAAAACAG8jTRfRp06Zpy5YtCgkJ0ZIlS/Tggw/qhRde0AsvvGB1aECBkCxp3E3LAAAAcF/khgAAAI7l6SL69u3b1aFDB4WGhuqNN95QRESEBg8erMWLF1sdGlAgJEsab3UQAAAAyBPIDQEAABzL00V0SVq5cqVWrlxpdRgAAAAAAAAAADeU54voAHKOh6SaN5YPSDIWxgIAAABrkRsCAAA4RhEdcGNFJO27sewvKc7CWAAAAGAtckMAAADHPK0OAAAAAAAAAACAvIoiOgAAAAAAAAAATlBEBwAAAAAAAADACYroAAAAAAAAAAA4QREdAAAAAAAAAAAnKKIDAAAAAAAAAOCEl9UBALBOsqTJNy0DAADAfZEbAgAAOEYRHXBjyZJGWh0EAAAA8gRyQwAAAMeYzgUAAAAAAAAAACe4Eh1wYx6SKt5YPinJWBgLAAAArEVuCAAA4BhFdMCNFZF0/Mayv6Q460IBAACAxcgNAQAAHGM6FwAAAAAAAAAAnKCIDgAAAAAAAACAExTRAQAAAAAAAABwgiI6AAAAAAAAAABOcGNRoIDoPWtyltfxSUySho+RJPWYMkFJvj6uDgsAAAAAAADI17gSHQAAAAAAAAAAJ7gSHXBj1z099V3jR2zLAAAAcF8pkmbftAwAAIC/UEQH3FiKt5c+7dzR6jAAAACQByRJGmB1EAAAAHkQl54CAAAAAAAAAOAEV6ID7swY3RETK0mKucNf8vCwOCAAAABYqdSNPy9YGgUAAEDeQhEdcGM+ScmaMXq8JKn/lAlK8vWxOCIAAABYxU/S+RvL/pLiLIwFAAAgL2E6FwAAAAAAAAAAnKCIDgAAAAAAAACAE0znAgAAAAA5qPesyZbte/7AEZbtGwAAoKDgSnQAAAAAAAAAAJygiA4AAAAAAAAAgBMU0QEAAAAAAAAAcII50QE3dt3TUz892MC2DAAAAPeVImnBTcsAAAD4C0V0wI2leHtp/nPPWB0GAAAA8oAkSb2sDgIAACAP4tJTAAAAAAAAAACc4Ep0wJ0ZI5+kZElSko+35OFhcUAAAACwkt+NP+MsjQIAACBv4Up0wI35JCXr/eFj9P7wMbZiOgAAANyTn6TYG80vg7EAAADuJF8V0UeNGiVjjKZNm2Z1KAAAAAAAAAAAN5BviuiBgYF64YUXtGvXLqtDAQAAAAAAAAC4iXxRRPf399enn36q559/XpcvX7Y6HAAAAAAAAACAm8gXRfTZs2dr5cqV2rhxY4ZjfXx8FBAQYNcAAAAAAAAAAMgOL6sDyEiXLl1Uv359NWzYMFPjQ0JCNG7cuJwNCoDb6z1rsmX7nj9whGX7tvJ1AwAAAAAAWCFPX4l+9913a8aMGerevbsSExMztU5oaKiKFi1qa+XLl8/hKAEAAAAAAAAABVWevhK9QYMGKlOmjHbs2GHr8/LyUpMmTTRgwAD5+vrq+vXrduskJSUpKSkpt0MF8qXrnh7a/sD9tmUAAAC4r1RJX960DAAAgL/k6SL6xo0bVadOHbu+sLAwHTx4UJMmTUpXQAeQNSne3nq/z3NWhwEAAIA8IFFSZ6uDAAAAyIPydBE9JiZG+/bts+uLjY3VxYsX0/UDAAAAAAAAAOBqeXpOdAAAAAAAAAAArJSnr0R3pFmzZlaHABQYPolJen/4GElS/ykTlOTrY3FEAAAAsIqfpNgby/6S4iyMBQAAIC/hSnQAAAAAAAAAAJygiA4AAAAAAAAAgBMU0QEAAAAAAAAAcIIiOgAAAAAAAAAATlBEBwAAAAAAAADACYroAAAAANS4cWOtWLFCkZGRMsaoXbt26caMHTtWkZGRiouLU3h4uGrVqmVBpAAAAEDuoogOuLHrnh7aXes+7a51n657elgdDgAAsJC/v7927dqlAQMGOHx+5MiRGjp0qAYMGKCGDRvq7NmzWr9+ve64445cjhQ5JVXSyhst1eJYAAAA8hIvqwMAYJ0Ub2/N6N/H6jAAAEAesGbNGq1Zs8bp84MHD9aECRO0bNkySVJwcLCioqLUrVs3ffjhh7kVJnJQoqSnrA4CAAAgD+JKdAAAAAC3VKVKFZUrV07r1q2z9SUlJWnTpk169NFHLYwMAAAAyHlciQ4AAADglsqWLStJioqKsuuPiopSpUqVnK7n4+MjX19f2+OAgICcCRAAAADIQVyJDrgxn8QkvTdstN4bNlo+iUlWhwMAAPI4Y4zdYw8Pj3R9NwsJCdG1a9dsLTIyMqdDxG3wkxRzo/lZHAsAAEBeQhEdcHO+ScnyTUq2OgwAAJCHnT17VtL/XZGepnTp0umuTr9ZaGioihYtamvly5fP0Thx+/xvNAAAAPwfiugAAAAAbikiIkJnzpxRy5YtbX3e3t4KCgrSli1bnK6XlJSk6OhouwYAAADkN8yJDgAAAED+/v6qWrWq7XGVKlVUt25dXbp0SadOndL06dM1evRoHTlyREeOHNHo0aMVFxenxYsXWxg1AAAAkPMoogMAAABQYGCgvv/+e9vjadOmSZIWLFigXr166Z133lGRIkX03nvv6c4779S2bdvUqlUrxcTEWBQxAAAAkDsoogMAAADQpk2b5OHhccsx48eP1/jx43MpIgAAACBvoIgOAAAc6j1rsmX7nj9whGX7BgAAAADgZhTRATdmPDx0sOo9tmUAAAC4r+uSvr9pGQAAAH+hiA64sWQfb00e1N/qMAAAAJAHJEhqZnUQAAAAeZCn1QEAAAAAAAAAAJBXUUQHAAAAAAAAAMAJiuiAG/NJTNL0kHGaHjJOPolJVocDAAAAC/lJOnej+VkcCwAAQF7CnOiAmwuIibU6BAAAAOQR/7A6AAAAgDyIK9EBAAAAAAAAAHCCIjoAAAAAAAAAAE4wnQsAAAAAFFC9Z03O9FifxCRp+BhJUo8pE5Tk63Nb+54/cMRtrQ8AAJBXcCU6AAAAAAAAAABOUEQHAAAAAAAAAMAJpnMB3Jjx8FBExbttywAAAHBf5IYAAACOUUQH3Fiyj7feGjHI6jAAAACQB5AbAgAAOMZ0LgAAAAAAAAAAOEERHQAAAAAAAAAAJ5jOBXBjPklJenPCFEnS62OGK8nHx+KIAAAAYBVyQwAAAMcoogPuzEilLl22LQMAAMCNkRsCAAA4lKencxk1apR++eUXXbt2TVFRUVq2bJmqV69udVgAAAAAAAAAADeRp4voQUFBmj17th5++GG1bNlSXl5eWrdunfz8/KwODQAAAAAAAADgBvL0dC5t27a1e9yrVy+dP39eDRo00ObNmy2KCgAAAAAAAADgLvL0leh/V6xYMUnSpUuXLI4EAAAAAAAAAOAO8vSV6H/37rvvavPmzdq3b5/TMT4+PvL19bU9DggIyI3QAAAAAAAAAAAFUL4pov/3v//V/fffr0aNGt1yXEhIiMaNG5c7QQH5nYcUWbaMbRn5Q+9Zk60OAbmI8w0AyDXkhgAAAA7liyL6zJkz9fTTT6tJkyaKjIy85djQ0FC9++67tscBAQEZrgO4qyQfH70xZrjVYQAAACAPIDfM/6z8z/f5A0dYtm8AAHJani+iz5o1Sx06dFDTpk11/PjxDMcnJSUpKSkp5wMDAAAAAAAAABR4ebqIPnv2bHXr1k3t2rVTdHS0ypT566eFV69eVUJCgsXRAQAAAAAAAAAKujxdRH/ppZckSZs2bbLr79mzpxYuXGhFSECB4pOUpNcmz5QkvTXiFSX5+FgcEQAAAKxCbggAAOBYni6ie3hwNxsgRxmp/Nko2zIAAADcGLkhAACAQ55WBwAAAAAAAAAAQF5FER0AAAAAAAAAACfy9HQuAAAAAID8qfesyZbte/7AEZbtGwAAFDxciQ4AAAAAAAAAgBMU0QEAAAAAAAAAcILpXAB35iFdKHGnbRkAAABujNwQAADAIYrogBtL8vHRq+NHWx0GAAAA8gByQwAAAMeYzgUAAAAAAAAAACcoogMAAAAAAAAA4ATTuQBuzDspWa/OeE+SNGnQS0r28bY4IgAAAFiF3NA1es+abHUIAADAxSiiA27MwxhVOfmnbRkAAADui9wQAADAMaZzAQAAAAAAAADACYroAAAAAAAAAAA4QREdAAAAAAAAAAAnKKIDAAAAAAAAAOAERXQAAAAAAAAAAJzwsjoAANaKvsPf6hCAPK/3rMlWh+B2rDzm8weOsGzf7orzDeQd5IYAAADpUUQH3FiSr48Gh46zOgwAAADkAeSGAAAAjjGdCwAAAAAAAAAATlBEBwAAAAAAAADACaZzAdyYd1KyBr8/V5I0vX9fJft4WxwRAAAArEJuCAAA4BhFdMCNeRij+/44ZlsGAACA+yI3BAAAcIzpXAAAAAAAAAAAcIIiOgAAAAAAAAAATjCdCwAAAACgQOk9a7LVIbgdK4/5/IEjLNs3rzv3Wfm6AbgvrkQHAAAAAAAAAMAJiugAAAAAAAAAADjBdC6Am0v08bY6BAAAAOQR5IYAAADpUUQH3FiSr49emjrR6jAAAACQB5AbAgAAOMZ0LgAAAAAAAAAAOEERHQAAAAAAAAAAJ5jOBXBjXsnJennux5Kk2X17KMWbOTABAADcFbkhAACAYxTRATfmed3o/v0HbcsAAABwX+SGyK96z5psdQiWcNfXDSDnWPn3yvyBIyzbd2YwnQsAAAAAAAAAAE5QRAcAAAAAAAAAwIl8UUTv37+/jh07pvj4eG3fvl2NGjWyOiQAAADALZGbAwAAwN3k+SJ6586dNX36dE2YMEH16tXT5s2btXr1alWoUMHq0AAAAAC3Qm4OAAAAd5Tni+hDhw7VvHnzNG/ePB08eFBDhgzRqVOn1L9/f6tDAwAAANwKuTkAAADckZfVAdyKt7e3GjRooLffftuuf926dXr00UcdruPj4yNfX1/b44CAALs/c1thbx9L9gtkho+RdOOzUdjHR568XwHAspzBnVmZL1lxvvPreyy/5+bk5RkjNwSQH+TXf0eB/MDd8vKs7DdPF9FLlSolLy8vRUVF2fVHRUWpbNmyDtcJCQnRuHHj0vVHRkbmRIhA/jdwuCRpmsVhAEBeMfvFV6wOAbnIyvMdEBCg6Ohoy/afVeTmboLcEEAeR64GFExWf7Yzys3zdBE9jTHG7rGHh0e6vjShoaF699137fpKlCihS5cu5Vh8jgQEBCgyMlLly5fPV1+OcGuc14KJ81pwcW4LJs5rweRu5zUgIECnT5+2OoxsITfHrXCscwfHOXdwnHMHxzl3cJxzB8c5d7j6OGcmN8/TRfQLFy4oJSUl3ZUtpUuXTncFTJqkpCQlJSXZ9Vn5po2OjuZDUwBxXgsmzmvBxbktmDivBZO7nNf8+BrJzZEVHOvcwXHOHRzn3MFxzh0c59zBcc4drjrOmdlGnr6xaHJysnbs2KGWLVva9bds2VJbtmyxKCoAAADA/ZCbAwAAwF3l6SvRJendd9/VokWLtH37dm3dulUvvPCCKlasqDlz5lgdGgAAAOBWyM0BAADgjvJ8EX3JkiUqWbKk3njjDZUrV0579+7VE088oZMnT1od2i0lJiZq3LhxSkxMtDoUuBDntWDivBZcnNuCifNaMHFe8wdyc2SEY507OM65g+OcOzjOuYPjnDs4zrnDiuPsIcnxXYAAAAAAAAAAAHBzeXpOdAAAAAAAAAAArEQRHQAAAAAAAAAAJyiiAwAAAAAAAADgBEV0AAAAAAAAAACcoIh+G/r3769jx44pPj5e27dvV6NGjW45vkmTJtq+fbvi4+N19OhRvfjii7kUKbIiK+c1KChIxph0rUaNGrkYMTLSuHFjrVixQpGRkTLGqF27dhmuw+c178vqeeXzmj+MGjVKv/zyi65du6aoqCgtW7ZM1atXz3A9PrN5W3bOK59ZuFJW83ZkXXbyLWRNdv+NRNb069dPu3bt0tWrV3X16lVt2bJFbdq0sTqsAm/UqFEyxmjatGlWh1LgjB07Nl0+debMGavDKpDuuusuLVq0SBcuXFBsbKx27typ+vXrWx1WgRIREeHwO8J///vfHN83RfRs6ty5s6ZPn64JEyaoXr162rx5s1avXq0KFSo4HF+5cmWtWrVKmzdvVr169TRx4kTNnDlTHTt2zOXIcStZPa9pqlevrrJly9rakSNHciliZIa/v7927dqlAQMGZGo8n9f8IavnNQ2f17wtKChIs2fP1sMPP6yWLVvKy8tL69atk5+fn9N1+Mzmfdk5r2n4zOJ2ZTe/Q9Zk999lZN7t/F2KzPvzzz81atQoBQYGKjAwUN99952WL1+uWrVqWR1agRUYGKgXXnhBu3btsjqUAmvv3r12+dT/+3//z+qQCpzixYvrp59+UnJystq2batatWpp2LBhunLlitWhFSgNGza0ey8//vjjkqQvv/wyV/ZvaFlvP//8s3nvvffs+vbv328mTpzocPzbb79t9u/fb9f3/vvvmy1btlj+WmjZP69BQUHGGGOKFStmeey0zDVjjGnXrt0tx/B5zX8tM+eVz2v+bKVKlTLGGNO4cWOnY/jM5r+WmfPKZ5bmqpbV/I52+y0z/y7Tbr9l5u9SmmvaxYsXTe/evS2PoyA2f39/c+jQIdOiRQsTHh5upk2bZnlMBa2NHTvW7Ny50/I4CnoLDQ01P/zwg+VxuFubNm2aOXLkSK7siyvRs8Hb21sNGjTQunXr7PrXrVunRx991OE6jzzySLrxa9euVWBgoLy8vHIsVmReds5rmp07d+r06dPasGGDmjZtmoNRIjfweS3Y+LzmL8WKFZMkXbp0yekYPrP5T2bOaxo+s7gdt5PfAXldVv4uRfZ4enqqS5cu8vf319atW60Op0CaPXu2Vq5cqY0bN1odSoFWrVo1RUZG6tixY/rss89UpUoVq0MqcJ5++mlt375dS5YsUVRUlH777Tf17dvX6rAKNG9vb3Xv3l3z58/Plf1RRM+GUqVKycvLS1FRUXb9UVFRKlu2rMN1ypYt63C8t7e3SpUqlWOxIvOyc17PnDmj559/Xp06dVLHjh116NAhbdy4UY0bN86NkJFD+LwWTHxe86d3331Xmzdv1r59+5yO4TOb/2TmvPKZhStkJ78D8ovM/F2K7KlTp46io6OVmJioOXPmqEOHDjpw4IDVYRU4Xbp0Uf369RUSEmJ1KAXatm3b1KNHD7Vu3VrPP/+8ypYtqy1btqhEiRJWh1ag3HPPPerfv7+OHDmi1q1ba86cOZo5c6aee+45q0MrsNq3b6/ixYtrwYIFubI/Ls+6DcYYu8ceHh7p+jIa76gf1srKeT18+LAOHz5se/zzzz+rQoUKGj58uDZv3pyjcSJn8XktePi85j///e9/df/992fqBoB8ZvOPzJ5XPrNwpazm7UBel5V/I5F1hw4d0gMPPKDixYurU6dOWrhwoYKCgiiku9Ddd9+tGTNmqFWrVkpMTLQ6nAJtzZo1tuW9e/dq69atOnr0qIKDg7mRqwt5enpq+/btGjNmjCTp999/V+3atdW/f38tWrTI4ugKpj59+mj16tW5dqNcrkTPhgsXLiglJSXd1SulS5dOd5VLmrNnzzocn5ycrIsXL+ZYrMi87JxXR37++WdVq1bN1eEhF/F5dR98XvOumTNn6umnn1azZs0UGRl5y7F8ZvOPrJxXR/jMIqtcld8Becnt/l2KjCUnJ+vo0aPasWOHRo8erV27dmnQoEFWh1WgNGjQQGXKlNGOHTuUnJys5ORkNW3aVK+88oqSk5Pl6Um5KqfExcVpz5495FQudubMGe3fv9+u78CBA6pYsaJFERVsFStW1OOPP665c+fm2j75WykbkpOTtWPHDrVs2dKuv2XLltqyZYvDdbZu3ZpufKtWrbR9+3alpKTkWKzIvOycV0fq1auXa/8LhpzB59V98HnNm2bNmqWOHTuqefPmOn78eIbj+czmD1k9r47wmUVWuSq/A/IKV/xdiqzz8PCQr6+v1WEUKBs3blSdOnX0wAMP2Nqvv/6qTz/9VA888ICuX79udYgFlo+Pj2rWrElO5WI//fSTatSoYddXvXp1nThxwqKICrZevXrp3LlzWrlyZa7u1/I7qebH1rlzZ5OYmGh69epl7rvvPvPuu++a6OhoU7FiRSPJTJw40SxcuNA2vnLlyiYmJsZMnTrV3HfffaZXr14mMTHRdOzY0fLXQsv+eR00aJBp166dqVq1qqlVq5aZOHGiMcaYDh06WP5aaP/X/P39Td26dU3dunWNMcYMHjzY1K1b11SoUMHheeXzmj9aVs8rn9f80WbPnm0uX75smjRpYsqUKWNrhQsXto3hM5v/WnbOK59ZmqtaRvkdzTUto3+XabffMvN3Ke3224QJE0yjRo1MpUqVTJ06dcxbb71lUlJSzOOPP255bAW9hYeHm2nTplkeR0FrkydPNk2aNDGVK1c2Dz74oFmxYoW5evUq/w66uAUGBpqkpCQTEhJi7r33XtO1a1cTExNjunXrZnlsBa15eHiY48ePm9DQ0Nzet/UvPr+2/v37m4iICJOQkGC2b99uGjdubHsuLCzMhIeH241v0qSJ2bFjh0lISDDHjh0zL774ouWvgXZ753XEiBHmyJEjJi4uzly8eNH88MMPpm3btpa/Bpp9CwoKMo6EhYU5PK8Sn9f80LJ6Xvm85o/mTHBwsG0Mn9n817JzXvnM0lzZbpXf0VzTMvp3mXb7LTN/l9Juv82dO9f290VUVJRZv349BfRcahTRc6Z99tlnJjIy0iQmJpo///zTfPXVV6ZmzZqWx1UQ25NPPml2795t4uPjzf79+03fvn0tj6kgtpYtWxpjjKlWrVqu7tfjxgIAAAAAAAAAAPgb5kQHAAAAAAAAAMAJiugAAAAAAAAAADhBER0AAAAAAAAAACcoogMAAAAAAAAA4ARFdAAAAAAAAAAAnKCIDgAAAAAAAACAExTRAQAAAAAAAABwgiI6AAAAAAAAAABOUEQHgEwKCgpSRESE1WFkWnBwsC5fvmx1GFkSFhamZcuW2R6Hh4dr2rRpuR5HUFCQjDEqVqyYrS8iIkJBQUG5HgsAAAD+UqJECUVFRalSpUpWh5IpY8eO1c6dO60OI0v+nn9HRERo0KBBuR7H37/LvPzyy1q+fHmuxwEAaSiiA4ALfPDBB0pJSVGXLl2ytJ6jYm1eEx4eLmOMjDFKSEjQoUOHFBISIk/PnP8npGPHjnr99dczNTY/HEsAAABkX0hIiL799ludOHEi3XNr165VSkqKHnrooSxtMz9ceBIREWHLx2NjY7Vnzx698MILubLvhg0b6sMPP8zU2Jw8lh999JEaNmyoxx57zNb32muvaf369dq/f78WL14sHx+fHNk3AEgU0QHgthUpUkRdunTR5MmT1adPH6vDyREffvihypYtqxo1amjmzJl66623NHz4cIdjvb29Xbbfy5cvKyYmxmXbAwAAQP5UuHBh9enTR3Pnzk33XIUKFfTII4/ov//9b4HNx19//XWVLVtW999/v7755ht98MEH6ty5s8OxrszHL1y4oPj4eJdtL7uSkpK0ePFiDRw40Nb3zjvvqGXLlqpVq5YCAwN17733WhghgIKOIjoA3KZ///vf2r9/v0JDQ/XYY4+l+3mpj4+PJk2apJMnTyohIUGHDx9W7969ValSJX3//feSpCtXrsgYo7CwMEmOfza5c+dOjR071vZ4yJAh2r17t2JiYnTy5EnNnj1b/v7+OfIa4+LiFBUVpRMnTmj27NnauHGj2rdvL+n/pmAZNWqUIiMjdfjwYUnSXXfdpc8//1yXLl3ShQsX9M0339gdG09PT02dOlWXL1/WhQsXNGnSJHl4eNjt9+8/J83OsZSkESNG6OjRo4qLi9Pvv/+uTp062e2nbdu2OnTokOLi4vTdd9+pcuXKLjx6AAAAuF1t27ZVSkqKfv7553TP9erVS//73//0/vvvq0uXLvLz87N7vlixYvrggw909uxZxcfHa8+ePXryyScVFBSkBQsWqHjx4rYrvdPybWOM2rVrZ7edy5cvKzg42Pb47bff1qFDhxQbG6ujR4/qP//5j7y8vHLg1UvR0dGKiorS0aNH9frrr+vw4cO2fDw8PFyzZs3S1KlTdf78ea1fv16SVLNmTa1cuVLR0dE6e/asPv74Y5UsWdK2TT8/Py1cuFDR0dE6ffq0hg4dmm6/f/9ekp1j6e3trUmTJunPP/9UTEyMfv7553TTJAYHB+vEiROKjY3V0qVL7eJMs2LFCrVv316FCxeW9FdhXZLeeOMNffPNNzpw4MBtHGEAuDWK6ABwm/r06aNPPvlE165d06pVq9SrVy+75z/++GM988wzeuWVV1SzZk3169dPMTExOnXqlDp27ChJql69usqWLZul+QavX7+uV155RXXq1FFwcLCaN2+ud955x6WvzZn4+Hi7K1xatGihmjVrqmXLlnrqqadUpEgRhYeHKyYmRk2aNFGjRo0UExOjNWvW2NYbNmyYevfurT59+qhRo0YqUaKEOnTocMv9ZudYvvXWW+rVq5f69++v2rVra9q0afrkk0/UpEkTSdLdd9+tpUuXatWqVXrggQc0d+5cvf322zlx2AAAAJBNTZo00fbt2x0+16tXL33yySc6dOiQDh8+bHeFtoeHh1avXq1HH31U3bt3V61atTRq1CilpqZqy5YtGjRokK5evaqyZcuqbNmymjJlSqZjio6OVs+ePVWrVi0NGjRIzz//vIYMGXLbrzUzEhIS7PLx4OBgpaSk6LHHHtOLL76osmXLatOmTfr9998VGBioNm3aqEyZMlqyZIltncmTJ6tZs2bq0KGDWrVqpaZNm6pBgwZO95ndYxkWFqbHHntMzzzzjO6//359+eWXWrNmjapWrSpJevDBBzV//ny99957euCBBxQeHq7XXnst3f63b98ub29vPfjgg5KkgIAAffLJJ7p8+bJGjhzpkuMKALdiaDQajZZxCwoKMhEREXZ9VatWNYmJiaZkyZJGkmnXrp05ceKE8fDwMJJMtWrVjDHGtGjRwuk2jTGmWLFidv0RERFm0KBBdn07d+40Y8eOdRrfv/71L3P+/Hnb4+DgYHP58uXbft3h4eFm2rRpRpLx8PAwrVu3NgkJCebtt982kkxYWJg5c+aM8fb2tq3Tq1cvc+DAAbvteHt7m9jYWNOyZUsjyURGRpqRI0fani9UqJA5efKkWbZsmcN9Z+dY+vn5mbi4OPPwww/bjf3oo4/Mp59+aiSZCRMmmH379tk9Hxoamm5bERERJigoyPL3IY1Go9FoNJo7tmXLlpm5c+em63/88cdNVFSUKVSokJFkBg0aZDZv3mx7vmXLliYlJcVUq1bN4Xad5czGGNOuXTu7vsuXL5vg4GCnMQ4fPtz8+uuvtsdjx441O3fuvO3XfvN3g0KFCpng4GBjjDH9+vUz0l8582+//Wa3zvjx482aNWvs+sqXL2+MMaZatWrG39/fJCQkmM6dO9uev/POO01sbKwt//77vrNzLO+55x6TmppqypUrZ9e/fv16M2HCBCPJfPrpp2bVqlV2z3/22WcOz8vFixdNjx49jCTzzTffmLNnz5qtW7earVu3mkcffdTy9ymNRiu4LWd+ZwQAbqJPnz5au3atLl68KElatWqV5s2bp8cff1zr16/XAw88oJSUFG3atMnl+27atKlGjx6tWrVqqWjRovLy8lKRIkXk5+enuLi4DNdftWqVGjduLEk6ceKE6tSp43TsSy+9pL59+9pu1rNo0SKNHz/e9vyePXuUnJxse9ygQQNVrVpV0dHRdtspXLiw7r33Xm3btk133XWXtm7dansuNTVV27dvTzelS5rsHMtatWqpSJEitp+0pvHx8dHOnTsl/fUz17//LPjmuAAAAGC9IkWKKCEhIV1/nz599MUXXyg1NVWS9Nlnn2ny5MmqXr26Dh8+rAceeEB//vmnjhw54vKYOnXqpMGDB6tq1aq644475OXlpWvXrmV6/b1799qmO9y8ebOeeOIJp2MnTZqkt956S76+vkpKStI777yjDz74wPb836/Sb9CggZo1a5YuH5eke++9V0WKFJGvr69d3nv58mUdOnTIaQzZOZb169eXp6enbcrHNL6+vrbvUDVr1tSyZcvsnt+6davatGmTbnvx8fG26XrSprMBgNxAER0AssnT01M9evRQ2bJl7QrIXl5e6tOnj9avX5/tm/Bcv349XTH55p9rVqxYUatWrdKcOXP0+uuv69KlS2rUqJHmz5+f6RsJ9e3bV0WKFJEku/gd+fTTTzVhwgQlJibq9OnTun79ut3zsbGxdo89PT21Y8cOPfvss+m2df78+UzF93fZOZaenn/NWvbkk08qMjLS7rnExERJclq0BwAAQN5x4cIF3XnnnXZ9d955p9q3by9vb2/179/f1u/l5aXevXtr1KhROZaPP/TQQ/r88881duxYrV27VlevXtUzzzyjYcOGZXofTzzxhG2bGcU5efJkLViwQHFxcTpz5ky65x3l499++61effXVdGPPnDmjatWqZTrONNnNx1NSUtSgQQPbf3SkiYmJkZS1fLxEiRLZ/j4BALeDIjoAZNMTTzyhgIAA1atXzy4hvO+++/Tpp5+qRIkS2rNnjzw9PRUUFKSNGzem20bazXAKFSpk13/+/HmVK1fO9jggIEBVqlSxPQ4MDJSXl5eGDRsmY4wk2c39mBmnT5/O9NirV6/q6NGjmR7/22+/qUuXLjp37pzDq1/S9v/www9r8+bNkv46Bg0aNNBvv/3mcHx2juX+/fuVkJCgihUr6ocffnC43f3796e7iuXhhx/O8DUCAAAg9+zcuVPdu3e363v22Wf1559/psvlWrRooZCQEI0ZM0a7d+/W3XffrWrVqjm8gjopKSldLi6lz8erVq0qf39/2+PHHntMJ06c0MSJE219aVeVZ9bJkyczPfbChQtZzsc7deqk48ePpyteS9Iff/yhpKQkPfzwwzp16pQkqXjx4qpevbrTX35m51ju3LlTXl5eKl26tH788UeH292/f3+6/NtRPn7PPfeoSJEitl+UAkBu4saiAJBNffr00cqVK7V7927t27fP1r7++mudP39e3bt314kTJ7Rw4ULNnz9f7dq1U+XKlRUUFKR///vfkv6aRuX69et66qmnVKpUKVti/t133+m5555To0aNVLt2bS1cuNAu+T169Ki8vb01cOBAValSRd27d1e/fv0sOQ6OfPrpp7pw4YKWL1+uRo0aqXLlymrSpImmT5+u8uXLS5JmzJihUaNGqX379qpRo4bee+89FS9e3Ok2s3MsY2JiNGXKFE2bNk09evTQPffcowceeEAvvfSSevToIUmaM2eO7r33Xk2dOlXVq1dX165d1bNnz5w+RAAAAMiCtWvXqnbt2nb5Yp8+ffTVV1/Z5eL79u3T/PnzVbx4cT355JP64Ycf9MMPP+jrr7/W448/rsqVK6tNmzZq3bq1JOn48eMKCAhQ8+bNVbJkSdsvNb/77jsNGDBA9erVU4MGDTRnzhzbRRvSX0XoihUrqkuXLrrnnns0cOBAdejQIVePya3Mnj1bJUqU0GeffaaGDRuqSpUqatmypebNmydPT0/FxsZq3rx5mjx5spo3b67atWtrwYIF6X5xerPsHMsjR47ok08+0ccff6wOHTqocuXKCgwM1MiRI9W2bVtJ0syZM9WmTRuNGDFC1apV08svv+xwKpfGjRvr6NGjOnbsWM4cNADIgOUTs9NoNFp+aDffWLR06dImKSnJ/Otf/3I4dsaMGWbXrl1GkvH19TVTp041kZGRJiEhwRw+fNj07NnTNva1114zp0+fNqmpqSYsLMxIMgEBAebzzz83V65cMSdOnDA9evRId2PRwYMHm8jISBMbG2tWr15tunfvbnczzJy4saijFhYWZncz0LRWpkwZs2DBAnPu3DkTHx9v/vjjD/PBBx+YgIAAI/11U6Rp06aZK1eumEuXLpkpU6aYBQsWOL2xaHaPpSQzcOBAc+DAAZOYmGiioqLM6tWrTePGjW3PP/nkk+bw4cMmPj7ebNq0yfTs2ZMbi9JoNBqNRqPlsbZlyxbzwgsvGEmmfv36xhhjAgMDHY5dvny5Wb58uZH+umHmvHnzzPnz501cXJzZvXu3eeKJJ2xj33vvPXP+/HljjLHl2+XKlTNr1qwx0dHR5tChQ6ZNmzbpbiw6adIkc/78eXPt2jXz2WefmUGDBtnl3zlxY1FHzVm+XrVqVfP111+bS5cumdjYWLN//37z7rvv2p739/c3H3/8sYmJiTFnzpwxw4cPT7etv+87O8fSy8vLjBs3zhw7dswkJiaa06dPm6+//trUqVPHtl6vXr3MyZMnTWxsrFm+fLkZOnRouu8ya9asMa+++qrl70MajeaezePGAgAgA0FBQVqwYIHdtCpwHxEREerZs2eO3CQWAAAAGWvbtq2mTJmiOnXq2KY0hHuoXbu2Nm7cqOrVq2fp5q0A4CrMiQ4AAAAAAPK81atXq1q1aipfvrz+/PNPq8NBLrrrrrvUo0cPCugALEMRHQAAAAAA5AszZ860OgRYYP369VaHAMDNcWNRAMik48ePa/r06VaHAYtMnz5dx48ftzoMAAAAAACQy5gTHQAAAAAAAAAAJ7gSHQAAAAAAAAAAJyiiAwAAAAAAAADgBEV0AAAAAAAAAACcoIgOAAAAAAAAAIATFNEBAAAAAAAAAHCCIjoAAAAAAAAAAE5QRAcAAAAAAAAAwAmK6AAAAAAAAAAAOPH/AUTQBO3FUmw7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true = df['Y'].head(100)\n",
    "\n",
    "# Generate predictions with random normal errors\n",
    "np.random.seed(42)  # for reproducibility\n",
    "errors = np.random.normal(0, 1, size=100)\n",
    "y_pred = y_true + errors\n",
    "\n",
    "# Calculate metrics\n",
    "mae = np.mean(np.abs(y_true - y_pred))\n",
    "mse = np.mean((y_true - y_pred)**2)\n",
    "\n",
    "# Create side-by-side visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot absolute errors\n",
    "plt.subplot(121)\n",
    "plt.hist(np.abs(y_true - y_pred), bins=20, alpha=0.7)\n",
    "plt.axvline(mae, color='r', linestyle='--', label=f'MAE={mae:.2f}')\n",
    "plt.title('Distribution of Absolute Errors')\n",
    "plt.xlabel('|Actual - Predicted|')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Plot squared errors\n",
    "plt.subplot(122)\n",
    "plt.hist((y_true - y_pred)**2, bins=20, alpha=0.7)\n",
    "plt.axvline(mse, color='r', linestyle='--', label=f'MSE={mse:.2f}')\n",
    "plt.title('Distribution of Squared Errors')\n",
    "plt.xlabel('(Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing MSE and MAE\n",
    "There a couple key differences between MAE and MSE:\n",
    "\n",
    "1. **Sensitivity to outliers.** The MSE is more sensitive to outliers than the MAE. This is because the MSE squares the errors, so that large errors are penalized more heavily. Similarly, errors less than $1$ are made even smaller when squared, resulting in the distribution on the right: lot's of values clustered near $0$, and long tail of outliers. In contrast, the MAE treats all errors equally, leading to a more spread out distribution of errors.\n",
    "2. **Differentiability.** The MSE (considered as a function of the parameters $\\mathbf{w}$) is differentiable everywhere, while the MAE is not differentiable at zero. This means that the MSE can be minimized using calculus, while the MAE cannot. This is a key reason why the MSE is more commonly used in practice, because for large datasets, the optimization algorithms used to minimize the loss function (namely, the method of gradient descent) require differentiability!\n",
    "\n",
    "It turns out that both MSE and MAE loss functions arise naturally as notions of distance in linear algebra. First, let's review some basic facts about norms of vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance between points in $\\mathbb{R}^m$\n",
    "Vectors should usually be thought of as arrows starting at the origin. Very often, it is useful to visualize vectors with different starting points. When the starting point is not the origin, we refer to these as **displacement vectors.**\n",
    "\n",
    "The term \"displacement\" arises because displacement vectors naturally arise in the context of physics: if an object starts at a point $P = (a_1,\\dotsc,a_m)$ and ends at $Q = (b_1,\\dotsc,b_m)$, then the displacement of the object is given by the displacement vector \n",
    "\\begin{equation*}\n",
    "    \\vec{PQ} = \\begin{bmatrix} b_1 - a_1 \\\\ \\vdots \\\\ b_m - a_m \\end{bmatrix} \\in \\mathbb{R}^m.\n",
    "\\end{equation*}\n",
    "\n",
    "The **norm** or **magnitude** of a vector $\\mathbf{v} = \\begin{bmatrix} \\; v_1 & \\dotsb & v_m \\; \\end{bmatrix}^T \\in \\mathbb{R}^m$ is simply its length. The formula for the length is a generalization of the Pythagorean Theorem:\n",
    "\\begin{equation*}\n",
    "    || \\mathbf{v} ||^2 = v_1^2 + \\dotsb + v_n^2.\n",
    "\\end{equation*}\n",
    "\n",
    "If we have two vectors $\\mathbf{u},\\mathbf{v} \\in \\mathbb{R}^m$, then thinking of them as points, the displacement vector between them is $\\mathbf{v} - \\mathbf{u}$. The distance between them is therefore naturally defined as its length:\n",
    "\\begin{equation*}\n",
    "    \\textup{ Distance between $\\mathbf{u}$ and $\\mathbf{v}$ } = ||\\mathbf{v} - \\mathbf{u}|| = \\sqrt{\\sum_{i=1}^m (v_i - u_i)^2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "**Remark.** The distance formula above is sometimes called the *Euclidean norm* or *$L_2$-norm*. There are other norms that can be used to measure the length of a vector. The most common ones are:\n",
    "\n",
    "- **$L_1$-norm:** \n",
    "This is the sum of the absolute values of the entries:\n",
    "$$||\\mathbf{v}||_1 = |v_1| + \\dotsb + |v_m|.$$ \n",
    "This is also called the *Manhattan norm* or *Taxicab norm* because it measures the distance between two points in a city if you can only travel along the grid of streets.\n",
    "- $L_{\\infty}$**-norm:** \n",
    "This is the maximum of the absolute values of the entries: $$ ||\\mathbf{v}||_{\\infty} = \\max \\{|v_1|,\\dotsc,|v_m|\\}. $$  \n",
    "This is also called the *supremum norm* or *maximum norm*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE and MAE as distances in $\\mathbb{R}^m$\n",
    "Let us package together all the true target values $y_i$, predictions $\\hat{y}_i = F_{\\mathbf{w}}(\\mathbf{x}_i)$, and residuals $\\epsilon_i$ into vectors $\\mathbf{y},\\hat{\\mathbf{y}},\\epsilon \\in \\mathbb{R}^m$. By definition, we have\n",
    "\\begin{equation*}\n",
    "    \\epsilon = \\mathbf{y} - \\hat{\\mathbf{y}} +  \\in \\mathbb{R}^m.\n",
    "\\end{equation*}\n",
    "This is pictured in the following diagram:\n",
    "\n",
    "<img src=\"assets/residual-diagram.png\" width=\"60%\"></img>\n",
    "\n",
    "Observe then that the MSE is the squared $L_2$-norm of the residual vector, and the MAE is the $L_1$-norm of the residual vector:\n",
    "\\begin{equation*}\n",
    "    \\begin{alignedat}{2}\n",
    "        \\textup{MSE}(\\mathbf{w}) & = \\frac{||\\epsilon||^2}{m}  && = \\dfrac{|| \\mathbf{y} - \\hat{\\mathbf{y}} ||_2^2}{m} ,\\\\\n",
    "        \\phantom{ } & && \\\\\n",
    "        \\textup{MAE}(\\mathbf{w}) & = \\frac{||\\epsilon||_1}{m}  && = \\dfrac{|| \\mathbf{y} - \\hat{\\mathbf{y}} ||_1}{m} .\n",
    "    \\end{alignedat}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression \n",
    "\n",
    "### The linear model\n",
    "The linear regression model is a simple yet powerful tool for predicting a continuous target variable. Suppose we have a dataset with $n$ features $X_1,\\dotsc,X_n$ and a target $Y$ (and $m$ instances). The linear regression model assumes that the target is a *linear function* of the features, plus some small noise term. Thus, the function $F_{\\mathbf{w}}$ is the linear function from $\\mathbb{R}^n \\to \\mathbb{R}$ defined by\n",
    "\\begin{equation*}\n",
    "    F_{\\mathbf{w}}(X_1,\\dotsc,X_n) = b + w_1 X_1 + \\dotsb + w_n X_n.\n",
    "\\end{equation*}\n",
    "Each $w_i$ can be interpreted as the weight or importance of the $i$-th feature in predicting the target; If all other features are held constant, then a one-unit increase in $X_i$ will result in a $w_i$-unit increase in the target. (Can you rephrase this in terms of partial derivatives?)  The parameter $b$ is called the **bias** or **intercept** term. It can be interpreted as the expected value of the target when all features are zero. Putting them all together, a linear model assumes that the target is a constant (the bias), plus a wighted sum of the features, plus some noise.\n",
    "\n",
    "### MSE loss for linear regression\n",
    "Linear functions are in one-to-one correspondence with vectors of parameters $$\\mathbf{w} = \\begin{bmatrix} \\; b & w_1 & \\dotsb & w_n \\; \\end{bmatrix} \\in \\mathbb{R}^{n+1}.$$\n",
    "Thus, the parameter space for our model is $\\mathbb{R}^{n+1}$. The prediction $\\hat{y}_i$ for the $i$-th instance is given by\n",
    "\\begin{align*}\n",
    "    \\hat{y}_i & = F_{\\mathbf{w}}(x_{i1},\\dotsc,x_{in}) \\\\\n",
    "    & = b + w_1 x_{i1} + \\dotsb + w_n x_{in}.\n",
    "\\end{align*}\n",
    "Thus, the $i$-th residual is given by\n",
    "\\begin{align*}\n",
    "    \\epsilon_i & = y_i - \\hat{y}_i \\\\\n",
    "    & = y_i - (b + w_1 x_{i1} + \\dotsb + w_n x_{in}).\n",
    "\\end{align*}\n",
    "We take as our loss function $J(\\mathbf{w})$ the MSE (which is the standard choice for linear regression). Thus, we have\n",
    "\\begin{align*}\n",
    "    J(\\mathbf{w}) & = \\frac{1}{m} \\sum_{i=1}^m \\epsilon_i^2 \\\\\n",
    "                & = \\frac{1}{m} \\sum_{i=1}^m (y_i - (b + w_1 x_{i1} + \\dotsb + w_n x_{in}))^2.\n",
    "\\end{align*}\n",
    "(NOTE: If we wish to emphasize that the loss depends on the parameters $\\mathbf{w}$ *and also* the design matrix $X$, we write $J(\\mathbf{w};X)$.)\n",
    "\n",
    "### Fitting the linear model\n",
    "\n",
    "In order to fit our linear model to the dataset, we need to find the special parameters $\\hat{\\mathbf{w}} = (\\hat{b}, \\hat{w}_1 , \\dotsc, \\hat{w}_n) \\in \\mathbb{R}^{n+1}$ that minimize the MSE loss function:\n",
    "\\begin{align*}\n",
    "    \\hat{\\mathbf{w}}&  = \\argmin_{\\mathbf{w} \\in \\mathbb{R}^{n+1}} J(\\mathbf{w}) \\\\\n",
    "    & = \\argmin_{\\mathbf{w} \\in \\mathbb{R}^{n+1}} \\frac{1}{m} \\sum_{i=1}^m \\epsilon_i^2 \\\\\n",
    "    & = \\argmin_{\\mathbf{w} \\in \\mathbb{R}^{n+1}} \\frac{1}{m} \\sum_{i=1}^m (y_i - (b + w_1 x_{i1} + \\dotsb + w_n x_{in}))^2.\n",
    "\\end{align*}\n",
    "\n",
    "To accomplish this, there are (broadly speaking) two approaches:\n",
    "\n",
    "1. **Analytical solution.** We can use calculus to find the (location of the) minimum of the loss function! This is possible because of some very useful properties of the function $J(\\mathbf{w})$:\n",
    "    - It is differentiable everywhere, which means that we can use calculus to find the minimum. Namely, we can compute the **gradient** of the loss function, which is a vector of partial derivatives of the loss function with respect to each parameter:\n",
    "    \\begin{equation*}\n",
    "        \\nabla J(\\mathbf{w}) = \\begin{bmatrix} \\; \\frac{\\partial J}{\\partial b} & \\frac{\\partial J}{\\partial w_1} & \\dotsb & \\frac{\\partial J}{\\partial w_n} \\; \\end{bmatrix}.\n",
    "    \\end{equation*}\n",
    "    Note that each entry in $\\nabla J(\\mathbf{w})$ is itself a function of $\\mathbf{w}$. Like all local minima/maxima of differentiable functions, the minimum of $J(\\mathbf{w})$ occurs at a point where the gradient is zero. Thus, a first step in finding the minimum is to compute the gradient and set it equal to zero:\n",
    "    \\begin{equation*}\n",
    "        \\textup{Compute and set }\\; \\frac{\\partial J}{\\partial b} = \\dotsb = \\frac{\\partial J}{\\partial w_n} = 0.\n",
    "    \\end{equation*}\n",
    "    - Each partial derivative turns out to be a *linear* function of the parameters $\\mathbf{w}$, so finding the parameters $\\mathbf{w}$ for which $\\nabla J(\\mathbf{w}) = 0$ amounts to solving a system of linear equations.\n",
    "    - It is a **convex function**, which means that the minimum is unique! In particular, this means if we find a minimum by setting the gradient to zero, then we have found the global minimum of the loss function!\n",
    "2. **Linear algebra solution.** We can use linear algebra to find the minimum of the loss function. This approach requires us to understand the geometry of the problem. Upon deconstructing what we want using the language of orthogonal projections, find the parameters $\\hat{\\mathbf{w}}$ amounts to inverting and multiplying certain matrices!\n",
    "3. **Gradient descent.** We can use a numerical optimization algorithm to find the minimum of the loss function. This approach is useful when the dataset is too large to fit in memory, or when the loss function is not differentiable. The most common algorithm for this is called **gradient descent**, which we will discuss in detail later. NOTE: This method is the most general out of the three, and can be applied to any reasonably nice model and loss function for regression. In particular, when we use neural networks to solve regression problems, we will use gradient descent (implemented cleverly in an algorithm known as **back-propagation**) to find the best parameters.\n",
    "    \n",
    "### Dot products\n",
    "In the next lecture, we derive the formulas for the best fit parameters in the simplest case of linear regression, aptly called **simple linear regression**; this is when we have only one features $X$ and one target $Y$. Following up on that, we derive the formulas for the general case. \n",
    "\n",
    "Before we get to that, now is a great time to recall the notion of a **dot product** of two vectors $\\mathbf{u},\\mathbf{v} \\in \\mathbb{R}^m$; it is the sum of the products of their corresponding entries:\n",
    "\\begin{equation*}\n",
    "    \\mathbf{u} \\cdot \\mathbf{v} = u_1v_1 + \\dotsb + u_mv_m.\n",
    "\\end{equation*}\n",
    "Note that $\\mathbf{u}^T$ can be thought of as a $1 \\times n$ matrix, and $\\mathbf{v}$ can be thought of as an $n \\times 1$ matrix. Then, the dot product is simply given by matrix multiplication:\n",
    "\\begin{align*}\n",
    "    \\mathbf{u} \\cdot \\mathbf{v} & = \\mathbf{u}^T \\mathbf{v} \\\\\n",
    "                                & = \\mathbf{v}^T \\mathbf{u} \\; \\in \\mathbb{R}.\n",
    "\\end{align*}\n",
    "You might notice right away that norms can be expressed in terms of dot products:\n",
    "\\begin{equation*}\n",
    "    ||\\mathbf{u}||^2 = \\mathbf{u} \\cdot \\mathbf{u} = \\mathbf{u}^T \\mathbf{u}.\n",
    "\\end{equation*}\n",
    "In general, whenever you see a sum of products of the form $u_1v_1 + \\dotsb + u_mv_m$, you should (immediately and without hesitation) think of it as a dot product $\\mathbf{u} \\cdot \\mathbf{v}$; more often than not, this viewpoint yields conceptual benefits, the reason being that the dot product encodes a LOT of useful information about how vectors are situated in space relative to each other. \n",
    "\n",
    "**Example.** One of the most important and frequently recurring customers in the dot product business is the **all-ones vector**\n",
    "\\begin{equation*}\n",
    "    \\mathbf{1} = \\begin{bmatrix} \\; 1 & 1 & \\dotsb & 1 \\; \\end{bmatrix}^T \\in \\mathbb{R}^m.\n",
    "\\end{equation*}\n",
    "For any vector $\\mathbf{u} \\in \\mathbb{R}^m$, we have $\\mathbf{1} \\cdot \\mathbf{u} = \\sum_{i=1}^m u_i$. Thus, if $\\overline{\\mathbf{u}} \\in \\mathbb{R}$ denotes the mean of the entries of $\\mathbf{u}$, then we have\n",
    "\\begin{equation*}\n",
    "    \\mathbf{1} \\cdot {\\mathbf{u}} = m \\overline{\\mathbf{u}}.\n",
    "\\end{equation*}\n",
    "\n",
    "**Example** The following example illustrates how to compute the dot product of two vectors in Python using vectorized code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product of columns X1 and X2: 15170824.290000003\n",
      "Dot product of rows 1 and 2: 1729129.47\n"
     ]
    }
   ],
   "source": [
    "# computing dot products of columns and rows in `df`\n",
    "\n",
    "# dot product of columns X1 and X2\n",
    "dot_col = np.dot(df['X1'], df['X2'])\n",
    "\n",
    "# dot product of rows 1 and 2\n",
    "dot_row = np.dot(df.iloc[0, :-1], df.iloc[1, :-1])\n",
    "\n",
    "# display the results\n",
    "print(f'Dot product of columns X1 and X2: {dot_col}')\n",
    "print(f'Dot product of rows 1 and 2: {dot_row}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A different view of the dot product\n",
    "The algebraic formula for the dot product is short and sweet. Incredibly enough, there is another way to define the dot product, which is even more geometric in nature. Namely, if $\\mathbf{u},\\mathbf{v} \\in \\mathbb{R}^m$ are two vectors, then the dot product is given by\n",
    "\\begin{equation*}\n",
    "    \\mathbf{u} \\cdot \\mathbf{v} = ||\\mathbf{u}|| \\cdot ||\\mathbf{v}|| \\cdot \\cos(\\theta),\n",
    "\\end{equation*}\n",
    "where $\\theta$ is the angle between the two vectors. (To make sense of the phrase \"angle between the two vectors\", you need to visualize the plane spanned by the two vectors!)\n",
    "\n",
    "Since $\\cos \\theta$ ranges between $-1$ and $1$, we can see the following properties:\n",
    "\n",
    "1. $\\mathbf{u} \\cdot \\mathbf{v} = 0$ if and only if $\\theta = 90^{\\circ}$. When this holds, we say that the vectors are **orthogonal**.\n",
    "2. $\\mathbf{u} \\cdot \\mathbf{v} > 0$ if and only if $\\theta < 90^{\\circ}$, i.e. the two vectors point roughly in the same direction (this can be made more precise using the terminology of \"half-spaces\").\n",
    "3. $\\mathbf{u} \\cdot \\mathbf{v} < 0$ if and only if $\\theta > 90^{\\circ}$, i.e. the two vectors point roughly in opposite directions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
