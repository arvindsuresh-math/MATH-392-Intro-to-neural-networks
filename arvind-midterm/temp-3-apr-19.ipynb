{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b1e164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device (Apple Silicon GPU)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import election_project as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3943d968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataHandler initialized:\n",
      "  Using 115 features\n",
      "  Test year: 2020\n",
      "  Dataloaders created for cross-validation and final training.\n"
     ]
    }
   ],
   "source": [
    "dh = ep.DataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce91912",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1 = ep.MLP1Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9c57f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MODEL_NAME',\n",
       " 'PARAM_GRID',\n",
       " '_MLP1Net',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_network',\n",
       " '_train_one_fold',\n",
       " 'best_params',\n",
       " 'cross_validate',\n",
       " 'evaluate',\n",
       " 'final_loss_history',\n",
       " 'load_model',\n",
       " 'loss_save_path',\n",
       " 'model',\n",
       " 'results_save_path',\n",
       " 'state_dict_save_path',\n",
       " 'train_final_model',\n",
       " 'weighted_cross_entropy_loss']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mlp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3956ba36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Cross-Validation for MLP1 ---\n",
      "  Testing config 1: {'dropout_rate': 0.1, 'learning_rate': 0.01, 'n_hidden': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.081266, Val Loss: 1.154333\n",
      "    Early stopping at epoch 35. Best val loss 1.141784 at epoch 15.\n",
      "      Epoch 25/100 -> Train Loss: 1.105176, Val Loss: 1.084009\n",
      "      Epoch 50/100 -> Train Loss: 1.109668, Val Loss: 1.083237\n",
      "    Early stopping at epoch 55. Best val loss 1.080291 at epoch 35.\n",
      "      Epoch 25/100 -> Train Loss: 1.101728, Val Loss: 1.104878\n",
      "    Early stopping at epoch 48. Best val loss 1.092106 at epoch 28.\n",
      "    Avg Val Score (Weighted CE): 1.104727\n",
      "  Testing config 2: {'dropout_rate': 0.1, 'learning_rate': 0.01, 'n_hidden': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.084161, Val Loss: 1.153684\n",
      "    Early stopping at epoch 38. Best val loss 1.139728 at epoch 18.\n",
      "      Epoch 25/100 -> Train Loss: 1.110247, Val Loss: 1.093603\n",
      "      Epoch 50/100 -> Train Loss: 1.112277, Val Loss: 1.083133\n",
      "    Early stopping at epoch 58. Best val loss 1.080117 at epoch 38.\n",
      "      Epoch 25/100 -> Train Loss: 1.106491, Val Loss: 1.108929\n",
      "    Early stopping at epoch 40. Best val loss 1.095243 at epoch 20.\n",
      "    Avg Val Score (Weighted CE): 1.105030\n",
      "  Testing config 3: {'dropout_rate': 0.1, 'learning_rate': 0.01, 'n_hidden': 128}\n",
      "      Epoch 25/100 -> Train Loss: 1.083505, Val Loss: 1.156030\n",
      "    Early stopping at epoch 37. Best val loss 1.142580 at epoch 17.\n",
      "      Epoch 25/100 -> Train Loss: 1.107781, Val Loss: 1.083898\n",
      "    Early stopping at epoch 34. Best val loss 1.080820 at epoch 14.\n",
      "      Epoch 25/100 -> Train Loss: 1.108479, Val Loss: 1.099382\n",
      "    Early stopping at epoch 40. Best val loss 1.094199 at epoch 20.\n",
      "    Avg Val Score (Weighted CE): 1.105866\n",
      "  Testing config 4: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'n_hidden': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.079668, Val Loss: 1.148276\n",
      "    Early stopping at epoch 44. Best val loss 1.144784 at epoch 24.\n",
      "      Epoch 25/100 -> Train Loss: 1.103890, Val Loss: 1.079758\n",
      "      Epoch 50/100 -> Train Loss: 1.103846, Val Loss: 1.078494\n",
      "      Epoch 75/100 -> Train Loss: 1.103637, Val Loss: 1.078789\n",
      "    Early stopping at epoch 91. Best val loss 1.077859 at epoch 71.\n",
      "      Epoch 25/100 -> Train Loss: 1.101317, Val Loss: 1.104334\n",
      "    Early stopping at epoch 33. Best val loss 1.098745 at epoch 13.\n",
      "    Avg Val Score (Weighted CE): 1.107129\n",
      "  Testing config 5: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'n_hidden': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.075406, Val Loss: 1.140307\n",
      "      Epoch 50/100 -> Train Loss: 1.074849, Val Loss: 1.144377\n",
      "    Early stopping at epoch 60. Best val loss 1.138845 at epoch 40.\n",
      "      Epoch 25/100 -> Train Loss: 1.101957, Val Loss: 1.080559\n",
      "      Epoch 50/100 -> Train Loss: 1.099293, Val Loss: 1.077212\n",
      "    Early stopping at epoch 72. Best val loss 1.076121 at epoch 52.\n",
      "      Epoch 25/100 -> Train Loss: 1.096296, Val Loss: 1.096027\n",
      "      Epoch 50/100 -> Train Loss: 1.094756, Val Loss: 1.096453\n",
      "    Early stopping at epoch 66. Best val loss 1.093559 at epoch 46.\n",
      "    Avg Val Score (Weighted CE): 1.102842\n",
      "  Testing config 6: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'n_hidden': 128}\n",
      "      Epoch 25/100 -> Train Loss: 1.075291, Val Loss: 1.141333\n",
      "    Early stopping at epoch 49. Best val loss 1.138680 at epoch 29.\n",
      "      Epoch 25/100 -> Train Loss: 1.100394, Val Loss: 1.077384\n",
      "    Early stopping at epoch 44. Best val loss 1.076438 at epoch 24.\n",
      "      Epoch 25/100 -> Train Loss: 1.095981, Val Loss: 1.098156\n",
      "      Epoch 50/100 -> Train Loss: 1.093463, Val Loss: 1.102605\n",
      "      Epoch 75/100 -> Train Loss: 1.094282, Val Loss: 1.098425\n",
      "    Early stopping at epoch 88. Best val loss 1.090567 at epoch 68.\n",
      "    Avg Val Score (Weighted CE): 1.101895\n",
      "  Testing config 7: {'dropout_rate': 0.1, 'learning_rate': 0.0001, 'n_hidden': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.101774, Val Loss: 1.166127\n",
      "      Epoch 50/100 -> Train Loss: 1.087971, Val Loss: 1.151686\n",
      "      Epoch 75/100 -> Train Loss: 1.086465, Val Loss: 1.148068\n",
      "      Epoch 100/100 -> Train Loss: 1.081441, Val Loss: 1.147003\n",
      "    Reached max_epochs (100). Best val loss 1.146051 at epoch 96.\n",
      "      Epoch 25/100 -> Train Loss: 1.120163, Val Loss: 1.095958\n",
      "      Epoch 50/100 -> Train Loss: 1.110752, Val Loss: 1.086135\n",
      "      Epoch 75/100 -> Train Loss: 1.106682, Val Loss: 1.083237\n",
      "      Epoch 100/100 -> Train Loss: 1.103545, Val Loss: 1.081456\n",
      "    Reached max_epochs (100). Best val loss 1.081276 at epoch 99.\n",
      "      Epoch 25/100 -> Train Loss: 1.124434, Val Loss: 1.124165\n",
      "      Epoch 50/100 -> Train Loss: 1.108481, Val Loss: 1.106645\n",
      "      Epoch 75/100 -> Train Loss: 1.104196, Val Loss: 1.100961\n",
      "      Epoch 100/100 -> Train Loss: 1.101874, Val Loss: 1.100538\n",
      "    Reached max_epochs (100). Best val loss 1.099623 at epoch 98.\n",
      "    Avg Val Score (Weighted CE): 1.108983\n",
      "  Testing config 8: {'dropout_rate': 0.1, 'learning_rate': 0.0001, 'n_hidden': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.086366, Val Loss: 1.155001\n",
      "      Epoch 50/100 -> Train Loss: 1.078896, Val Loss: 1.146214\n",
      "      Epoch 75/100 -> Train Loss: 1.077055, Val Loss: 1.144335\n",
      "      Epoch 100/100 -> Train Loss: 1.076395, Val Loss: 1.142902\n",
      "    Reached max_epochs (100). Best val loss 1.142689 at epoch 94.\n",
      "      Epoch 25/100 -> Train Loss: 1.109792, Val Loss: 1.087575\n",
      "      Epoch 50/100 -> Train Loss: 1.105701, Val Loss: 1.081761\n",
      "      Epoch 75/100 -> Train Loss: 1.102426, Val Loss: 1.080078\n",
      "      Epoch 100/100 -> Train Loss: 1.100943, Val Loss: 1.078187\n",
      "    Reached max_epochs (100). Best val loss 1.078187 at epoch 100.\n",
      "      Epoch 25/100 -> Train Loss: 1.105501, Val Loss: 1.103774\n",
      "      Epoch 50/100 -> Train Loss: 1.101391, Val Loss: 1.100600\n",
      "      Epoch 75/100 -> Train Loss: 1.098727, Val Loss: 1.099433\n",
      "      Epoch 100/100 -> Train Loss: 1.096606, Val Loss: 1.099061\n",
      "    Reached max_epochs (100). Best val loss 1.097620 at epoch 96.\n",
      "    Avg Val Score (Weighted CE): 1.106165\n",
      "  Testing config 9: {'dropout_rate': 0.1, 'learning_rate': 0.0001, 'n_hidden': 128}\n",
      "      Epoch 25/100 -> Train Loss: 1.081143, Val Loss: 1.148792\n",
      "      Epoch 50/100 -> Train Loss: 1.076045, Val Loss: 1.143246\n",
      "      Epoch 75/100 -> Train Loss: 1.075413, Val Loss: 1.141276\n",
      "      Epoch 100/100 -> Train Loss: 1.074521, Val Loss: 1.142124\n",
      "    Reached max_epochs (100). Best val loss 1.141052 at epoch 87.\n",
      "      Epoch 25/100 -> Train Loss: 1.105776, Val Loss: 1.081725\n",
      "      Epoch 50/100 -> Train Loss: 1.101250, Val Loss: 1.078888\n",
      "      Epoch 75/100 -> Train Loss: 1.100470, Val Loss: 1.078579\n",
      "      Epoch 100/100 -> Train Loss: 1.100034, Val Loss: 1.077380\n",
      "    Reached max_epochs (100). Best val loss 1.076754 at epoch 87.\n",
      "      Epoch 25/100 -> Train Loss: 1.100215, Val Loss: 1.099799\n",
      "      Epoch 50/100 -> Train Loss: 1.097344, Val Loss: 1.097586\n",
      "      Epoch 75/100 -> Train Loss: 1.094512, Val Loss: 1.097703\n",
      "    Early stopping at epoch 81. Best val loss 1.095614 at epoch 61.\n",
      "    Avg Val Score (Weighted CE): 1.104473\n",
      "  Testing config 10: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'n_hidden': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.089351, Val Loss: 1.153457\n",
      "    Early stopping at epoch 31. Best val loss 1.146950 at epoch 11.\n",
      "      Epoch 25/100 -> Train Loss: 1.119605, Val Loss: 1.084366\n",
      "    Early stopping at epoch 36. Best val loss 1.081806 at epoch 16.\n",
      "      Epoch 25/100 -> Train Loss: 1.108938, Val Loss: 1.105652\n",
      "    Early stopping at epoch 37. Best val loss 1.096215 at epoch 17.\n",
      "    Avg Val Score (Weighted CE): 1.108324\n",
      "  Testing config 11: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'n_hidden': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.091933, Val Loss: 1.153472\n",
      "    Early stopping at epoch 46. Best val loss 1.147449 at epoch 26.\n",
      "      Epoch 25/100 -> Train Loss: 1.120189, Val Loss: 1.092990\n",
      "    Early stopping at epoch 34. Best val loss 1.083853 at epoch 14.\n",
      "      Epoch 25/100 -> Train Loss: 1.122876, Val Loss: 1.122648\n",
      "    Early stopping at epoch 36. Best val loss 1.097814 at epoch 16.\n",
      "    Avg Val Score (Weighted CE): 1.109705\n",
      "  Testing config 12: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'n_hidden': 128}\n",
      "      Epoch 25/100 -> Train Loss: 1.099432, Val Loss: 1.158171\n",
      "    Early stopping at epoch 26. Best val loss 1.149145 at epoch 6.\n",
      "      Epoch 25/100 -> Train Loss: 1.129459, Val Loss: 1.098022\n",
      "    Early stopping at epoch 32. Best val loss 1.084480 at epoch 12.\n",
      "      Epoch 25/100 -> Train Loss: 1.122188, Val Loss: 1.131772\n",
      "    Early stopping at epoch 27. Best val loss 1.100602 at epoch 7.\n",
      "    Avg Val Score (Weighted CE): 1.111409\n",
      "  Testing config 13: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'n_hidden': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.086529, Val Loss: 1.148913\n",
      "      Epoch 50/100 -> Train Loss: 1.083471, Val Loss: 1.144407\n",
      "    Early stopping at epoch 53. Best val loss 1.143328 at epoch 33.\n",
      "      Epoch 25/100 -> Train Loss: 1.112221, Val Loss: 1.082352\n",
      "      Epoch 50/100 -> Train Loss: 1.108474, Val Loss: 1.080409\n",
      "    Early stopping at epoch 58. Best val loss 1.080234 at epoch 38.\n",
      "      Epoch 25/100 -> Train Loss: 1.107499, Val Loss: 1.103252\n",
      "    Early stopping at epoch 38. Best val loss 1.096940 at epoch 18.\n",
      "    Avg Val Score (Weighted CE): 1.106834\n",
      "  Testing config 14: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'n_hidden': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.079157, Val Loss: 1.143664\n",
      "      Epoch 50/100 -> Train Loss: 1.078630, Val Loss: 1.146152\n",
      "    Early stopping at epoch 50. Best val loss 1.140148 at epoch 30.\n",
      "      Epoch 25/100 -> Train Loss: 1.105411, Val Loss: 1.083061\n",
      "      Epoch 50/100 -> Train Loss: 1.103996, Val Loss: 1.078832\n",
      "    Early stopping at epoch 67. Best val loss 1.078007 at epoch 47.\n",
      "      Epoch 25/100 -> Train Loss: 1.098833, Val Loss: 1.097179\n",
      "    Early stopping at epoch 48. Best val loss 1.095130 at epoch 28.\n",
      "    Avg Val Score (Weighted CE): 1.104428\n",
      "  Testing config 15: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'n_hidden': 128}\n",
      "      Epoch 25/100 -> Train Loss: 1.077544, Val Loss: 1.141277\n",
      "      Epoch 50/100 -> Train Loss: 1.074854, Val Loss: 1.145818\n",
      "    Early stopping at epoch 61. Best val loss 1.137938 at epoch 41.\n",
      "      Epoch 25/100 -> Train Loss: 1.103947, Val Loss: 1.080481\n",
      "      Epoch 50/100 -> Train Loss: 1.101522, Val Loss: 1.077011\n",
      "    Early stopping at epoch 65. Best val loss 1.076870 at epoch 45.\n",
      "      Epoch 25/100 -> Train Loss: 1.097766, Val Loss: 1.100278\n",
      "      Epoch 50/100 -> Train Loss: 1.097799, Val Loss: 1.099161\n",
      "    Early stopping at epoch 52. Best val loss 1.094451 at epoch 32.\n",
      "    Avg Val Score (Weighted CE): 1.103086\n",
      "  Testing config 16: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'n_hidden': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.121981, Val Loss: 1.169299\n",
      "      Epoch 50/100 -> Train Loss: 1.097422, Val Loss: 1.157792\n",
      "      Epoch 75/100 -> Train Loss: 1.093205, Val Loss: 1.152671\n",
      "      Epoch 100/100 -> Train Loss: 1.088751, Val Loss: 1.147980\n",
      "    Reached max_epochs (100). Best val loss 1.147980 at epoch 100.\n",
      "      Epoch 25/100 -> Train Loss: 1.141276, Val Loss: 1.107712\n",
      "      Epoch 50/100 -> Train Loss: 1.122052, Val Loss: 1.088994\n",
      "      Epoch 75/100 -> Train Loss: 1.115585, Val Loss: 1.085064\n",
      "      Epoch 100/100 -> Train Loss: 1.114352, Val Loss: 1.083483\n",
      "    Reached max_epochs (100). Best val loss 1.083452 at epoch 98.\n",
      "      Epoch 25/100 -> Train Loss: 1.147803, Val Loss: 1.132524\n",
      "      Epoch 50/100 -> Train Loss: 1.120565, Val Loss: 1.107134\n",
      "      Epoch 75/100 -> Train Loss: 1.112062, Val Loss: 1.103001\n",
      "      Epoch 100/100 -> Train Loss: 1.111058, Val Loss: 1.101964\n",
      "    Reached max_epochs (100). Best val loss 1.100805 at epoch 99.\n",
      "    Avg Val Score (Weighted CE): 1.110745\n",
      "  Testing config 17: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'n_hidden': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.093122, Val Loss: 1.156352\n",
      "      Epoch 50/100 -> Train Loss: 1.085020, Val Loss: 1.148924\n",
      "      Epoch 75/100 -> Train Loss: 1.081227, Val Loss: 1.145008\n",
      "      Epoch 100/100 -> Train Loss: 1.080573, Val Loss: 1.144080\n",
      "    Reached max_epochs (100). Best val loss 1.143167 at epoch 97.\n",
      "      Epoch 25/100 -> Train Loss: 1.115872, Val Loss: 1.087263\n",
      "      Epoch 50/100 -> Train Loss: 1.108477, Val Loss: 1.082926\n",
      "      Epoch 75/100 -> Train Loss: 1.107167, Val Loss: 1.080315\n",
      "      Epoch 100/100 -> Train Loss: 1.107460, Val Loss: 1.080228\n",
      "    Reached max_epochs (100). Best val loss 1.079505 at epoch 96.\n",
      "      Epoch 25/100 -> Train Loss: 1.108861, Val Loss: 1.106205\n",
      "      Epoch 50/100 -> Train Loss: 1.104321, Val Loss: 1.101541\n",
      "      Epoch 75/100 -> Train Loss: 1.101747, Val Loss: 1.099524\n",
      "      Epoch 100/100 -> Train Loss: 1.099896, Val Loss: 1.099039\n",
      "    Reached max_epochs (100). Best val loss 1.098477 at epoch 89.\n",
      "    Avg Val Score (Weighted CE): 1.107050\n",
      "  Testing config 18: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'n_hidden': 128}\n",
      "      Epoch 25/100 -> Train Loss: 1.087272, Val Loss: 1.152472\n",
      "      Epoch 50/100 -> Train Loss: 1.081067, Val Loss: 1.147157\n",
      "      Epoch 75/100 -> Train Loss: 1.078959, Val Loss: 1.144340\n",
      "      Epoch 100/100 -> Train Loss: 1.079266, Val Loss: 1.143627\n",
      "    Reached max_epochs (100). Best val loss 1.142080 at epoch 97.\n",
      "      Epoch 25/100 -> Train Loss: 1.108949, Val Loss: 1.084390\n",
      "      Epoch 50/100 -> Train Loss: 1.106736, Val Loss: 1.080907\n",
      "      Epoch 75/100 -> Train Loss: 1.102448, Val Loss: 1.078927\n",
      "      Epoch 100/100 -> Train Loss: 1.101985, Val Loss: 1.078886\n",
      "    Reached max_epochs (100). Best val loss 1.078073 at epoch 99.\n",
      "      Epoch 25/100 -> Train Loss: 1.107527, Val Loss: 1.103032\n",
      "      Epoch 50/100 -> Train Loss: 1.100204, Val Loss: 1.101468\n",
      "      Epoch 75/100 -> Train Loss: 1.099187, Val Loss: 1.100245\n",
      "    Early stopping at epoch 87. Best val loss 1.098059 at epoch 67.\n",
      "    Avg Val Score (Weighted CE): 1.106070\n",
      "  Testing config 19: {'dropout_rate': 0.5, 'learning_rate': 0.01, 'n_hidden': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.098766, Val Loss: 1.165215\n",
      "    Early stopping at epoch 28. Best val loss 1.152477 at epoch 8.\n",
      "      Epoch 25/100 -> Train Loss: 1.126995, Val Loss: 1.090887\n",
      "      Epoch 50/100 -> Train Loss: 1.124674, Val Loss: 1.086235\n",
      "    Early stopping at epoch 52. Best val loss 1.084342 at epoch 32.\n",
      "      Epoch 25/100 -> Train Loss: 1.120516, Val Loss: 1.102991\n",
      "    Early stopping at epoch 40. Best val loss 1.098395 at epoch 20.\n",
      "    Avg Val Score (Weighted CE): 1.111738\n",
      "  Testing config 20: {'dropout_rate': 0.5, 'learning_rate': 0.01, 'n_hidden': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.098444, Val Loss: 1.162997\n",
      "    Early stopping at epoch 32. Best val loss 1.152358 at epoch 12.\n",
      "      Epoch 25/100 -> Train Loss: 1.131871, Val Loss: 1.091699\n",
      "    Early stopping at epoch 31. Best val loss 1.087325 at epoch 11.\n",
      "    Early stopping at epoch 24. Best val loss 1.100069 at epoch 4.\n",
      "    Avg Val Score (Weighted CE): 1.113250\n",
      "  Testing config 21: {'dropout_rate': 0.5, 'learning_rate': 0.01, 'n_hidden': 128}\n",
      "      Epoch 25/100 -> Train Loss: 1.101148, Val Loss: 1.163007\n",
      "    Early stopping at epoch 27. Best val loss 1.149913 at epoch 7.\n",
      "      Epoch 25/100 -> Train Loss: 1.137936, Val Loss: 1.100456\n",
      "    Early stopping at epoch 33. Best val loss 1.087175 at epoch 13.\n",
      "    Early stopping at epoch 24. Best val loss 1.096772 at epoch 4.\n",
      "    Avg Val Score (Weighted CE): 1.111287\n",
      "  Testing config 22: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'n_hidden': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.093355, Val Loss: 1.150857\n",
      "      Epoch 50/100 -> Train Loss: 1.088501, Val Loss: 1.150046\n",
      "    Early stopping at epoch 66. Best val loss 1.147259 at epoch 46.\n",
      "      Epoch 25/100 -> Train Loss: 1.120627, Val Loss: 1.084635\n",
      "      Epoch 50/100 -> Train Loss: 1.115857, Val Loss: 1.083707\n",
      "    Early stopping at epoch 57. Best val loss 1.082239 at epoch 37.\n",
      "      Epoch 25/100 -> Train Loss: 1.115239, Val Loss: 1.102213\n",
      "      Epoch 50/100 -> Train Loss: 1.111469, Val Loss: 1.099135\n",
      "    Early stopping at epoch 53. Best val loss 1.098649 at epoch 33.\n",
      "    Avg Val Score (Weighted CE): 1.109382\n",
      "  Testing config 23: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'n_hidden': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.085237, Val Loss: 1.145002\n",
      "    Early stopping at epoch 47. Best val loss 1.142725 at epoch 27.\n",
      "      Epoch 25/100 -> Train Loss: 1.108984, Val Loss: 1.079868\n",
      "      Epoch 50/100 -> Train Loss: 1.106183, Val Loss: 1.082763\n",
      "    Early stopping at epoch 68. Best val loss 1.078448 at epoch 48.\n",
      "      Epoch 25/100 -> Train Loss: 1.104646, Val Loss: 1.101139\n",
      "    Early stopping at epoch 38. Best val loss 1.096532 at epoch 18.\n",
      "    Avg Val Score (Weighted CE): 1.105902\n",
      "  Testing config 24: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'n_hidden': 128}\n",
      "      Epoch 25/100 -> Train Loss: 1.081562, Val Loss: 1.145853\n",
      "    Early stopping at epoch 42. Best val loss 1.141867 at epoch 22.\n",
      "      Epoch 25/100 -> Train Loss: 1.106241, Val Loss: 1.080795\n",
      "      Epoch 50/100 -> Train Loss: 1.103806, Val Loss: 1.079732\n",
      "    Early stopping at epoch 57. Best val loss 1.077735 at epoch 37.\n",
      "      Epoch 25/100 -> Train Loss: 1.101768, Val Loss: 1.099500\n",
      "      Epoch 50/100 -> Train Loss: 1.099735, Val Loss: 1.095340\n",
      "    Early stopping at epoch 60. Best val loss 1.095214 at epoch 40.\n",
      "    Avg Val Score (Weighted CE): 1.104939\n",
      "  Testing config 25: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'n_hidden': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.143855, Val Loss: 1.179685\n",
      "      Epoch 50/100 -> Train Loss: 1.110837, Val Loss: 1.162532\n",
      "      Epoch 75/100 -> Train Loss: 1.102914, Val Loss: 1.157549\n",
      "      Epoch 100/100 -> Train Loss: 1.098092, Val Loss: 1.156266\n",
      "    Reached max_epochs (100). Best val loss 1.154597 at epoch 94.\n",
      "      Epoch 25/100 -> Train Loss: 1.162903, Val Loss: 1.120394\n",
      "      Epoch 50/100 -> Train Loss: 1.132615, Val Loss: 1.093489\n",
      "      Epoch 75/100 -> Train Loss: 1.128192, Val Loss: 1.087398\n",
      "      Epoch 100/100 -> Train Loss: 1.120227, Val Loss: 1.085562\n",
      "    Reached max_epochs (100). Best val loss 1.085360 at epoch 93.\n",
      "      Epoch 25/100 -> Train Loss: 1.181954, Val Loss: 1.143596\n",
      "      Epoch 50/100 -> Train Loss: 1.137656, Val Loss: 1.112536\n",
      "      Epoch 75/100 -> Train Loss: 1.124694, Val Loss: 1.105667\n",
      "      Epoch 100/100 -> Train Loss: 1.122477, Val Loss: 1.103338\n",
      "    Reached max_epochs (100). Best val loss 1.103338 at epoch 100.\n",
      "    Avg Val Score (Weighted CE): 1.114432\n",
      "  Testing config 26: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'n_hidden': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.103455, Val Loss: 1.156792\n",
      "      Epoch 50/100 -> Train Loss: 1.090952, Val Loss: 1.149845\n",
      "      Epoch 75/100 -> Train Loss: 1.085056, Val Loss: 1.145611\n",
      "      Epoch 100/100 -> Train Loss: 1.084270, Val Loss: 1.147182\n",
      "    Reached max_epochs (100). Best val loss 1.145048 at epoch 90.\n",
      "      Epoch 25/100 -> Train Loss: 1.126372, Val Loss: 1.090267\n",
      "      Epoch 50/100 -> Train Loss: 1.114205, Val Loss: 1.083581\n",
      "      Epoch 75/100 -> Train Loss: 1.110969, Val Loss: 1.082464\n",
      "      Epoch 100/100 -> Train Loss: 1.108508, Val Loss: 1.080876\n",
      "    Reached max_epochs (100). Best val loss 1.080345 at epoch 97.\n",
      "      Epoch 25/100 -> Train Loss: 1.120865, Val Loss: 1.108616\n",
      "      Epoch 50/100 -> Train Loss: 1.110961, Val Loss: 1.100966\n",
      "      Epoch 75/100 -> Train Loss: 1.108588, Val Loss: 1.100483\n",
      "      Epoch 100/100 -> Train Loss: 1.106547, Val Loss: 1.099779\n",
      "    Reached max_epochs (100). Best val loss 1.099078 at epoch 82.\n",
      "    Avg Val Score (Weighted CE): 1.108157\n",
      "  Testing config 27: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'n_hidden': 128}\n",
      "      Epoch 25/100 -> Train Loss: 1.092877, Val Loss: 1.154669\n",
      "      Epoch 50/100 -> Train Loss: 1.084896, Val Loss: 1.148407\n",
      "      Epoch 75/100 -> Train Loss: 1.081158, Val Loss: 1.146294\n",
      "      Epoch 100/100 -> Train Loss: 1.079370, Val Loss: 1.144710\n",
      "    Reached max_epochs (100). Best val loss 1.144185 at epoch 96.\n",
      "      Epoch 25/100 -> Train Loss: 1.116175, Val Loss: 1.085962\n",
      "      Epoch 50/100 -> Train Loss: 1.108175, Val Loss: 1.082506\n",
      "      Epoch 75/100 -> Train Loss: 1.107775, Val Loss: 1.080834\n",
      "      Epoch 100/100 -> Train Loss: 1.106492, Val Loss: 1.080704\n",
      "    Reached max_epochs (100). Best val loss 1.079781 at epoch 98.\n",
      "      Epoch 25/100 -> Train Loss: 1.112282, Val Loss: 1.102434\n",
      "      Epoch 50/100 -> Train Loss: 1.105364, Val Loss: 1.099051\n",
      "      Epoch 75/100 -> Train Loss: 1.102268, Val Loss: 1.098172\n",
      "    Early stopping at epoch 90. Best val loss 1.096705 at epoch 70.\n",
      "    Avg Val Score (Weighted CE): 1.106890\n",
      "CV results saved to: ./results/mlp1_cv_results.csv\n",
      "\n",
      "Best MLP1 CV params: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'n_hidden': 128} (Score: 1.101895)\n",
      "--- Finished Cross-Validation for MLP1 ---\n"
     ]
    }
   ],
   "source": [
    "mlp1.cross_validate(dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b4dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([2008, 2012], 2016), ([2008, 2016], 2012), ([2012, 2016], 2008)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh.folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b5cfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout_rate': 0.1, 'learning_rate': 0.001, 'n_hidden': 128}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff486b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1.model == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a2e12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Final Model Training for MLP1 ---\n",
      "Using best hyperparameters from CV: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'n_hidden': 128}\n",
      "Starting training for 300 epochs...\n",
      "  Epoch 10/300 - Loss: 1.092228 (best 1.091887, no_improve=1)\n",
      "  Epoch 20/300 - Loss: 1.090710 (best 1.090426, no_improve=3)\n",
      "  Epoch 30/300 - Loss: 1.090250 (best 1.089448, no_improve=2)\n",
      "  Epoch 40/300 - Loss: 1.090023 (best 1.089095, no_improve=4)\n",
      "  Epoch 50/300 - Loss: 1.090161 (best 1.088174, no_improve=4)\n",
      "  Epoch 60/300 - Loss: 1.088740 (best 1.088039, no_improve=7)\n",
      "  Epoch 70/300 - Loss: 1.087679 (best 1.086871, no_improve=4)\n",
      "  Epoch 80/300 - Loss: 1.086951 (best 1.086500, no_improve=9)\n",
      "  Epoch 90/300 - Loss: 1.088630 (best 1.086500, no_improve=19)\n",
      "  Epoch 100/300 - Loss: 1.087319 (best 1.086500, no_improve=29)\n",
      "  Epoch 110/300 - Loss: 1.088456 (best 1.086459, no_improve=2)\n",
      "  Epoch 120/300 - Loss: 1.087650 (best 1.086152, no_improve=5)\n",
      "  Epoch 130/300 - Loss: 1.088319 (best 1.086152, no_improve=15)\n",
      "  Epoch 140/300 - Loss: 1.087161 (best 1.086152, no_improve=25)\n",
      "  Epoch 150/300 - Loss: 1.086455 (best 1.086152, no_improve=35)\n",
      "  Epoch 160/300 - Loss: 1.087059 (best 1.085962, no_improve=1)\n",
      "  Epoch 170/300 - Loss: 1.087818 (best 1.085962, no_improve=11)\n",
      "  Epoch 180/300 - Loss: 1.086020 (best 1.085962, no_improve=21)\n",
      "  Epoch 190/300 - Loss: 1.086944 (best 1.085962, no_improve=31)\n",
      "  Epoch 200/300 - Loss: 1.087924 (best 1.085877, no_improve=7)\n",
      "  Epoch 210/300 - Loss: 1.088045 (best 1.085877, no_improve=17)\n",
      "  Epoch 220/300 - Loss: 1.086201 (best 1.085877, no_improve=27)\n",
      "  Epoch 230/300 - Loss: 1.086947 (best 1.085469, no_improve=1)\n",
      "  Epoch 240/300 - Loss: 1.086433 (best 1.085356, no_improve=9)\n",
      "  Epoch 250/300 - Loss: 1.085678 (best 1.085356, no_improve=19)\n",
      "  Epoch 260/300 - Loss: 1.086241 (best 1.085356, no_improve=29)\n",
      "  Epoch 270/300 - Loss: 1.086520 (best 1.085356, no_improve=39)\n",
      "  Epoch 280/300 - Loss: 1.087526 (best 1.085356, no_improve=49)\n",
      "  Early stopping at epoch 281 (best loss 1.085356)\n",
      "Saved best model state_dict to: ./models/mlp1_final_state_dict.pth\n",
      "Saved training loss history to: ./results/mlp1_final_training_loss.csv\n",
      "--- Finished Final Model Training for MLP1 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_MLP1Net(\n",
       "  (layer_1): Linear(in_features=115, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layer_2): Linear(in_features=128, out_features=4, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1.train_final_model(dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f5f42dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLP1 on year '2020' with Aggregate Cross-Entropy (CPU)...\n",
      "Test data loaded: 3090 samples.\n",
      "  County-level predictions saved to: ./results/mlp1_2020_predictions.csv\n",
      "  Aggregate True Distribution: [0.31386703 0.01158256 0.28773913 0.38681123]\n",
      "  Aggregate Predicted Distribution: [0.3098109  0.04552347 0.2102628  0.43440282]\n",
      "  Aggregate Cross-Entropy: 1.174788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.3098109 , 0.04552347, 0.2102628 , 0.43440282], dtype=float32),\n",
       " 1.1747881174087524)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1.evaluate(dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10978037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout_rate': 0.1, 'learning_rate': 0.001, 'n_hidden': 128}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb0cd47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained mlp1 state_dict from: ./models/mlp1_final_state_dict.pth\n",
      "Building model architecture with params: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'n_hidden': 128, 'mean_cv_score': 1.1018949702483456}\n",
      "mlp1 model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arvindsuresh/Documents/MATH-392-Intro-to-neural-networks/arvind-midterm/election_project.py:890: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(self.state_dict_save_path, map_location=DEVICE))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_MLP1Net(\n",
       "  (layer_1): Linear(in_features=115, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layer_2): Linear(in_features=128, out_features=4, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = ep.MLP1Model()\n",
    "check.load_model(input_dim=dh.input_dim, output_dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34e53b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout_rate': 0.1,\n",
       " 'learning_rate': 0.001,\n",
       " 'n_hidden': 128,\n",
       " 'mean_cv_score': 1.1018949702483456}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979d2ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLP1 on year '2020' with Aggregate Cross-Entropy (CPU)...\n",
      "Test data loaded: 3090 samples.\n",
      "  County-level predictions saved to: ./results/mlp1_2020_predictions.csv\n",
      "  Aggregate True Distribution: [0.31386703 0.01158256 0.28773913 0.38681123]\n",
      "  Aggregate Predicted Distribution: [0.3098109  0.04552347 0.2102628  0.43440282]\n",
      "  Aggregate Cross-Entropy: 1.174788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.3098109 , 0.04552347, 0.2102628 , 0.43440282], dtype=float32),\n",
       " 1.1747881174087524)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.evaluate(dh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
