{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427245ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device (Apple Silicon GPU)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import election_project as ep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1cf4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import election_project as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc20cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataHandler initialized:\n",
      "  Using 115 features\n",
      "  Test year: 2020\n",
      "  Dataloaders created for cross-validation and final training.\n"
     ]
    }
   ],
   "source": [
    "dh = ep.DataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83a0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = ep.MLP2Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e28871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MODEL_NAME',\n",
       " 'PARAM_GRID',\n",
       " '_MLP2Net',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_network',\n",
       " '_train_one_fold',\n",
       " 'best_params',\n",
       " 'cross_validate',\n",
       " 'evaluate',\n",
       " 'final_loss_history',\n",
       " 'load_model',\n",
       " 'loss_save_path',\n",
       " 'model',\n",
       " 'results_save_path',\n",
       " 'state_dict_save_path',\n",
       " 'train_final_model',\n",
       " 'weighted_cross_entropy_loss']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mlp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c2bea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Cross-Validation for MLP2 ---\n",
      "  Testing config 1: {'dropout_rate': 0.1, 'learning_rate': 0.01, 'shared_hidden_size': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.084046, Val Loss: 1.151159\n",
      "    Early stopping at epoch 42. Best val loss 1.144669 at epoch 22.\n",
      "      Epoch 25/100 -> Train Loss: 1.108865, Val Loss: 1.087073\n",
      "    Early stopping at epoch 34. Best val loss 1.080831 at epoch 14.\n",
      "      Epoch 25/100 -> Train Loss: 1.100419, Val Loss: 1.105280\n",
      "    Early stopping at epoch 33. Best val loss 1.092496 at epoch 13.\n",
      "    Avg Val Score (Weighted CE): 1.105999\n",
      "  Testing config 2: {'dropout_rate': 0.1, 'learning_rate': 0.01, 'shared_hidden_size': 32}\n",
      "      Epoch 25/100 -> Train Loss: 1.081133, Val Loss: 1.150536\n",
      "      Epoch 50/100 -> Train Loss: 1.083321, Val Loss: 1.150751\n",
      "    Early stopping at epoch 51. Best val loss 1.145883 at epoch 31.\n",
      "      Epoch 25/100 -> Train Loss: 1.110977, Val Loss: 1.081461\n",
      "    Early stopping at epoch 31. Best val loss 1.081055 at epoch 11.\n",
      "      Epoch 25/100 -> Train Loss: 1.105250, Val Loss: 1.101677\n",
      "      Epoch 50/100 -> Train Loss: 1.102628, Val Loss: 1.097578\n",
      "    Early stopping at epoch 55. Best val loss 1.094092 at epoch 35.\n",
      "    Avg Val Score (Weighted CE): 1.107010\n",
      "  Testing config 3: {'dropout_rate': 0.1, 'learning_rate': 0.01, 'shared_hidden_size': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.088096, Val Loss: 1.161313\n",
      "    Early stopping at epoch 30. Best val loss 1.144441 at epoch 10.\n",
      "      Epoch 25/100 -> Train Loss: 1.115546, Val Loss: 1.083131\n",
      "    Early stopping at epoch 32. Best val loss 1.080543 at epoch 12.\n",
      "      Epoch 25/100 -> Train Loss: 1.104521, Val Loss: 1.097440\n",
      "    Early stopping at epoch 26. Best val loss 1.092927 at epoch 6.\n",
      "    Avg Val Score (Weighted CE): 1.105970\n",
      "  Testing config 4: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'shared_hidden_size': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.080975, Val Loss: 1.145869\n",
      "      Epoch 50/100 -> Train Loss: 1.078928, Val Loss: 1.144333\n",
      "    Early stopping at epoch 72. Best val loss 1.141781 at epoch 52.\n",
      "      Epoch 25/100 -> Train Loss: 1.106069, Val Loss: 1.081843\n",
      "      Epoch 50/100 -> Train Loss: 1.105394, Val Loss: 1.079503\n",
      "      Epoch 75/100 -> Train Loss: 1.104759, Val Loss: 1.079460\n",
      "    Early stopping at epoch 83. Best val loss 1.078428 at epoch 63.\n",
      "      Epoch 25/100 -> Train Loss: 1.103027, Val Loss: 1.102946\n",
      "    Early stopping at epoch 35. Best val loss 1.098265 at epoch 15.\n",
      "    Avg Val Score (Weighted CE): 1.106158\n",
      "  Testing config 5: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'shared_hidden_size': 32}\n",
      "      Epoch 25/100 -> Train Loss: 1.077772, Val Loss: 1.141100\n",
      "    Early stopping at epoch 46. Best val loss 1.139456 at epoch 26.\n",
      "      Epoch 25/100 -> Train Loss: 1.101876, Val Loss: 1.077917\n",
      "      Epoch 50/100 -> Train Loss: 1.101860, Val Loss: 1.078421\n",
      "    Early stopping at epoch 63. Best val loss 1.076799 at epoch 43.\n",
      "      Epoch 25/100 -> Train Loss: 1.098693, Val Loss: 1.093996\n",
      "    Early stopping at epoch 45. Best val loss 1.093996 at epoch 25.\n",
      "    Avg Val Score (Weighted CE): 1.103417\n",
      "  Testing config 6: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'shared_hidden_size': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.075489, Val Loss: 1.140844\n",
      "    Early stopping at epoch 31. Best val loss 1.138141 at epoch 11.\n",
      "      Epoch 25/100 -> Train Loss: 1.102428, Val Loss: 1.078725\n",
      "      Epoch 50/100 -> Train Loss: 1.100053, Val Loss: 1.077180\n",
      "      Epoch 75/100 -> Train Loss: 1.099259, Val Loss: 1.075398\n",
      "      Epoch 100/100 -> Train Loss: 1.097934, Val Loss: 1.075315\n",
      "    Reached max_epochs (100). Best val loss 1.075219 at epoch 86.\n",
      "      Epoch 25/100 -> Train Loss: 1.097890, Val Loss: 1.093180\n",
      "      Epoch 50/100 -> Train Loss: 1.095178, Val Loss: 1.094247\n",
      "    Early stopping at epoch 63. Best val loss 1.091486 at epoch 43.\n",
      "    Avg Val Score (Weighted CE): 1.101615\n",
      "  Testing config 7: {'dropout_rate': 0.1, 'learning_rate': 0.0001, 'shared_hidden_size': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.098876, Val Loss: 1.160374\n",
      "      Epoch 50/100 -> Train Loss: 1.089085, Val Loss: 1.156464\n",
      "      Epoch 75/100 -> Train Loss: 1.086510, Val Loss: 1.153146\n",
      "      Epoch 100/100 -> Train Loss: 1.082020, Val Loss: 1.150554\n",
      "    Reached max_epochs (100). Best val loss 1.149923 at epoch 99.\n",
      "      Epoch 25/100 -> Train Loss: 1.127019, Val Loss: 1.095422\n",
      "      Epoch 50/100 -> Train Loss: 1.116260, Val Loss: 1.088061\n",
      "      Epoch 75/100 -> Train Loss: 1.110300, Val Loss: 1.085362\n",
      "      Epoch 100/100 -> Train Loss: 1.110734, Val Loss: 1.083254\n",
      "    Reached max_epochs (100). Best val loss 1.082872 at epoch 96.\n",
      "      Epoch 25/100 -> Train Loss: 1.119209, Val Loss: 1.109726\n",
      "      Epoch 50/100 -> Train Loss: 1.110288, Val Loss: 1.103096\n",
      "      Epoch 75/100 -> Train Loss: 1.106205, Val Loss: 1.099788\n",
      "      Epoch 100/100 -> Train Loss: 1.103203, Val Loss: 1.100363\n",
      "    Reached max_epochs (100). Best val loss 1.099267 at epoch 94.\n",
      "    Avg Val Score (Weighted CE): 1.110687\n",
      "  Testing config 8: {'dropout_rate': 0.1, 'learning_rate': 0.0001, 'shared_hidden_size': 32}\n",
      "      Epoch 25/100 -> Train Loss: 1.089704, Val Loss: 1.159181\n",
      "      Epoch 50/100 -> Train Loss: 1.083526, Val Loss: 1.149917\n",
      "      Epoch 75/100 -> Train Loss: 1.080181, Val Loss: 1.145893\n",
      "      Epoch 100/100 -> Train Loss: 1.080417, Val Loss: 1.144619\n",
      "    Reached max_epochs (100). Best val loss 1.144619 at epoch 100.\n",
      "      Epoch 25/100 -> Train Loss: 1.118378, Val Loss: 1.090034\n",
      "      Epoch 50/100 -> Train Loss: 1.109314, Val Loss: 1.083772\n",
      "      Epoch 75/100 -> Train Loss: 1.107128, Val Loss: 1.082432\n",
      "      Epoch 100/100 -> Train Loss: 1.103411, Val Loss: 1.080615\n",
      "    Reached max_epochs (100). Best val loss 1.080257 at epoch 90.\n",
      "      Epoch 25/100 -> Train Loss: 1.108000, Val Loss: 1.104266\n",
      "      Epoch 50/100 -> Train Loss: 1.104188, Val Loss: 1.102967\n",
      "      Epoch 75/100 -> Train Loss: 1.099789, Val Loss: 1.099456\n",
      "      Epoch 100/100 -> Train Loss: 1.099369, Val Loss: 1.099131\n",
      "    Reached max_epochs (100). Best val loss 1.097676 at epoch 92.\n",
      "    Avg Val Score (Weighted CE): 1.107517\n",
      "  Testing config 9: {'dropout_rate': 0.1, 'learning_rate': 0.0001, 'shared_hidden_size': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.083677, Val Loss: 1.154674\n",
      "      Epoch 50/100 -> Train Loss: 1.079798, Val Loss: 1.145235\n",
      "      Epoch 75/100 -> Train Loss: 1.077305, Val Loss: 1.141832\n",
      "      Epoch 100/100 -> Train Loss: 1.076128, Val Loss: 1.141179\n",
      "    Reached max_epochs (100). Best val loss 1.140636 at epoch 94.\n",
      "      Epoch 25/100 -> Train Loss: 1.108235, Val Loss: 1.082851\n",
      "      Epoch 50/100 -> Train Loss: 1.104026, Val Loss: 1.080514\n",
      "      Epoch 75/100 -> Train Loss: 1.102638, Val Loss: 1.078672\n",
      "      Epoch 100/100 -> Train Loss: 1.100079, Val Loss: 1.078362\n",
      "    Reached max_epochs (100). Best val loss 1.077815 at epoch 99.\n",
      "      Epoch 25/100 -> Train Loss: 1.104023, Val Loss: 1.099801\n",
      "      Epoch 50/100 -> Train Loss: 1.100492, Val Loss: 1.100297\n",
      "      Epoch 75/100 -> Train Loss: 1.097480, Val Loss: 1.099012\n",
      "      Epoch 100/100 -> Train Loss: 1.096879, Val Loss: 1.098720\n",
      "    Reached max_epochs (100). Best val loss 1.097088 at epoch 82.\n",
      "    Avg Val Score (Weighted CE): 1.105180\n",
      "  Testing config 10: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'shared_hidden_size': 16}\n",
      "    Early stopping at epoch 24. Best val loss 1.149744 at epoch 4.\n",
      "      Epoch 25/100 -> Train Loss: 1.122743, Val Loss: 1.091837\n",
      "      Epoch 50/100 -> Train Loss: 1.123162, Val Loss: 1.088477\n",
      "    Early stopping at epoch 57. Best val loss 1.085627 at epoch 37.\n",
      "      Epoch 25/100 -> Train Loss: 1.114336, Val Loss: 1.103025\n",
      "    Early stopping at epoch 27. Best val loss 1.100258 at epoch 7.\n",
      "    Avg Val Score (Weighted CE): 1.111876\n",
      "  Testing config 11: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'shared_hidden_size': 32}\n",
      "      Epoch 25/100 -> Train Loss: 1.094119, Val Loss: 1.164603\n",
      "    Early stopping at epoch 27. Best val loss 1.150967 at epoch 7.\n",
      "      Epoch 25/100 -> Train Loss: 1.121907, Val Loss: 1.088573\n",
      "    Early stopping at epoch 33. Best val loss 1.084067 at epoch 13.\n",
      "      Epoch 25/100 -> Train Loss: 1.118869, Val Loss: 1.109904\n",
      "    Early stopping at epoch 26. Best val loss 1.097181 at epoch 6.\n",
      "    Avg Val Score (Weighted CE): 1.110738\n",
      "  Testing config 12: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'shared_hidden_size': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.103708, Val Loss: 1.168368\n",
      "    Early stopping at epoch 27. Best val loss 1.152410 at epoch 7.\n",
      "      Epoch 25/100 -> Train Loss: 1.142048, Val Loss: 1.110857\n",
      "    Early stopping at epoch 25. Best val loss 1.087334 at epoch 5.\n",
      "      Epoch 25/100 -> Train Loss: 1.123855, Val Loss: 1.113845\n",
      "    Early stopping at epoch 29. Best val loss 1.098676 at epoch 9.\n",
      "    Avg Val Score (Weighted CE): 1.112807\n",
      "  Testing config 13: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'shared_hidden_size': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.090662, Val Loss: 1.152766\n",
      "      Epoch 50/100 -> Train Loss: 1.086557, Val Loss: 1.149441\n",
      "    Early stopping at epoch 64. Best val loss 1.147380 at epoch 44.\n",
      "      Epoch 25/100 -> Train Loss: 1.117159, Val Loss: 1.084943\n",
      "      Epoch 50/100 -> Train Loss: 1.114115, Val Loss: 1.084958\n",
      "    Early stopping at epoch 57. Best val loss 1.081911 at epoch 37.\n",
      "      Epoch 25/100 -> Train Loss: 1.115899, Val Loss: 1.101867\n",
      "    Early stopping at epoch 46. Best val loss 1.096065 at epoch 26.\n",
      "    Avg Val Score (Weighted CE): 1.108452\n",
      "  Testing config 14: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'shared_hidden_size': 32}\n",
      "      Epoch 25/100 -> Train Loss: 1.085514, Val Loss: 1.146011\n",
      "      Epoch 50/100 -> Train Loss: 1.082596, Val Loss: 1.144123\n",
      "      Epoch 75/100 -> Train Loss: 1.078245, Val Loss: 1.146371\n",
      "    Early stopping at epoch 88. Best val loss 1.142141 at epoch 68.\n",
      "      Epoch 25/100 -> Train Loss: 1.111214, Val Loss: 1.083309\n",
      "      Epoch 50/100 -> Train Loss: 1.108583, Val Loss: 1.081268\n",
      "    Early stopping at epoch 64. Best val loss 1.078757 at epoch 44.\n",
      "      Epoch 25/100 -> Train Loss: 1.107351, Val Loss: 1.103869\n",
      "    Early stopping at epoch 48. Best val loss 1.096160 at epoch 28.\n",
      "    Avg Val Score (Weighted CE): 1.105686\n",
      "  Testing config 15: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'shared_hidden_size': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.081961, Val Loss: 1.144274\n",
      "      Epoch 50/100 -> Train Loss: 1.077622, Val Loss: 1.144192\n",
      "    Early stopping at epoch 65. Best val loss 1.140503 at epoch 45.\n",
      "      Epoch 25/100 -> Train Loss: 1.110039, Val Loss: 1.080073\n",
      "      Epoch 50/100 -> Train Loss: 1.104144, Val Loss: 1.080837\n",
      "      Epoch 75/100 -> Train Loss: 1.104252, Val Loss: 1.079209\n",
      "    Early stopping at epoch 81. Best val loss 1.077172 at epoch 61.\n",
      "      Epoch 25/100 -> Train Loss: 1.101881, Val Loss: 1.097725\n",
      "      Epoch 50/100 -> Train Loss: 1.097947, Val Loss: 1.093656\n",
      "    Early stopping at epoch 51. Best val loss 1.092697 at epoch 31.\n",
      "    Avg Val Score (Weighted CE): 1.103457\n",
      "  Testing config 16: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'shared_hidden_size': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.126888, Val Loss: 1.160479\n",
      "      Epoch 50/100 -> Train Loss: 1.105552, Val Loss: 1.160012\n",
      "      Epoch 75/100 -> Train Loss: 1.097909, Val Loss: 1.156353\n",
      "      Epoch 100/100 -> Train Loss: 1.094809, Val Loss: 1.153213\n",
      "    Reached max_epochs (100). Best val loss 1.153213 at epoch 100.\n",
      "      Epoch 25/100 -> Train Loss: 1.137518, Val Loss: 1.098009\n",
      "      Epoch 50/100 -> Train Loss: 1.125519, Val Loss: 1.091226\n",
      "      Epoch 75/100 -> Train Loss: 1.119665, Val Loss: 1.087163\n",
      "      Epoch 100/100 -> Train Loss: 1.119101, Val Loss: 1.086117\n",
      "    Reached max_epochs (100). Best val loss 1.085225 at epoch 98.\n",
      "      Epoch 25/100 -> Train Loss: 1.144350, Val Loss: 1.114489\n",
      "      Epoch 50/100 -> Train Loss: 1.127927, Val Loss: 1.103555\n",
      "      Epoch 75/100 -> Train Loss: 1.118679, Val Loss: 1.099942\n",
      "      Epoch 100/100 -> Train Loss: 1.114068, Val Loss: 1.098839\n",
      "    Reached max_epochs (100). Best val loss 1.098839 at epoch 100.\n",
      "    Avg Val Score (Weighted CE): 1.112426\n",
      "  Testing config 17: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'shared_hidden_size': 32}\n",
      "      Epoch 25/100 -> Train Loss: 1.101681, Val Loss: 1.162604\n",
      "      Epoch 50/100 -> Train Loss: 1.092951, Val Loss: 1.152951\n",
      "      Epoch 75/100 -> Train Loss: 1.088759, Val Loss: 1.149264\n",
      "      Epoch 100/100 -> Train Loss: 1.085232, Val Loss: 1.147014\n",
      "    Reached max_epochs (100). Best val loss 1.146801 at epoch 91.\n",
      "      Epoch 25/100 -> Train Loss: 1.126820, Val Loss: 1.092206\n",
      "      Epoch 50/100 -> Train Loss: 1.117262, Val Loss: 1.085705\n",
      "      Epoch 75/100 -> Train Loss: 1.112652, Val Loss: 1.083100\n",
      "      Epoch 100/100 -> Train Loss: 1.110504, Val Loss: 1.082754\n",
      "    Reached max_epochs (100). Best val loss 1.081989 at epoch 99.\n",
      "      Epoch 25/100 -> Train Loss: 1.123386, Val Loss: 1.106306\n",
      "      Epoch 50/100 -> Train Loss: 1.114772, Val Loss: 1.100895\n",
      "      Epoch 75/100 -> Train Loss: 1.111255, Val Loss: 1.099717\n",
      "    Early stopping at epoch 82. Best val loss 1.098723 at epoch 62.\n",
      "    Avg Val Score (Weighted CE): 1.109171\n",
      "  Testing config 18: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'shared_hidden_size': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.092509, Val Loss: 1.158832\n",
      "      Epoch 50/100 -> Train Loss: 1.086499, Val Loss: 1.150672\n",
      "      Epoch 75/100 -> Train Loss: 1.083372, Val Loss: 1.147714\n",
      "      Epoch 100/100 -> Train Loss: 1.080527, Val Loss: 1.146392\n",
      "    Reached max_epochs (100). Best val loss 1.144270 at epoch 95.\n",
      "      Epoch 25/100 -> Train Loss: 1.117482, Val Loss: 1.086121\n",
      "      Epoch 50/100 -> Train Loss: 1.112409, Val Loss: 1.082075\n",
      "      Epoch 75/100 -> Train Loss: 1.109144, Val Loss: 1.080677\n",
      "      Epoch 100/100 -> Train Loss: 1.105601, Val Loss: 1.080535\n",
      "    Reached max_epochs (100). Best val loss 1.079655 at epoch 94.\n",
      "      Epoch 25/100 -> Train Loss: 1.114159, Val Loss: 1.103525\n",
      "      Epoch 50/100 -> Train Loss: 1.106265, Val Loss: 1.098318\n",
      "      Epoch 75/100 -> Train Loss: 1.104365, Val Loss: 1.099578\n",
      "      Epoch 100/100 -> Train Loss: 1.103004, Val Loss: 1.101193\n",
      "    Reached max_epochs (100). Best val loss 1.097511 at epoch 92.\n",
      "    Avg Val Score (Weighted CE): 1.107145\n",
      "  Testing config 19: {'dropout_rate': 0.5, 'learning_rate': 0.01, 'shared_hidden_size': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.103110, Val Loss: 1.169281\n",
      "    Early stopping at epoch 33. Best val loss 1.162081 at epoch 13.\n",
      "      Epoch 25/100 -> Train Loss: 1.134069, Val Loss: 1.097110\n",
      "    Early stopping at epoch 25. Best val loss 1.096071 at epoch 5.\n",
      "      Epoch 25/100 -> Train Loss: 1.126931, Val Loss: 1.113010\n",
      "    Early stopping at epoch 29. Best val loss 1.108968 at epoch 9.\n",
      "    Avg Val Score (Weighted CE): 1.122373\n",
      "  Testing config 20: {'dropout_rate': 0.5, 'learning_rate': 0.01, 'shared_hidden_size': 32}\n",
      "      Epoch 25/100 -> Train Loss: 1.103052, Val Loss: 1.174095\n",
      "    Early stopping at epoch 30. Best val loss 1.159559 at epoch 10.\n",
      "    Early stopping at epoch 21. Best val loss 1.093184 at epoch 1.\n",
      "      Epoch 25/100 -> Train Loss: 1.129312, Val Loss: 1.115798\n",
      "    Early stopping at epoch 35. Best val loss 1.107813 at epoch 15.\n",
      "    Avg Val Score (Weighted CE): 1.120185\n",
      "  Testing config 21: {'dropout_rate': 0.5, 'learning_rate': 0.01, 'shared_hidden_size': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.114396, Val Loss: 1.182132\n",
      "    Early stopping at epoch 28. Best val loss 1.155199 at epoch 8.\n",
      "      Epoch 25/100 -> Train Loss: 1.133940, Val Loss: 1.099345\n",
      "    Early stopping at epoch 40. Best val loss 1.097768 at epoch 20.\n",
      "    Early stopping at epoch 22. Best val loss 1.106043 at epoch 2.\n",
      "    Avg Val Score (Weighted CE): 1.119670\n",
      "  Testing config 22: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'shared_hidden_size': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.102109, Val Loss: 1.158673\n",
      "      Epoch 50/100 -> Train Loss: 1.094730, Val Loss: 1.153969\n",
      "      Epoch 75/100 -> Train Loss: 1.091355, Val Loss: 1.153470\n",
      "    Early stopping at epoch 81. Best val loss 1.151844 at epoch 61.\n",
      "      Epoch 25/100 -> Train Loss: 1.129623, Val Loss: 1.092921\n",
      "      Epoch 50/100 -> Train Loss: 1.123462, Val Loss: 1.088858\n",
      "    Early stopping at epoch 61. Best val loss 1.086512 at epoch 41.\n",
      "      Epoch 25/100 -> Train Loss: 1.123731, Val Loss: 1.103040\n",
      "      Epoch 50/100 -> Train Loss: 1.119426, Val Loss: 1.107473\n",
      "    Early stopping at epoch 52. Best val loss 1.101609 at epoch 32.\n",
      "    Avg Val Score (Weighted CE): 1.113322\n",
      "  Testing config 23: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'shared_hidden_size': 32}\n",
      "      Epoch 25/100 -> Train Loss: 1.090810, Val Loss: 1.151635\n",
      "      Epoch 50/100 -> Train Loss: 1.087622, Val Loss: 1.147556\n",
      "    Early stopping at epoch 70. Best val loss 1.147556 at epoch 50.\n",
      "      Epoch 25/100 -> Train Loss: 1.117814, Val Loss: 1.085035\n",
      "      Epoch 50/100 -> Train Loss: 1.115029, Val Loss: 1.084400\n",
      "    Early stopping at epoch 68. Best val loss 1.082365 at epoch 48.\n",
      "      Epoch 25/100 -> Train Loss: 1.113180, Val Loss: 1.106940\n",
      "      Epoch 50/100 -> Train Loss: 1.111072, Val Loss: 1.098516\n",
      "      Epoch 75/100 -> Train Loss: 1.107420, Val Loss: 1.102520\n",
      "    Early stopping at epoch 76. Best val loss 1.094754 at epoch 56.\n",
      "    Avg Val Score (Weighted CE): 1.108225\n",
      "  Testing config 24: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'shared_hidden_size': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.087378, Val Loss: 1.148271\n",
      "      Epoch 50/100 -> Train Loss: 1.083908, Val Loss: 1.144949\n",
      "    Early stopping at epoch 73. Best val loss 1.142882 at epoch 53.\n",
      "      Epoch 25/100 -> Train Loss: 1.112597, Val Loss: 1.085189\n",
      "      Epoch 50/100 -> Train Loss: 1.111016, Val Loss: 1.082559\n",
      "    Early stopping at epoch 60. Best val loss 1.080067 at epoch 40.\n",
      "      Epoch 25/100 -> Train Loss: 1.106877, Val Loss: 1.100982\n",
      "      Epoch 50/100 -> Train Loss: 1.106078, Val Loss: 1.098168\n",
      "    Early stopping at epoch 60. Best val loss 1.095413 at epoch 40.\n",
      "    Avg Val Score (Weighted CE): 1.106121\n",
      "  Testing config 25: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'shared_hidden_size': 16}\n",
      "      Epoch 25/100 -> Train Loss: 1.147364, Val Loss: 1.157932\n",
      "    Early stopping at epoch 47. Best val loss 1.157501 at epoch 27.\n",
      "      Epoch 25/100 -> Train Loss: 1.164656, Val Loss: 1.109964\n",
      "      Epoch 50/100 -> Train Loss: 1.143935, Val Loss: 1.098526\n",
      "      Epoch 75/100 -> Train Loss: 1.133906, Val Loss: 1.094052\n",
      "      Epoch 100/100 -> Train Loss: 1.130338, Val Loss: 1.091711\n",
      "    Reached max_epochs (100). Best val loss 1.091515 at epoch 92.\n",
      "      Epoch 25/100 -> Train Loss: 1.164340, Val Loss: 1.122541\n",
      "      Epoch 50/100 -> Train Loss: 1.139005, Val Loss: 1.109111\n",
      "      Epoch 75/100 -> Train Loss: 1.133290, Val Loss: 1.106141\n",
      "      Epoch 100/100 -> Train Loss: 1.128759, Val Loss: 1.104617\n",
      "    Reached max_epochs (100). Best val loss 1.103934 at epoch 94.\n",
      "    Avg Val Score (Weighted CE): 1.117650\n",
      "  Testing config 26: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'shared_hidden_size': 32}\n",
      "      Epoch 25/100 -> Train Loss: 1.124760, Val Loss: 1.173034\n",
      "      Epoch 50/100 -> Train Loss: 1.106647, Val Loss: 1.166575\n",
      "      Epoch 75/100 -> Train Loss: 1.101563, Val Loss: 1.158452\n",
      "      Epoch 100/100 -> Train Loss: 1.096190, Val Loss: 1.156024\n",
      "    Reached max_epochs (100). Best val loss 1.155796 at epoch 91.\n",
      "      Epoch 25/100 -> Train Loss: 1.146582, Val Loss: 1.101639\n",
      "      Epoch 50/100 -> Train Loss: 1.133260, Val Loss: 1.092612\n",
      "      Epoch 75/100 -> Train Loss: 1.127327, Val Loss: 1.089092\n",
      "      Epoch 100/100 -> Train Loss: 1.124491, Val Loss: 1.087477\n",
      "    Reached max_epochs (100). Best val loss 1.087477 at epoch 100.\n",
      "      Epoch 25/100 -> Train Loss: 1.137023, Val Loss: 1.110323\n",
      "      Epoch 50/100 -> Train Loss: 1.129433, Val Loss: 1.104191\n",
      "      Epoch 75/100 -> Train Loss: 1.120422, Val Loss: 1.101199\n",
      "      Epoch 100/100 -> Train Loss: 1.118056, Val Loss: 1.101095\n",
      "    Reached max_epochs (100). Best val loss 1.100061 at epoch 87.\n",
      "    Avg Val Score (Weighted CE): 1.114444\n",
      "  Testing config 27: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'shared_hidden_size': 64}\n",
      "      Epoch 25/100 -> Train Loss: 1.104773, Val Loss: 1.159048\n",
      "      Epoch 50/100 -> Train Loss: 1.096018, Val Loss: 1.155240\n",
      "      Epoch 75/100 -> Train Loss: 1.090155, Val Loss: 1.149841\n",
      "    Early stopping at epoch 96. Best val loss 1.148485 at epoch 76.\n",
      "      Epoch 25/100 -> Train Loss: 1.128785, Val Loss: 1.090797\n",
      "      Epoch 50/100 -> Train Loss: 1.120515, Val Loss: 1.087079\n",
      "      Epoch 75/100 -> Train Loss: 1.116619, Val Loss: 1.085095\n",
      "      Epoch 100/100 -> Train Loss: 1.114687, Val Loss: 1.083637\n",
      "    Reached max_epochs (100). Best val loss 1.082640 at epoch 99.\n",
      "      Epoch 25/100 -> Train Loss: 1.126490, Val Loss: 1.102147\n",
      "      Epoch 50/100 -> Train Loss: 1.118223, Val Loss: 1.101559\n",
      "    Early stopping at epoch 57. Best val loss 1.099894 at epoch 37.\n",
      "    Avg Val Score (Weighted CE): 1.110339\n",
      "CV results saved to: ./results/mlp2_cv_results.csv\n",
      "\n",
      "Best MLP2 CV params: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'shared_hidden_size': 64} (Score: 1.101615)\n",
      "--- Finished Cross-Validation for MLP2 ---\n"
     ]
    }
   ],
   "source": [
    "mlp2.cross_validate(dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c03f40ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Final Model Training for MLP2 ---\n",
      "Using best hyperparameters from CV: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'shared_hidden_size': 64}\n",
      "Starting training for 300 epochs...\n",
      "  Epoch 10/300 - Loss: 1.093569 (best 1.093569, no_improve=0)\n",
      "  Epoch 20/300 - Loss: 1.090855 (best 1.090815, no_improve=4)\n",
      "  Epoch 30/300 - Loss: 1.089503 (best 1.089453, no_improve=3)\n",
      "  Epoch 40/300 - Loss: 1.089801 (best 1.088617, no_improve=1)\n",
      "  Epoch 50/300 - Loss: 1.087836 (best 1.087836, no_improve=0)\n",
      "  Epoch 60/300 - Loss: 1.088081 (best 1.087836, no_improve=10)\n",
      "  Epoch 70/300 - Loss: 1.088676 (best 1.087800, no_improve=4)\n",
      "  Epoch 80/300 - Loss: 1.088466 (best 1.087005, no_improve=8)\n",
      "  Epoch 90/300 - Loss: 1.087338 (best 1.086772, no_improve=1)\n",
      "  Epoch 100/300 - Loss: 1.087672 (best 1.086772, no_improve=11)\n",
      "  Epoch 110/300 - Loss: 1.088450 (best 1.086772, no_improve=21)\n",
      "  Epoch 120/300 - Loss: 1.088234 (best 1.086223, no_improve=8)\n",
      "  Epoch 130/300 - Loss: 1.087952 (best 1.086223, no_improve=18)\n",
      "  Epoch 140/300 - Loss: 1.087782 (best 1.086223, no_improve=28)\n",
      "  Epoch 150/300 - Loss: 1.088322 (best 1.086223, no_improve=38)\n",
      "  Epoch 160/300 - Loss: 1.087060 (best 1.086223, no_improve=48)\n",
      "  Early stopping at epoch 162 (best loss 1.086223)\n",
      "Saved best model state_dict to: ./models/mlp2_final_state_dict.pth\n",
      "Saved training loss history to: ./results/mlp2_final_training_loss.csv\n",
      "--- Finished Final Model Training for MLP2 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_MLP2Net(\n",
       "  (layer_1): Linear(in_features=115, out_features=64, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (layer_3): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.train_final_model(dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb0582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLP2 on year '2020' with Aggregate Cross-Entropy (CPU)...\n",
      "Test data loaded: 3090 samples.\n",
      "  County-level predictions saved to: ./results/mlp2_2020_predictions.csv\n",
      "  Aggregate True Distribution: [0.31386703 0.01158256 0.28773913 0.38681123]\n",
      "  Aggregate Predicted Distribution: [0.30526263 0.03982713 0.21776499 0.43714526]\n",
      "  Aggregate Cross-Entropy: 1.168456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.30526263, 0.03982713, 0.21776499, 0.43714526], dtype=float32),\n",
       " 1.1684564352035522)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.evaluate(dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "760d24bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(democrat|C)</th>\n",
       "      <th>P(other|C)</th>\n",
       "      <th>P(republican|C)</th>\n",
       "      <th>P(non_voter|C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127687</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.337605</td>\n",
       "      <td>0.293137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.357913</td>\n",
       "      <td>0.318503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.193592</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.225992</td>\n",
       "      <td>0.370141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.089254</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.338187</td>\n",
       "      <td>0.356883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044687</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.418285</td>\n",
       "      <td>0.303418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>0.090853</td>\n",
       "      <td>0.015352</td>\n",
       "      <td>0.290620</td>\n",
       "      <td>0.348321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>0.421828</td>\n",
       "      <td>0.025615</td>\n",
       "      <td>0.185942</td>\n",
       "      <td>0.190354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>0.077436</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>0.364840</td>\n",
       "      <td>0.260343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>0.084272</td>\n",
       "      <td>0.017605</td>\n",
       "      <td>0.420065</td>\n",
       "      <td>0.259288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>0.052402</td>\n",
       "      <td>0.013537</td>\n",
       "      <td>0.452256</td>\n",
       "      <td>0.277584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3090 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      P(democrat|C)  P(other|C)  P(republican|C)  P(non_voter|C)\n",
       "0          0.127687    0.007301         0.337605        0.293137\n",
       "1          0.105295    0.006670         0.357913        0.318503\n",
       "2          0.193592    0.003216         0.225992        0.370141\n",
       "3          0.089254    0.003775         0.338187        0.356883\n",
       "4          0.044687    0.004012         0.418285        0.303418\n",
       "...             ...         ...              ...             ...\n",
       "3085       0.090853    0.015352         0.290620        0.348321\n",
       "3086       0.421828    0.025615         0.185942        0.190354\n",
       "3087       0.077436    0.018106         0.364840        0.260343\n",
       "3088       0.084272    0.017605         0.420065        0.259288\n",
       "3089       0.052402    0.013537         0.452256        0.277584\n",
       "\n",
       "[3090 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh.final_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6c54f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout_rate': 0.1, 'learning_rate': 0.001, 'shared_hidden_size': 64}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
