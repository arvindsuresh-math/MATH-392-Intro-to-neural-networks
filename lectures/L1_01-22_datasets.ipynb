{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\title{Lecture 1: Datasets}\n",
    "\\author{Arvind Suresh}\n",
    "\\date{Jan 22, 2025}\n",
    "\n",
    "\\maketitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#  Understanding rows and columns of datasets\n",
    "\n",
    "I want to begin by offering a framework for viewing data and datasets. This section is informal, partly opinion-based, and not very rigorous, so be warned!\n",
    "\n",
    "Data arises naturally when you ask a question about an *object*, which (typically) refers to something physical, like *flower*, *human*, *country*, *house*, *car*, *concrete mix*, and so on. Note that each of these objects is in fact referring to a *collection* of things. For example, *flower* refers to the collection of all flowers. The individual members of the collection are called *instances* of the object. For example, I am an instance of the object *human*, and you are also an instance of *human* (or perhaps *AI*).\n",
    "\n",
    "\"Asking a question about an object\" simply means that you ask a question about every instance of the object. For example, if the object is *human*, you can ask *What is the height*?\n",
    "If the object is *house*, you can ask *What is the square footage*?  Typically (as is the case with these examples), the answer to your question will vary as you vary the instance-- it is a variable! In fact, when we make things more formal using probability theory, we'll call them *Random Variables*.\n",
    "\n",
    "\n",
    "Any question about an object is called a *feature* of the object, because it usually refers to some kind of natural attribute of the object (e.x. height of a human, square footage of a house). Now, the main point to keep in mind about datasets is:\n",
    "\n",
    "- *Columns correspond to features*: each column contains answers to a single question about the object for all the instances (being considered).\n",
    "- *Rows correspond to instances*-- each row contains answers to all the questions (being considered) about a particular instance.\n",
    "\n",
    "For example, the questions *What is the age* and *What is the date of birth* define features of the object *human*. If we have $100$ people, numbered $0,\\dotsc,99$, for whom we know the answers to these two questions, then we can assemble these answers into a single dataset:\n",
    "\n",
    "- There will be two columns, which we can name (for example) `age` and `data_of_birth`.\n",
    "- There will be $100$ rows, indexed (labelled) by $0,\\dotsc,99$.\n",
    "- The row with index $i$ will have the age and date of birth of the $i$-th person, respectively. \n",
    "\n",
    "# Two interesting datasets\n",
    "\n",
    "Let's start by reading in two interesting datasets (sourced from the UCI ML repo). \n",
    "    - The first is the famous `iris` dataset, a small and simple dataset containing measurements of three types of iris flower.\n",
    "    - The second dataset `real_estate` contains various characteristics of houses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris: 120 rows and 5 columns\n",
      "   sepal length  sepal width  petal length  petal width            class\n",
      "0           4.4          2.9           1.4          0.2      Iris-setosa\n",
      "1           4.9          2.5           4.5          1.7   Iris-virginica\n",
      "2           6.8          2.8           4.8          1.4  Iris-versicolor\n",
      "3           4.9          3.1           1.5          0.1      Iris-setosa\n",
      "4           5.5          2.5           4.0          1.3  Iris-versicolor\n",
      "\n",
      "real_estate: 331 rows and 7 columns\n",
      "   X1 transaction date  X2 house age  X3 distance to the nearest MRT station  \\\n",
      "0             2013.417          35.3                               614.13940   \n",
      "1             2013.083           6.2                                90.45606   \n",
      "2             2013.500          23.0                              3947.94500   \n",
      "3             2013.167           1.1                               193.58450   \n",
      "4             2013.417          17.1                               967.40000   \n",
      "\n",
      "   X4 number of convenience stores  X5 latitude  X6 longitude  \\\n",
      "0                                7     24.97913     121.53666   \n",
      "1                                9     24.97433     121.54310   \n",
      "2                                0     24.94783     121.50243   \n",
      "3                                6     24.96571     121.54089   \n",
      "4                                4     24.98872     121.53408   \n",
      "\n",
      "   Y house price of unit area  \n",
      "0                        33.1  \n",
      "1                        58.0  \n",
      "2                        25.3  \n",
      "3                        48.6  \n",
      "4                        40.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "iris = pd.read_csv('../data/classification/iris/train.csv')\n",
    "real_estate = pd.read_csv('../data/regression/real_estate_valuation/train.csv')\n",
    "\n",
    "print(f'iris: {iris.shape[0]} rows and {iris.shape[1]} columns')\n",
    "print(iris.head())\n",
    "print()\n",
    "print(f'real_estate: {real_estate.shape[0]} rows and {real_estate.shape[1]} columns')\n",
    "print(real_estate.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of data\n",
    "\n",
    "Observe that the features in these datasets fall into two categories.\n",
    "\n",
    "1. *Continuous*:\n",
    "    - These are features whose values are real numbers that (may) include decimal places, that is, the values are of type `float`. \n",
    "    - E.g. all columns of the `iris` dataset except for the `class` column, and all columns of the `real_estate` dataset except for `X4 number of convenience stores`.\n",
    "    - Mathematically, the variable corresponding to the column is called a *continuous random variable*.\n",
    "2. *Categorical*:\n",
    "    - These are features whose values are contained in a finite set.\n",
    "    - The values may be numeric (e.g. `X4 number of convenience stores`is of type `int`) or non-numeric (e.g. `class` is of type `str`).\n",
    "    - Mathematically, the variable corresponding to the column is called a *discrete random variable*. \n",
    "\n",
    "**Remark.**  There is a potential grey area where a variable could be viewed as either continuous or categorical; e.x. if the object is *US county* and the feature is *population*, then (in principle) any positive integer is a possible value, but these values are discrete... Let's ignore this subtlety for now!\n",
    "\n",
    "# Problems of prediction\n",
    "\n",
    "Problems in ML are problems of prediction. Namely, one has an object and a certain distinguished feature $Y$, called the *target variable*, and given an instance, one wants to predict the value of the target. Such problems are of two kinds, depending on the nature of the target $Y$:\n",
    "\n",
    "- *Classification*. \n",
    "    - This is when  $Y$ is a categorical variable with finitely many possible values $c_1,\\dotsc,c_r$.\n",
    "    - The values of $Y$ partition the instances into $r$ classes. \n",
    "    - Predicting $Y$ amounts to classifying the instances, i.e. determining which class the instance lies in.\n",
    "    - For example, a natural target for `iris` is `class`; given a particular iris flower, one wants to classify it as belonging to one of the three classes (`Iris-setosa`, `Iris-virginica`, or `Iris-versicolor`).\n",
    "- *Regression*.\n",
    "    - This is when $Y$ is a continuous variable with real values.\n",
    "    - One wants to predict the value of $Y$ as closely as possible.\n",
    "    - For example, a natural target for `real_estate` is `Y house price of unit area`; given a particular house, one wants to predict the price per unit area. \n",
    "\n",
    "Notice that if we are looking at an instance that's already in the dataset, then there is nothing to predict! Thus, the goal is to look at instances for which we *don't* know the value of the target, and we want to predict it. For example, we might want to predict the targets that are missing from the following datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_test: 30 rows and 4 columns\n",
      "   sepal length  sepal width  petal length  petal width\n",
      "0           4.4          3.0           1.3          0.2\n",
      "1           6.1          3.0           4.9          1.8\n",
      "2           4.9          2.4           3.3          1.0\n",
      "3           5.0          2.3           3.3          1.0\n",
      "4           4.4          3.2           1.3          0.2\n",
      "\n",
      "real_estate_test: 83 rows and 6 columns\n",
      "   X1 transaction date  X2 house age  X3 distance to the nearest MRT station  \\\n",
      "0             2013.083          33.0                                181.0766   \n",
      "1             2012.917          16.9                                964.7496   \n",
      "2             2012.917          31.9                               1146.3290   \n",
      "3             2013.083          17.5                                395.6747   \n",
      "4             2013.500          11.8                                533.4762   \n",
      "\n",
      "   X4 number of convenience stores  X5 latitude  X6 longitude  \n",
      "0                                9     24.97697     121.54262  \n",
      "1                                4     24.98872     121.53411  \n",
      "2                                0     24.94920     121.53076  \n",
      "3                                5     24.95674     121.53400  \n",
      "4                                4     24.97445     121.54765  \n"
     ]
    }
   ],
   "source": [
    "iris_test = pd.read_csv('../data/classification/iris/test.csv')\n",
    "real_estate_test = pd.read_csv('../data/regression/real_estate_valuation/test.csv')\n",
    "\n",
    "print(f'iris_test: {iris_test.shape[0]} rows and {iris_test.shape[1]} columns')\n",
    "print(iris_test.head())\n",
    "print()\n",
    "print(f'real_estate_test: {real_estate_test.shape[0]} rows and {real_estate_test.shape[1]} columns')\n",
    "print(real_estate_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset `iris` is a *labelled* dataset; it contains the value of the target `class` for all instances. The second one `iris_test` is *not labelled*; the value of `class` is not known for any instances. Machine Learning falls, broadly speaking, into one of two types:\n",
    "\n",
    "- Supervised Machine Learning seeks to train models on labelled datasets like `real_estate`, so that they can make predictions on unlabelled datasets like `real_estate_test`. \n",
    "- Unsupervised Machine Learning... is postponed until later. \n",
    "\n",
    "In the next lecture, we go into more detail about the framework of supervised machine learning. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
