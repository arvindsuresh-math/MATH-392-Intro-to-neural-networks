{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee440435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e3f26",
   "metadata": {},
   "source": [
    "First, we read in the datasets with conditional probabilities of demographic groups and the dataset with raw counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c2ca0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/probabilities.csv')\n",
    "raws = pd.read_csv(('../data/dataset.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3571e6b5",
   "metadata": {},
   "source": [
    "Next, we add in some missing features from the raw counts dataset to the probabilities dataset. Specifically, we add `median_household_income` and `per_capita_income`, and we also throw in `per_capita_year` (computed by dividing `land_area_sqkm` by `persons_total` in the raws dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cae137fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/w7q1fjwd5kn8xvqty5sp3h7r0000gn/T/ipykernel_91302/841716927.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['per_capita_area'] = raws['land_area_sqkm'].div(raws['persons_total'])\n"
     ]
    }
   ],
   "source": [
    "temp = raws[['year','gisjoin','median_household_income', 'per_capita_income']]\n",
    "temp['per_capita_area'] = raws['land_area_sqkm'].div(raws['persons_total'])\n",
    "\n",
    "# merge temp and df on gisjoin and year. If any gisjoin is missing, drop that row\n",
    "merged = pd.merge(temp, data, on=['gisjoin','year'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd4b0c4",
   "metadata": {},
   "source": [
    "Next, we make a column `P(underage|C)` which is the probability of being underage given the county. This is computed as one minus the sum over all `sex_age_edus` columns (since these add up to all people aged 18+ in the county)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6902bc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(democrat|C)</th>\n",
       "      <th>P(other|C)</th>\n",
       "      <th>P(republican|C)</th>\n",
       "      <th>P(non_voter|C)</th>\n",
       "      <th>P(underage|C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12360.000000</td>\n",
       "      <td>12360.000000</td>\n",
       "      <td>12360.000000</td>\n",
       "      <td>12360.000000</td>\n",
       "      <td>12360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.165146</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>0.277635</td>\n",
       "      <td>0.317940</td>\n",
       "      <td>0.227216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.079625</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>0.085371</td>\n",
       "      <td>0.074824</td>\n",
       "      <td>0.034346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007386</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.071341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.103428</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.223412</td>\n",
       "      <td>0.266529</td>\n",
       "      <td>0.206919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.274800</td>\n",
       "      <td>0.315766</td>\n",
       "      <td>0.227229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.214947</td>\n",
       "      <td>0.014055</td>\n",
       "      <td>0.330726</td>\n",
       "      <td>0.366879</td>\n",
       "      <td>0.245678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.540248</td>\n",
       "      <td>0.185841</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.735494</td>\n",
       "      <td>0.406266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P(democrat|C)    P(other|C)  P(republican|C)  P(non_voter|C)  \\\n",
       "count   12360.000000  12360.000000     12360.000000    12360.000000   \n",
       "mean        0.165146      0.012064         0.277635        0.317940   \n",
       "std         0.079625      0.010955         0.085371        0.074824   \n",
       "min         0.008703      0.000000         0.007386        0.026042   \n",
       "25%         0.103428      0.005683         0.223412        0.266529   \n",
       "50%         0.151652      0.008817         0.274800        0.315766   \n",
       "75%         0.214947      0.014055         0.330726        0.366879   \n",
       "max         0.540248      0.185841         0.729167        0.735494   \n",
       "\n",
       "       P(underage|C)  \n",
       "count   12360.000000  \n",
       "mean        0.227216  \n",
       "std         0.034346  \n",
       "min         0.071341  \n",
       "25%         0.206919  \n",
       "50%         0.227229  \n",
       "75%         0.245678  \n",
       "max         0.406266  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_age_edus = ['male_18_24_less_than_9th',\n",
    "                'male_18_24_some_hs',\n",
    "                'male_18_24_hs_grad',\n",
    "                'male_18_24_some_college',\n",
    "                'male_18_24_associates',\n",
    "                'male_18_24_bachelors',\n",
    "                'male_18_24_graduate',\n",
    "                'male_25_34_less_than_9th',\n",
    "                'male_25_34_some_hs',\n",
    "                'male_25_34_hs_grad',\n",
    "                'male_25_34_some_college',\n",
    "                'male_25_34_associates',\n",
    "                'male_25_34_bachelors',\n",
    "                'male_25_34_graduate',\n",
    "                'male_35_44_less_than_9th',\n",
    "                'male_35_44_some_hs',\n",
    "                'male_35_44_hs_grad',\n",
    "                'male_35_44_some_college',\n",
    "                'male_35_44_associates',\n",
    "                'male_35_44_bachelors',\n",
    "                'male_35_44_graduate',\n",
    "                'male_45_64_less_than_9th',\n",
    "                'male_45_64_some_hs',\n",
    "                'male_45_64_hs_grad',\n",
    "                'male_45_64_some_college',\n",
    "                'male_45_64_associates',\n",
    "                'male_45_64_bachelors',\n",
    "                'male_45_64_graduate',\n",
    "                'male_65plus_less_than_9th',\n",
    "                'male_65plus_some_hs',\n",
    "                'male_65plus_hs_grad',\n",
    "                'male_65plus_some_college',\n",
    "                'male_65plus_associates',\n",
    "                'male_65plus_bachelors',\n",
    "                'male_65plus_graduate',\n",
    "                'female_18_24_less_than_9th',\n",
    "                'female_18_24_some_hs',\n",
    "                'female_18_24_hs_grad',\n",
    "                'female_18_24_some_college',\n",
    "                'female_18_24_associates',\n",
    "                'female_18_24_bachelors',\n",
    "                'female_18_24_graduate',\n",
    "                'female_25_34_less_than_9th',\n",
    "                'female_25_34_some_hs',\n",
    "                'female_25_34_hs_grad',\n",
    "                'female_25_34_some_college',\n",
    "                'female_25_34_associates',\n",
    "                'female_25_34_bachelors',\n",
    "                'female_25_34_graduate',\n",
    "                'female_35_44_less_than_9th',\n",
    "                'female_35_44_some_hs',\n",
    "                'female_35_44_hs_grad',\n",
    "                'female_35_44_some_college',\n",
    "                'female_35_44_associates',\n",
    "                'female_35_44_bachelors',\n",
    "                'female_35_44_graduate',\n",
    "                'female_45_64_less_than_9th',\n",
    "                'female_45_64_some_hs',\n",
    "                'female_45_64_hs_grad',\n",
    "                'female_45_64_some_college',\n",
    "                'female_45_64_associates',\n",
    "                'female_45_64_bachelors',\n",
    "                'female_45_64_graduate',\n",
    "                'female_65plus_less_than_9th',\n",
    "                'female_65plus_some_hs',\n",
    "                'female_65plus_hs_grad',\n",
    "                'female_65plus_some_college',\n",
    "                'female_65plus_associates',\n",
    "                'female_65plus_bachelors',\n",
    "                'female_65plus_graduate']\n",
    "#make a list of P(x|C) columns for x in sex_age_edus\n",
    "P_sae = [f'P({col}|C)' for col in sex_age_edus]\n",
    "\n",
    "merged['P(underage|C)'] = 1 - merged[P_sae].sum(axis=1)\n",
    "merged['P(non_voter|C)'] -= merged['P(underage|C)']\n",
    "\n",
    "merged[merged.columns[-5:]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3a2aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('final_dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a9b5760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(democrat|C)</th>\n",
       "      <th>P(republican|C)</th>\n",
       "      <th>P(non_voter|C)</th>\n",
       "      <th>P(other|C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12360.000000</td>\n",
       "      <td>12360.000000</td>\n",
       "      <td>12360.000000</td>\n",
       "      <td>12360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.213071</td>\n",
       "      <td>0.359081</td>\n",
       "      <td>0.412284</td>\n",
       "      <td>0.015564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.100790</td>\n",
       "      <td>0.108909</td>\n",
       "      <td>0.098661</td>\n",
       "      <td>0.014236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.011791</td>\n",
       "      <td>0.009811</td>\n",
       "      <td>0.030581</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.344410</td>\n",
       "      <td>0.007398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.197019</td>\n",
       "      <td>0.356474</td>\n",
       "      <td>0.409682</td>\n",
       "      <td>0.011410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.276480</td>\n",
       "      <td>0.427924</td>\n",
       "      <td>0.476383</td>\n",
       "      <td>0.018036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.688758</td>\n",
       "      <td>0.915152</td>\n",
       "      <td>0.975512</td>\n",
       "      <td>0.228487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P(democrat|C)  P(republican|C)  P(non_voter|C)    P(other|C)\n",
       "count   12360.000000     12360.000000    12360.000000  12360.000000\n",
       "mean        0.213071         0.359081        0.412284      0.015564\n",
       "std         0.100790         0.108909        0.098661      0.014236\n",
       "min         0.011791         0.009811        0.030581      0.000000\n",
       "25%         0.134299         0.290189        0.344410      0.007398\n",
       "50%         0.197019         0.356474        0.409682      0.011410\n",
       "75%         0.276480         0.427924        0.476383      0.018036\n",
       "max         0.688758         0.915152        0.975512      0.228487"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = ['P(democrat|C)', 'P(republican|C)', 'P(non_voter|C)', 'P(other|C)']\n",
    "\n",
    "#divide each target by the sum of all targets\n",
    "merged[targets] = merged[targets].div(merged[targets].sum(axis=1), axis=0)\n",
    "merged[targets].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7e6817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'gisjoin',\n",
       " 'median_household_income',\n",
       " 'per_capita_income',\n",
       " 'per_capita_area',\n",
       " 'state',\n",
       " 'county',\n",
       " 'P(C)',\n",
       " 'P(households_income_under_10k|C)',\n",
       " 'P(households_income_10k_15k|C)',\n",
       " 'P(households_income_15k_25k|C)',\n",
       " 'P(households_income_25k_plus|C)',\n",
       " 'P(persons_male|C)',\n",
       " 'P(persons_female|C)',\n",
       " 'P(male_never_married|C)',\n",
       " 'P(male_married|C)',\n",
       " 'P(male_separated|C)',\n",
       " 'P(male_widowed|C)',\n",
       " 'P(male_divorced|C)',\n",
       " 'P(female_never_married|C)',\n",
       " 'P(female_married|C)',\n",
       " 'P(female_separated|C)',\n",
       " 'P(female_widowed|C)',\n",
       " 'P(female_divorced|C)',\n",
       " 'P(male_18_24_less_than_9th|C)',\n",
       " 'P(male_18_24_some_hs|C)',\n",
       " 'P(male_18_24_hs_grad|C)',\n",
       " 'P(male_18_24_some_college|C)',\n",
       " 'P(male_18_24_associates|C)',\n",
       " 'P(male_18_24_bachelors|C)',\n",
       " 'P(male_18_24_graduate|C)',\n",
       " 'P(male_25_34_less_than_9th|C)',\n",
       " 'P(male_25_34_some_hs|C)',\n",
       " 'P(male_25_34_hs_grad|C)',\n",
       " 'P(male_25_34_some_college|C)',\n",
       " 'P(male_25_34_associates|C)',\n",
       " 'P(male_25_34_bachelors|C)',\n",
       " 'P(male_25_34_graduate|C)',\n",
       " 'P(male_35_44_less_than_9th|C)',\n",
       " 'P(male_35_44_some_hs|C)',\n",
       " 'P(male_35_44_hs_grad|C)',\n",
       " 'P(male_35_44_some_college|C)',\n",
       " 'P(male_35_44_associates|C)',\n",
       " 'P(male_35_44_bachelors|C)',\n",
       " 'P(male_35_44_graduate|C)',\n",
       " 'P(male_45_64_less_than_9th|C)',\n",
       " 'P(male_45_64_some_hs|C)',\n",
       " 'P(male_45_64_hs_grad|C)',\n",
       " 'P(male_45_64_some_college|C)',\n",
       " 'P(male_45_64_associates|C)',\n",
       " 'P(male_45_64_bachelors|C)',\n",
       " 'P(male_45_64_graduate|C)',\n",
       " 'P(male_65plus_less_than_9th|C)',\n",
       " 'P(male_65plus_some_hs|C)',\n",
       " 'P(male_65plus_hs_grad|C)',\n",
       " 'P(male_65plus_some_college|C)',\n",
       " 'P(male_65plus_associates|C)',\n",
       " 'P(male_65plus_bachelors|C)',\n",
       " 'P(male_65plus_graduate|C)',\n",
       " 'P(female_18_24_less_than_9th|C)',\n",
       " 'P(female_18_24_some_hs|C)',\n",
       " 'P(female_18_24_hs_grad|C)',\n",
       " 'P(female_18_24_some_college|C)',\n",
       " 'P(female_18_24_associates|C)',\n",
       " 'P(female_18_24_bachelors|C)',\n",
       " 'P(female_18_24_graduate|C)',\n",
       " 'P(female_25_34_less_than_9th|C)',\n",
       " 'P(female_25_34_some_hs|C)',\n",
       " 'P(female_25_34_hs_grad|C)',\n",
       " 'P(female_25_34_some_college|C)',\n",
       " 'P(female_25_34_associates|C)',\n",
       " 'P(female_25_34_bachelors|C)',\n",
       " 'P(female_25_34_graduate|C)',\n",
       " 'P(female_35_44_less_than_9th|C)',\n",
       " 'P(female_35_44_some_hs|C)',\n",
       " 'P(female_35_44_hs_grad|C)',\n",
       " 'P(female_35_44_some_college|C)',\n",
       " 'P(female_35_44_associates|C)',\n",
       " 'P(female_35_44_bachelors|C)',\n",
       " 'P(female_35_44_graduate|C)',\n",
       " 'P(female_45_64_less_than_9th|C)',\n",
       " 'P(female_45_64_some_hs|C)',\n",
       " 'P(female_45_64_hs_grad|C)',\n",
       " 'P(female_45_64_some_college|C)',\n",
       " 'P(female_45_64_associates|C)',\n",
       " 'P(female_45_64_bachelors|C)',\n",
       " 'P(female_45_64_graduate|C)',\n",
       " 'P(female_65plus_less_than_9th|C)',\n",
       " 'P(female_65plus_some_hs|C)',\n",
       " 'P(female_65plus_hs_grad|C)',\n",
       " 'P(female_65plus_some_college|C)',\n",
       " 'P(female_65plus_associates|C)',\n",
       " 'P(female_65plus_bachelors|C)',\n",
       " 'P(female_65plus_graduate|C)',\n",
       " 'P(male_white|C)',\n",
       " 'P(female_white|C)',\n",
       " 'P(male_black|C)',\n",
       " 'P(female_black|C)',\n",
       " 'P(male_aian|C)',\n",
       " 'P(female_aian|C)',\n",
       " 'P(male_asian|C)',\n",
       " 'P(female_asian|C)',\n",
       " 'P(male_nhpi|C)',\n",
       " 'P(female_nhpi|C)',\n",
       " 'P(male_other|C)',\n",
       " 'P(female_other|C)',\n",
       " 'P(male_multi|C)',\n",
       " 'P(female_multi|C)',\n",
       " 'P(persons_native|C)',\n",
       " 'P(persons_foreign_born|C)',\n",
       " 'P(labor_force_total|C)',\n",
       " 'P(labor_force_armed|C)',\n",
       " 'P(labor_force_civilian|C)',\n",
       " 'P(labor_force_employed|C)',\n",
       " 'P(labor_force_unemployed|C)',\n",
       " 'P(not_in_labor_force|C)',\n",
       " 'P(persons_hispanic|C)',\n",
       " 'P(persons_below_poverty|C)',\n",
       " 'P(democrat|C)',\n",
       " 'P(other|C)',\n",
       " 'P(republican|C)',\n",
       " 'P(non_voter|C)',\n",
       " 'P(underage|C)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bbe853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from scratch by reading in the final dataset\n",
    "df = pd.read_csv('final_dataset.csv')\n",
    "\n",
    "#list of election years\n",
    "years = [2008,2012,2016,2020]\n",
    "\n",
    "#dictinary of dataframes for each year\n",
    "dfs={year: df[df['year']==year] for year in years}\n",
    "\n",
    "# save each dataframe to a csv file\n",
    "for year in years:\n",
    "    dfs[year].to_csv(f'final_dataset_{year}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of data by election year (start from scratch)\n",
    "dfs = {year: pd.read_csv(f'final_dataset_{year}.csv') for year in years}\n",
    "\n",
    "#4 targets (along with P(underage|C), form a probability distribution)\n",
    "targets = ['P(democrat|C)',\n",
    "            'P(other|C)',\n",
    "            'P(republican|C)',\n",
    "            'P(non_voter|C)']\n",
    "\n",
    "#dictionaries X, y, and county weights for each year\n",
    "ys = {year: dfs[year][targets] for year in years}\n",
    "wts = {year: dfs[year]['P(C)'] for year in years}\n",
    "Xs = {year: dfs[year].drop(columns = targets + ['year','gisjoin','state','county']) for year in years}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b058a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "standardized_Xs = {}\n",
    "for i,y1 in enumerate(years):\n",
    "    #standardize X for the year y1\n",
    "    standardized_Xs[y1] = pd.DataFrame(scaler.fit_transform(Xs[y1]), columns = Xs[y1].columns)\n",
    "    #save X, y and weights for year y1 to csv\n",
    "    standardized_Xs[y1].to_csv(f'X_{y1}.csv', index = False)\n",
    "    ys[y1].to_csv(f'y_{y1}.csv', index = False)\n",
    "    wts[y1].to_csv(f'wts_{y1}.csv', index = False)\n",
    "\n",
    "    # loop over years after y1\n",
    "    for j in range(i+1,4):\n",
    "        y2 = years[j]\n",
    "        #concatentate Xs, ys, and wts for the two years along columns\n",
    "        temp_X = pd.concat([Xs[y1], Xs[y2]])\n",
    "        temp_y = pd.concat([ys[y1], ys[y2]])\n",
    "        temp_wts = pd.concat([wts[y1], wts[y2]])\n",
    "\n",
    "        #standardize the concatenated Xs\n",
    "        temp_X = pd.DataFrame(scaler.fit_transform(temp_X), columns = temp_X.columns)\n",
    "\n",
    "        #add standardized Xs, wts and ys to the corresponding dictionaries\n",
    "        standardized_Xs[(y1,y2)] = temp_X\n",
    "        wts[(y1,y2)] = temp_wts\n",
    "        ys[(y1,y2)] = temp_y\n",
    "\n",
    "        #save X, y and wts for the two years to csv\n",
    "        temp_X.to_csv(f'X_{y1}_{y2}.csv', index = False)\n",
    "        temp_y.to_csv(f'y_{y1}_{y2}.csv', index = False)\n",
    "        temp_wts.to_csv(f'wts_{y1}_{y2}.csv', index = False)\n",
    "\n",
    "        # loop over years after y2\n",
    "        for k in range(j+1,4):\n",
    "            y3 = years[k]\n",
    "            #concatentate Xs, ys, and wts for the three years along columns\n",
    "            temp_X = pd.concat([Xs[y1], Xs[y2], Xs[y3]])\n",
    "            temp_y = pd.concat([ys[y1], ys[y2], ys[y3]])\n",
    "            temp_wts = pd.concat([wts[y1], wts[y2], wts[y3]])\n",
    "\n",
    "            #standardize the concatenated Xs\n",
    "            temp_X = pd.DataFrame(scaler.fit_transform(temp_X), columns = temp_X.columns)\n",
    "            #add wts and ys to the corresponding dictionaries\n",
    "            standardized_Xs[(y1,y2,y3)] = temp_X\n",
    "            wts[(y1,y2,y3)] = temp_wts\n",
    "            ys[(y1,y2,y3)] = temp_y\n",
    "\n",
    "            #save X, y and wts for the two years to csv\n",
    "            temp_X.to_csv(f'X_{y1}_{y2}_{y3}.csv', index = False)\n",
    "            temp_y.to_csv(f'y_{y1}_{y2}_{y3}.csv', index = False)\n",
    "            temp_wts.to_csv(f'wts_{y1}_{y2}_{y3}.csv', index = False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
