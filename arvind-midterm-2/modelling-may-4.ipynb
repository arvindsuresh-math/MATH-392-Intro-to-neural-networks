{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835ae442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device (Apple Silicon GPU)\n",
      "DataHandler initialized - Using 114 features - Test year: 2020\n"
     ]
    }
   ],
   "source": [
    "from election_project import *\n",
    "dh = DataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b52492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- XGBoost Hyperparameter Grid and Constants ---\n",
    "XGB_PARAM_GRID = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],     # Step size shrinkage (eta)\n",
    "    'max_depth': [5, 7, 10],                # Max depth of a tree\n",
    "    'subsample': [0.8, 1.0],         # Fraction of samples used per tree\n",
    "    'colsample_bytree': [0.7, 0.85, 1.0],  # Fraction of features used per tree\n",
    "    'gamma': [0.1, 0.2],                # Min loss reduction for split (min_split_loss)\n",
    "    'reg_alpha': [0, 0.1, 0.01],            # L1 regularization\n",
    "    'reg_lambda': [0, 0.1, 0.01],           # L2 regularization\n",
    "    'random_state': [42]               # For reproducibility\n",
    "}\n",
    "\n",
    "xgb_model = XGBoostModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f618a4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Cross-Validation for XGBOOST. Testing   972 configs ---\n",
      "--------------------------------------\n",
      "Config:   1 | Train loss: 1.0347 | Val Loss: 1.0444 | Optimal Rounds: 149 | Time taken: 4.07s\n",
      "Config:   2 | Train loss: 1.0357 | Val Loss: 1.0446 | Optimal Rounds: 81 | Time taken: 3.65s\n",
      "Config:   3 | Train loss: 1.0348 | Val Loss: 1.0444 | Optimal Rounds: 147 | Time taken: 3.97s\n",
      "Config:   4 | Train loss: 1.0349 | Val Loss: 1.0447 | Optimal Rounds: 114 | Time taken: 3.82s\n",
      "Config:   5 | Train loss: 1.0347 | Val Loss: 1.0446 | Optimal Rounds: 149 | Time taken: 4.24s\n",
      "Config:   6 | Train loss: 1.0351 | Val Loss: 1.0445 | Optimal Rounds: 98 | Time taken: 3.79s\n",
      "Config:   7 | Train loss: 1.0353 | Val Loss: 1.0450 | Optimal Rounds: 149 | Time taken: 3.88s\n",
      "Config:   8 | Train loss: 1.0353 | Val Loss: 1.0449 | Optimal Rounds: 111 | Time taken: 3.71s\n",
      "Config:   9 | Train loss: 1.0353 | Val Loss: 1.0449 | Optimal Rounds: 149 | Time taken: 3.86s\n",
      "Config:  10 | Train loss: 1.0357 | Val Loss: 1.0451 | Optimal Rounds: 98 | Time taken: 3.72s\n",
      "Config:  11 | Train loss: 1.0352 | Val Loss: 1.0449 | Optimal Rounds: 150 | Time taken: 3.96s\n",
      "Config:  12 | Train loss: 1.0353 | Val Loss: 1.0451 | Optimal Rounds: 118 | Time taken: 3.73s\n",
      "Config:  13 | Train loss: 1.0348 | Val Loss: 1.0446 | Optimal Rounds: 147 | Time taken: 3.98s\n",
      "Config:  14 | Train loss: 1.0353 | Val Loss: 1.0447 | Optimal Rounds: 92 | Time taken: 3.74s\n",
      "Config:  15 | Train loss: 1.0349 | Val Loss: 1.0446 | Optimal Rounds: 150 | Time taken: 4.02s\n",
      "Config:  16 | Train loss: 1.0350 | Val Loss: 1.0446 | Optimal Rounds: 106 | Time taken: 4.00s\n",
      "Config:  17 | Train loss: 1.0349 | Val Loss: 1.0446 | Optimal Rounds: 146 | Time taken: 4.23s\n",
      "Config:  18 | Train loss: 1.0356 | Val Loss: 1.0447 | Optimal Rounds: 84 | Time taken: 4.05s\n",
      "Config:  19 | Train loss: 1.0347 | Val Loss: 1.0442 | Optimal Rounds: 87 | Time taken: 5.03s\n",
      "Config:  20 | Train loss: 1.0348 | Val Loss: 1.0442 | Optimal Rounds: 76 | Time taken: 5.00s\n",
      "Config:  21 | Train loss: 1.0346 | Val Loss: 1.0443 | Optimal Rounds: 98 | Time taken: 5.06s\n",
      "Config:  22 | Train loss: 1.0348 | Val Loss: 1.0443 | Optimal Rounds: 81 | Time taken: 5.64s\n",
      "Config:  23 | Train loss: 1.0346 | Val Loss: 1.0443 | Optimal Rounds: 89 | Time taken: 5.74s\n",
      "Config:  24 | Train loss: 1.0346 | Val Loss: 1.0442 | Optimal Rounds: 81 | Time taken: 5.07s\n",
      "Config:  25 | Train loss: 1.0351 | Val Loss: 1.0448 | Optimal Rounds: 98 | Time taken: 5.72s\n",
      "Config:  26 | Train loss: 1.0351 | Val Loss: 1.0448 | Optimal Rounds: 87 | Time taken: 5.04s\n",
      "Config:  27 | Train loss: 1.0352 | Val Loss: 1.0448 | Optimal Rounds: 98 | Time taken: 6.50s\n",
      "Config:  28 | Train loss: 1.0352 | Val Loss: 1.0447 | Optimal Rounds: 87 | Time taken: 4.87s\n",
      "Config:  29 | Train loss: 1.0354 | Val Loss: 1.0448 | Optimal Rounds: 87 | Time taken: 4.79s\n",
      "Config:  30 | Train loss: 1.0352 | Val Loss: 1.0447 | Optimal Rounds: 85 | Time taken: 4.78s\n",
      "Config:  31 | Train loss: 1.0349 | Val Loss: 1.0443 | Optimal Rounds: 83 | Time taken: 5.46s\n",
      "Config:  32 | Train loss: 1.0347 | Val Loss: 1.0442 | Optimal Rounds: 81 | Time taken: 5.61s\n",
      "Config:  33 | Train loss: 1.0347 | Val Loss: 1.0444 | Optimal Rounds: 98 | Time taken: 5.13s\n",
      "Config:  34 | Train loss: 1.0347 | Val Loss: 1.0445 | Optimal Rounds: 85 | Time taken: 5.34s\n",
      "Config:  35 | Train loss: 1.0345 | Val Loss: 1.0442 | Optimal Rounds: 98 | Time taken: 5.33s\n",
      "Config:  36 | Train loss: 1.0346 | Val Loss: 1.0441 | Optimal Rounds: 83 | Time taken: 5.01s\n",
      "Config:  37 | Train loss: 1.0344 | Val Loss: 1.0443 | Optimal Rounds: 83 | Time taken: 5.94s\n",
      "Config:  38 | Train loss: 1.0344 | Val Loss: 1.0441 | Optimal Rounds: 75 | Time taken: 6.25s\n",
      "Config:  39 | Train loss: 1.0350 | Val Loss: 1.0444 | Optimal Rounds: 76 | Time taken: 5.75s\n",
      "Config:  40 | Train loss: 1.0345 | Val Loss: 1.0442 | Optimal Rounds: 78 | Time taken: 6.00s\n",
      "Config:  41 | Train loss: 1.0345 | Val Loss: 1.0443 | Optimal Rounds: 83 | Time taken: 5.83s\n",
      "Config:  42 | Train loss: 1.0342 | Val Loss: 1.0441 | Optimal Rounds: 81 | Time taken: 6.01s\n",
      "Config:  43 | Train loss: 1.0352 | Val Loss: 1.0447 | Optimal Rounds: 87 | Time taken: 5.43s\n",
      "Config:  44 | Train loss: 1.0351 | Val Loss: 1.0448 | Optimal Rounds: 80 | Time taken: 5.95s\n",
      "Config:  45 | Train loss: 1.0350 | Val Loss: 1.0448 | Optimal Rounds: 98 | Time taken: 5.44s\n",
      "Config:  46 | Train loss: 1.0351 | Val Loss: 1.0448 | Optimal Rounds: 85 | Time taken: 5.53s\n",
      "Config:  47 | Train loss: 1.0352 | Val Loss: 1.0447 | Optimal Rounds: 87 | Time taken: 5.52s\n",
      "Config:  48 | Train loss: 1.0353 | Val Loss: 1.0447 | Optimal Rounds: 75 | Time taken: 5.66s\n",
      "Config:  49 | Train loss: 1.0344 | Val Loss: 1.0444 | Optimal Rounds: 87 | Time taken: 6.41s\n",
      "Config:  50 | Train loss: 1.0343 | Val Loss: 1.0443 | Optimal Rounds: 81 | Time taken: 6.06s\n",
      "Config:  51 | Train loss: 1.0348 | Val Loss: 1.0444 | Optimal Rounds: 81 | Time taken: 5.59s\n",
      "Config:  52 | Train loss: 1.0347 | Val Loss: 1.0444 | Optimal Rounds: 76 | Time taken: 6.74s\n",
      "Config:  53 | Train loss: 1.0346 | Val Loss: 1.0443 | Optimal Rounds: 83 | Time taken: 6.07s\n",
      "Config:  54 | Train loss: 1.0345 | Val Loss: 1.0442 | Optimal Rounds: 76 | Time taken: 6.14s\n",
      "Config:  55 | Train loss: 1.0348 | Val Loss: 1.0443 | Optimal Rounds: 119 | Time taken: 3.13s\n",
      "Config:  56 | Train loss: 1.0349 | Val Loss: 1.0446 | Optimal Rounds: 56 | Time taken: 2.54s\n",
      "Config:  57 | Train loss: 1.0348 | Val Loss: 1.0444 | Optimal Rounds: 150 | Time taken: 3.22s\n",
      "Config:  58 | Train loss: 1.0352 | Val Loss: 1.0446 | Optimal Rounds: 50 | Time taken: 2.45s\n",
      "Config:  59 | Train loss: 1.0348 | Val Loss: 1.0444 | Optimal Rounds: 150 | Time taken: 3.19s\n",
      "Config:  60 | Train loss: 1.0350 | Val Loss: 1.0446 | Optimal Rounds: 53 | Time taken: 2.48s\n",
      "Config:  61 | Train loss: 1.0352 | Val Loss: 1.0448 | Optimal Rounds: 95 | Time taken: 3.90s\n",
      "Config:  62 | Train loss: 1.0354 | Val Loss: 1.0452 | Optimal Rounds: 59 | Time taken: 2.46s\n",
      "Config:  63 | Train loss: 1.0352 | Val Loss: 1.0447 | Optimal Rounds: 146 | Time taken: 3.14s\n",
      "Config:  64 | Train loss: 1.0355 | Val Loss: 1.0451 | Optimal Rounds: 51 | Time taken: 2.44s\n",
      "Config:  65 | Train loss: 1.0351 | Val Loss: 1.0447 | Optimal Rounds: 147 | Time taken: 3.27s\n",
      "Config:  66 | Train loss: 1.0354 | Val Loss: 1.0451 | Optimal Rounds: 58 | Time taken: 2.91s\n",
      "Config:  67 | Train loss: 1.0347 | Val Loss: 1.0444 | Optimal Rounds: 144 | Time taken: 3.26s\n",
      "Config:  68 | Train loss: 1.0351 | Val Loss: 1.0445 | Optimal Rounds: 50 | Time taken: 2.62s\n",
      "Config:  69 | Train loss: 1.0348 | Val Loss: 1.0444 | Optimal Rounds: 146 | Time taken: 4.56s\n",
      "Config:  70 | Train loss: 1.0350 | Val Loss: 1.0447 | Optimal Rounds: 54 | Time taken: 4.68s\n",
      "Config:  71 | Train loss: 1.0348 | Val Loss: 1.0443 | Optimal Rounds: 144 | Time taken: 3.26s\n",
      "Config:  72 | Train loss: 1.0349 | Val Loss: 1.0445 | Optimal Rounds: 57 | Time taken: 2.95s\n",
      "Config:  73 | Train loss: 1.0347 | Val Loss: 1.0441 | Optimal Rounds: 42 | Time taken: 3.23s\n",
      "Config:  74 | Train loss: 1.0345 | Val Loss: 1.0442 | Optimal Rounds: 42 | Time taken: 3.03s\n",
      "Config:  75 | Train loss: 1.0348 | Val Loss: 1.0441 | Optimal Rounds: 44 | Time taken: 3.42s\n",
      "Config:  76 | Train loss: 1.0347 | Val Loss: 1.0442 | Optimal Rounds: 42 | Time taken: 3.07s\n",
      "Config:  77 | Train loss: 1.0343 | Val Loss: 1.0443 | Optimal Rounds: 61 | Time taken: 3.08s\n",
      "Config:  78 | Train loss: 1.0345 | Val Loss: 1.0442 | Optimal Rounds: 41 | Time taken: 2.99s\n",
      "Config:  79 | Train loss: 1.0349 | Val Loss: 1.0447 | Optimal Rounds: 63 | Time taken: 3.15s\n",
      "Config:  80 | Train loss: 1.0352 | Val Loss: 1.0449 | Optimal Rounds: 42 | Time taken: 3.08s\n",
      "Config:  81 | Train loss: 1.0348 | Val Loss: 1.0448 | Optimal Rounds: 149 | Time taken: 3.84s\n",
      "Config:  82 | Train loss: 1.0351 | Val Loss: 1.0451 | Optimal Rounds: 46 | Time taken: 3.66s\n",
      "Config:  83 | Train loss: 1.0348 | Val Loss: 1.0447 | Optimal Rounds: 149 | Time taken: 3.69s\n",
      "Config:  84 | Train loss: 1.0350 | Val Loss: 1.0448 | Optimal Rounds: 44 | Time taken: 2.96s\n",
      "Config:  85 | Train loss: 1.0347 | Val Loss: 1.0443 | Optimal Rounds: 44 | Time taken: 3.11s\n",
      "Config:  86 | Train loss: 1.0350 | Val Loss: 1.0442 | Optimal Rounds: 37 | Time taken: 2.88s\n",
      "Config:  87 | Train loss: 1.0344 | Val Loss: 1.0444 | Optimal Rounds: 63 | Time taken: 3.20s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xgb_cv_results \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mcross_validate(dh, XGB_PARAM_GRID, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MATH-392-Intro-to-neural-networks/arvind-midterm-2/election_project.py:1005\u001b[0m, in \u001b[0;36mXGBoostModel.cross_validate\u001b[0;34m(self, dh, param_grid, max_finalists, early_stopping_rounds, num_boost_rounds, save)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;66;03m# add gpu_hist param if cuda is available\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEVICE\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1005\u001b[0m     params_for_cv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtree_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;66;03m#NOTE: setting shuffle=False ensures that the folds are exactly same as what's used by other models\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m cv_results_df \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mcv(\n\u001b[1;32m   1009\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams_for_cv,\n\u001b[1;32m   1010\u001b[0m     dtrain\u001b[38;5;241m=\u001b[39mdtrain,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/math392/lib/python3.11/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/math392/lib/python3.11/site-packages/xgboost/training.py:581\u001b[0m, in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle, custom_metric)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks_container\u001b[38;5;241m.\u001b[39mbefore_iteration(booster, i, dtrain, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 581\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(i, obj)\n\u001b[1;32m    583\u001b[0m should_break \u001b[38;5;241m=\u001b[39m callbacks_container\u001b[38;5;241m.\u001b[39mafter_iteration(booster, i, dtrain, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    584\u001b[0m res \u001b[38;5;241m=\u001b[39m callbacks_container\u001b[38;5;241m.\u001b[39maggregated_cv\n",
      "File \u001b[0;32m/opt/anaconda3/envs/math392/lib/python3.11/site-packages/xgboost/training.py:229\u001b[0m, in \u001b[0;36m_PackedBooster.update\u001b[0;34m(self, iteration, obj)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterate through folds for update\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcvfolds:\n\u001b[0;32m--> 229\u001b[0m     fold\u001b[38;5;241m.\u001b[39mupdate(iteration, obj)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/math392/lib/python3.11/site-packages/xgboost/training.py:215\u001b[0m, in \u001b[0;36mCVPack.update\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, iteration: \u001b[38;5;28mint\u001b[39m, fobj: Optional[Objective]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \"Update the boosters for one iteration\"\"\"\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbst\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtrain, iteration, fobj)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/math392/lib/python3.11/site-packages/xgboost/core.py:2254\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2252\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2253\u001b[0m grad, hess \u001b[38;5;241m=\u001b[39m fobj(pred, dtrain)\n\u001b[0;32m-> 2254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboost(dtrain, iteration\u001b[38;5;241m=\u001b[39miteration, grad\u001b[38;5;241m=\u001b[39mgrad, hess\u001b[38;5;241m=\u001b[39mhess)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/math392/lib/python3.11/site-packages/xgboost/core.py:2309\u001b[0m, in \u001b[0;36mBooster.boost\u001b[0;34m(self, dtrain, iteration, grad, hess)\u001b[0m\n\u001b[1;32m   2304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m   2306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m interface\n\u001b[1;32m   2308\u001b[0m _check_call(\n\u001b[0;32m-> 2309\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mXGBoosterTrainOneIter(\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   2311\u001b[0m         dtrain\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   2312\u001b[0m         iteration,\n\u001b[1;32m   2313\u001b[0m         grad_arrinf(grad),\n\u001b[1;32m   2314\u001b[0m         grad_arrinf(hess),\n\u001b[1;32m   2315\u001b[0m     )\n\u001b[1;32m   2316\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_cv_results = xgb_model.cross_validate(dh, XGB_PARAM_GRID, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c8046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model Predictions ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(democrat)</th>\n",
       "      <th>P(other)</th>\n",
       "      <th>P(republican)</th>\n",
       "      <th>P(non_voter)</th>\n",
       "      <th>P(underage)</th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>KL Div</th>\n",
       "      <th>KL Div%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.197592</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.194111</td>\n",
       "      <td>0.224836</td>\n",
       "      <td>0.221261</td>\n",
       "      <td>1.563372</td>\n",
       "      <td>0.146192</td>\n",
       "      <td>10.315669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>0.244420</td>\n",
       "      <td>0.00902</td>\n",
       "      <td>0.224074</td>\n",
       "      <td>0.301225</td>\n",
       "      <td>0.221261</td>\n",
       "      <td>1.417181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         P(democrat)  P(other)  P(republican)  P(non_voter)  P(underage)  \\\n",
       "xgboost     0.197592   0.16220       0.194111      0.224836     0.221261   \n",
       "true        0.244420   0.00902       0.224074      0.301225     0.221261   \n",
       "\n",
       "         Cross-entropy    KL Div    KL Div%  \n",
       "xgboost       1.563372  0.146192  10.315669  \n",
       "true          1.417181  0.000000   0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.load_model()\n",
    "y_pred = xgb_model.predict(dh, save=False)\n",
    "check = evaluate_predictions({'xgboost': y_pred}, dh, save=False)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556c481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
